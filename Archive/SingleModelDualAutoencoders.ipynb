{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_autoencoder(n, l, act_layer_config, lin_layer_config):\n",
    "    # First build the encoder\n",
    "    input_ = keras.layers.Input(shape=n)\n",
    "    hidden1 = keras.layers.Dense(n, **act_layer_config)(input_)\n",
    "    hidden2 = keras.layers.Dense(n, **act_layer_config)(hidden1)\n",
    "    hidden3 = keras.layers.Dense(n, **lin_layer_config)(hidden2)\n",
    "    added = keras.layers.Add()([input_, hidden3])\n",
    "    latentspace = keras.layers.Dense(l, **lin_layer_config)(added)\n",
    "    encoder = keras.Model(inputs=[input_], outputs=[latentspace])\n",
    "    # Now the decoder\n",
    "    latent_ = keras.layers.Input(shape=l)\n",
    "    hidden4 = keras.layers.Dense(n, **lin_layer_config)(latent_)\n",
    "    hidden5 = keras.layers.Dense(n, **act_layer_config)(hidden4)\n",
    "    hidden6 = keras.layers.Dense(n, **act_layer_config)(hidden5)\n",
    "    hidden7 = keras.layers.Dense(n, **act_layer_config)(hidden6)\n",
    "    added_ = keras.layers.Add()([hidden4, hidden7])\n",
    "    decoder = keras.Model(inputs=[latent_], outputs=[added_])\n",
    "    # Tie them together\n",
    "    autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "    # And return the autoencoder model\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Duffing_Equation_expt4'  ## FILL IN HERE (from file name)\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_train_u = np.load(('../data/%s_train1_u.npy' % (data_name)))\n",
    "data_train_f = np.load(('../data/%s_train1_f.npy' % (data_name)))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_val_u = np.load(('../data/%s_val_u.npy' % (data_name)))\n",
    "data_val_f = np.load(('../data/%s_val_f.npy' % (data_name)))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_test_u = np.load(('../data/%s_test2_u.npy' % (data_name)))\n",
    "data_test_f = np.load(('../data/%s_test2_f.npy' % (data_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training contains: 4798 samples.\n",
      "Validation contains: 1200 samples.\n",
      "Input vector is 128 neurons and latent space is 128 neurons.\n"
     ]
    }
   ],
   "source": [
    "_, n = data_train_u.shape\n",
    "l = int(n/4)\n",
    "l = n\n",
    "\n",
    "print(\"Training contains:\", data_train_u.shape[0], \"samples.\")\n",
    "print(\"Validation contains:\", data_val_u.shape[0], \"samples.\")\n",
    "print(\"Input vector is\", n, \"neurons and latent space is\", l, \"neurons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration to be used for layers with activation functions and linear, non-activated functions\n",
    "act_layer = dict(activation=\"relu\", kernel_initializer='he_normal')\n",
    "act_layer = dict(activation=\"elu\", kernel_initializer='he_normal')\n",
    "lin_layer = dict(activation=None)\n",
    "\n",
    "# Encoder for u and encoder for f\n",
    "u_aec = construct_autoencoder(n, l, act_layer, lin_layer)\n",
    "f_aec = construct_autoencoder(n, l, act_layer, lin_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'model_input:0' shape=(None, 128) dtype=float32>,\n",
       " <tf.Tensor 'model_2_input:0' shape=(None, 128) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_aec.inputs + f_aec.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'model_1/Identity:0' shape=(None, 128) dtype=float32>,\n",
       " <tf.Tensor 'model_3/Identity:0' shape=(None, 128) dtype=float32>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_aec.outputs + f_aec.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tie them together\n",
    "dual_autoencoder = keras.models.Model(inputs = u_aec.inputs + f_aec.inputs, \n",
    "                                      outputs = u_aec.outputs + f_aec.outputs)\n",
    "\n",
    "# Set the optimizer to be used\n",
    "optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# Compile the autoencoders\n",
    "dual_autoencoder.compile(loss=[\"mse\",\"mse\"], optimizer=optimizer)\n",
    "\n",
    "# Specify fit options\n",
    "cbs = [keras.callbacks.ModelCheckpoint(\"dae.h5\", save_best_only=True),\n",
    "       tf.keras.callbacks.EarlyStopping()]\n",
    "fit_options = dict(batch_size = 5, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = dual_autoencoder.fit(x=[data_train_u, data_train_f], y=[data_train_u, data_train_f], \n",
    "                            validation_data=[(data_val_u, data_val_f), (data_val_u, data_val_f)],\n",
    "                            callbacks=cbs,\n",
    "                            **fit_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the dual encoder's layers\n",
    "# see if you can break it down easily from top-down view to access encoder/decoder\n",
    "\n",
    "# if so, build a lyaer between latent spaces\n",
    "\n",
    "# if not, split autoencoder constructions into encoder constructor and decoder constructor\n",
    "# that way, it is easier to put together functional API-based model for linking latent spaces\n",
    "\n",
    "\n",
    "# Looks like modules can be built into layers fairly easily\n",
    "\n",
    "# Modules as layers: https://www.tensorflow.org/api_docs/python/tf/Module\n",
    "# LinearOperator is subclass of Module\n",
    "\n",
    "# another thought -- consider linking weights of both autoencoders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also -- consider how to build in superposition \n",
    "#  https://en.wikipedia.org/wiki/Superposition_principle\n",
    "# additivity and homogeneity are two different techniques..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to access the encoders:\n",
    "u_encoder = dual_autoencoder.layers[2]\n",
    "F_encoder = dual_autoencoder.layers[3]\n",
    "# And get their outputs:\n",
    "v_space = u_encoder.outputs[0]\n",
    "f_space = F_encoder.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above will be used for computing Lv and then building loss function ||Lv-f||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_input\n",
      "model_2_input\n",
      "model\n",
      "model_2\n",
      "model_1\n",
      "model_3\n"
     ]
    }
   ],
   "source": [
    "for layer in dual_autoencoder.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Identity:0' shape=(None, 128) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SelfAdjointOperator(tf.linalg.LinearOperator):\n",
    "    def __init__(self, dtype=tf.float32, graph_parents=None):\n",
    "        super(SelfAdjointOperator, self).__init__(dtype, graph_parents=graph_parents, is_self_adjoint=True)\n",
    "    \n",
    "    def _matmul(self, x):\n",
    "        return self.matmul(x, adjoint=False)\n",
    "        \n",
    "    def __call__(self):\n",
    "        y = self.matmul(x, adjoint=False)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class SelfAdjointOperator with abstract methods _shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-442cb0ae3152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfAdjointOperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_parents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class SelfAdjointOperator with abstract methods _shape"
     ]
    }
   ],
   "source": [
    "L = SelfAdjointOperator(graph_parents=v_space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
