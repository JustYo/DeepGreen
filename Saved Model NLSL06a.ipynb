{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import json\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AbstractArchitecture_v2 import AbstractArchitecture\n",
    "from DenseEncoder import DenseEncoder\n",
    "from DenseDecoder import DenseDecoder\n",
    "from NormalizedMeanSquaredError import NormalizedMeanSquaredError as NMSE\n",
    "from plot_model_prediction import plot_model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data file locations\n",
    "data_file_prefix = './data/NLSL_expt1'\n",
    "\n",
    "# Step 1. Load in the data\n",
    "data_train_u = np.load(\"{}_train1_u.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_train_f = np.load(\"{}_train1_f.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_val_u = np.load(\"{}_val_u.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_val_f = np.load(\"{}_val_f.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_test_u1 = np.load(\"{}_test1_u.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_test_f1 = np.load(\"{}_test1_f.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_test_u = np.load(\"{}_test2_u.npy\".format(data_file_prefix)).astype(np.float32)\n",
    "data_test_f = np.load(\"{}_test2_f.npy\".format(data_file_prefix)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"./model_weights/NLSL_Experiment_06b/final_model\"\n",
    "\n",
    "# Load the best model\n",
    "full_model = keras.models.load_model(best_model_path, \n",
    "                                     custom_objects={\"NormalizedMeanSquaredError\": NMSE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1:  1.7438053e-05\n",
      "Score 2:  4.44921898e-05\n",
      "Score 3:  7.37037844e-05\n",
      "Score 4:  0.0560517274\n",
      "(8906, 128)\n",
      "Total Loss: tf.Tensor(0.05618736, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss_fns = 4*[NMSE()]\n",
    "predicted_ys = full_model.predict(x=[data_train_u, data_train_f])\n",
    "\n",
    "true_ys=[data_train_u, data_train_f, data_train_f, data_train_u]\n",
    "nmse = NMSE()\n",
    "\n",
    "total_loss = 0\n",
    "for i, (pred_y, true_y, loss_fn) in enumerate(zip(predicted_ys, true_ys, loss_fns)):\n",
    "    #print(pred_y.dtype, true_y.dtype)\n",
    "    print(\"Score {}:\".format(i+1), end=\"  \")\n",
    "    loss = loss_fn(pred_y, true_y)\n",
    "    tf.print(loss)\n",
    "    total_loss += loss\n",
    "    \n",
    "print(data_train_u.shape)\n",
    "print(\"Total Loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0:  1.80504339e-05\n",
      "Score 1:  0.000231853555\n",
      "Score 2:  0.000150292646\n",
      "Score 3:  0.0572284088\n",
      "(8906, 128)\n",
      "Total Loss: tf.Tensor(0.057628606, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "val_x = [data_val_u, data_val_f]\n",
    "val_ys = [data_val_u, data_val_f, data_val_f, data_val_u]\n",
    "predicted_ys = full_model.predict(x=val_x)\n",
    "\n",
    "total_loss = 0\n",
    "for i, (pred_y, true_y, loss_fn) in enumerate(zip(predicted_ys, val_ys, loss_fns)):\n",
    "    #print(pred_y.dtype, true_y.dtype)\n",
    "    print(\"Score {}:\".format(i), end=\"  \")\n",
    "    loss = loss_fn(pred_y, true_y)\n",
    "    tf.print(loss)\n",
    "    total_loss += loss\n",
    "    \n",
    "print(data_train_u.shape)\n",
    "print(\"Total Loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0347 - output_1_loss: 1.8075e-05 - output_2_loss: 2.4335e-04 - output_3_loss: 1.4977e-04 - output_4_loss: 0.0340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03474007919430733,\n",
       " 1.8074726540362462e-05,\n",
       " 0.00024334988847840577,\n",
       " 0.0001497721386840567,\n",
       " 0.03404095396399498]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.evaluate(x=val_x, y=val_ys, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04213734716176987 0.03995571658015251\n",
      "0.04019251341621081\n"
     ]
    }
   ],
   "source": [
    "i_hist = json.load(open('./model_weights/NLSL_Experiment_06b/model_history.json'))\n",
    "m_hist = json.load(open('./model_weights/NLSL_Experiment_06b/initial_train.json'))\n",
    "f_hist = json.load(open('./model_weights/NLSL_Experiment_06b/final_model_history.json'))\n",
    "\n",
    "print(i_hist['loss'][-1], f_hist['loss'][0])\n",
    "print(min(m_hist['full_init_loss']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
