{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from OperatorLayer import SymmetricOperator\n",
    "from OperatorLayer import SolveOperatorInverse\n",
    "from NormalizedMeanSquaredError import NormalizedMeanSquaredError as NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Duffing_Equation_expt4'  ## FILL IN HERE (from file name)\n",
    "data_folder = '../NODE-Operators/data/'\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_train_u = np.load(data_folder + \"{}_train1_u.npy\".format(data_name))\n",
    "data_train_f = np.load(data_folder + \"{}_train1_f.npy\".format(data_name))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_val_u = np.load(data_folder + \"{}_val_u.npy\".format(data_name))\n",
    "data_val_f = np.load(data_folder + \"{}_val_f.npy\".format(data_name))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_test_u = np.load(data_folder + \"{}_test2_u.npy\".format(data_name))\n",
    "data_test_f = np.load(data_folder + \"{}_test2_f.npy\".format(data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out name in final model because this was causing the loading issue:\n",
    "# see https://stackoverflow.com/questions/57201943/during-creating-vae-model-throws-exception-you-should-implement-a-call-method\n",
    "\n",
    "def construct_encoder(n, l, act_layer_config, lin_layer_config, name):\n",
    "    # First build the encoder\n",
    "    input_ = keras.layers.Input(shape=n)\n",
    "    hidden1 = keras.layers.Dense(n, **act_layer_config)(input_)\n",
    "    hidden2 = keras.layers.Dense(n, **act_layer_config)(hidden1)\n",
    "    hidden3 = keras.layers.Dense(n, **lin_layer_config)(hidden2)\n",
    "    added = keras.layers.Add()([input_, hidden3])\n",
    "    latentspace = keras.layers.Dense(l, **lin_layer_config)(added)\n",
    "    encoder = keras.Model(inputs=[input_], outputs=[latentspace], name=name)\n",
    "    return encoder\n",
    "\n",
    "def construct_decoder(n, l, act_layer_config, lin_layer_config, name):\n",
    "    # Now the decoder\n",
    "    latent_ = keras.layers.Input(shape=l)\n",
    "    hidden4 = keras.layers.Dense(n, **lin_layer_config)(latent_)\n",
    "    hidden5 = keras.layers.Dense(n, **act_layer_config)(hidden4)\n",
    "    hidden6 = keras.layers.Dense(n, **act_layer_config)(hidden5)\n",
    "    hidden7 = keras.layers.Dense(n, **act_layer_config)(hidden6)\n",
    "    added_ = keras.layers.Add()([hidden4, hidden7])\n",
    "    decoder = keras.Model(inputs=[latent_], outputs=[added_], name=name)\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training contains: 4798 samples.\n",
      "Validation contains: 1200 samples.\n",
      "Input vector is 128 neurons and latent space is 20 neurons.\n"
     ]
    }
   ],
   "source": [
    "_, n = data_train_u.shape\n",
    "l = 20\n",
    "\n",
    "print(\"Training contains:\", data_train_u.shape[0], \"samples.\")\n",
    "print(\"Validation contains:\", data_val_u.shape[0], \"samples.\")\n",
    "print(\"Input vector is\", n, \"neurons and latent space is\", l, \"neurons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration to be used for layers with activation functions and linear, non-activated functions\n",
    "#act_layer = dict(activation=\"relu\", kernel_initializer='he_normal')\n",
    "act_layer = dict(activation=\"elu\", kernel_initializer='he_normal')\n",
    "lin_layer = dict(activation=None)\n",
    "\n",
    "# Encoder and decoder for u\n",
    "u_enc = construct_encoder(n, l, act_layer, lin_layer, \"u_encoder\")\n",
    "u_dec = construct_decoder(n, l, act_layer, lin_layer, \"u_decoder\")\n",
    "\n",
    "# Encoder and decoder for u\n",
    "f_enc = construct_encoder(n, l, act_layer, lin_layer, \"f_encoder\")\n",
    "f_dec = construct_decoder(n, l, act_layer, lin_layer, \"f_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now assemble the COMPLETE, LINKED autoencoder!!\n",
    "u_input = keras.layers.Input(shape=n)\n",
    "u_encoded = u_enc(u_input)\n",
    "\n",
    "f_input = keras.layers.Input(shape=n)\n",
    "f_encoded = f_enc(f_input)\n",
    "\n",
    "Operator = SymmetricOperator()\n",
    "#L = Operator.get_operator()\n",
    "OperatorLayer = Operator(u_encoded)\n",
    "\n",
    "Inverse = SolveOperatorInverse(Operator)\n",
    "InverseLayer = Inverse(f_encoded)\n",
    "\n",
    "#L_full = tf.Variable(tf.eye(l), trainable=True, dtype=tf.float32, name=\"L_full\")\n",
    "#L_upper = tf.linalg.band_part(L_full, 0, -1, name=\"L_upper\")\n",
    "#L = tf.multiply(0.5,L_upper+tf.transpose(L_upper), name=\"L\")\n",
    "#OperatorLayer = tf.matmul(u_encoded, L, name=\"OperatorLayer\")\n",
    "\n",
    "#f_encoded_T = tf.transpose(f_encoded)\n",
    "#Linvf_T = tf.linalg.solve(L, f_encoded_T, adjoint=True)\n",
    "#Linvf = tf.transpose(Linvf_T)\n",
    "\n",
    "#DiffLayer = keras.layers.Subtract()([OperatorLayer, f_encoded])\n",
    "\n",
    "u_decoded = u_dec(u_encoded)\n",
    "f_decoded = f_dec(f_encoded)\n",
    "\n",
    "Lv_decoded = f_dec(OperatorLayer)\n",
    "Linvf_decoded = u_dec(InverseLayer)\n",
    "\n",
    "linked_aec = keras.Model(inputs = [u_input, f_input], \n",
    "#                         outputs = [u_decoded, f_decoded, Lv_decoded, Linvf_decoded],\n",
    "                         outputs = [u_decoded, f_decoded, Lv_decoded, Linvf_decoded])\n",
    "#                         name=\"linked_autoencoders\")\n",
    "\n",
    "# Add the superposition loss function\n",
    "f_sums = tf.reshape(f_encoded[None]+f_encoded[:,None], [-1,l])\n",
    "Lv_sums = tf.reshape(OperatorLayer[None]+OperatorLayer[:,None], [-1,l])\n",
    "linked_aec.add_loss(NMSE()(f_encoded, OperatorLayer))\n",
    "linked_aec.add_loss(NMSE()(f_sums, Lv_sums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer to be used\n",
    "#optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# Create a Normalized Mean Squared Error loss function\n",
    "loss_fns = 4*[NMSE()]\n",
    "\n",
    "# Compile the model\n",
    "#linked_aec.compile(loss=[\"mse\",\"mse\", \"mse\"], optimizer=optimizer)\n",
    "#linked_aec.compile(loss=[encoder_loss, encoder_loss, encoder_loss, encoder_loss], optimizer=optimizer)\n",
    "linked_aec.compile(loss=loss_fns, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16512       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           input_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 20)           2580        add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 52,116\n",
      "Trainable params: 52,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"u_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          2688        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128)          0           dense_4[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 52,224\n",
      "Trainable params: 52,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"f_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16512       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          16512       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           input_3[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 20)           2580        add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 52,116\n",
      "Trainable params: 52,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"f_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          2688        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          16512       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          16512       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           dense_12[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 52,224\n",
      "Trainable params: 52,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "u_encoder (Model)               (None, 20)           52116       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "f_encoder (Model)               (None, 20)           52116       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "symmetric_operator (SymmetricOp (None, 20)           400         u_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "solve_operator_inverse (SolveOp (None, 20)           400         f_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "u_decoder (Model)               (None, 128)          52224       u_encoder[1][0]                  \n",
      "                                                                 solve_operator_inverse[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "f_decoder (Model)               (None, 128)          52224       f_encoder[1][0]                  \n",
      "                                                                 symmetric_operator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 20)]         0           symmetric_operator[0][0]         \n",
      "                                                                 f_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 20)]         0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm/mul (TensorFlo [(None, 20)]         0           tf_op_layer_Square[0][0]         \n",
      "                                                                 tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_1/mul (TensorF [(None, 20)]         0           f_encoder[1][0]                  \n",
      "                                                                 f_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm/Sum (TensorFlo [(1, 1)]             0           tf_op_layer_norm/mul[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_1/Sum (TensorF [(1, 1)]             0           tf_op_layer_norm_1/mul[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm/Sqrt (TensorFl [(1, 1)]             0           tf_op_layer_norm/Sum[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_1/Sqrt (Tensor [(1, 1)]             0           tf_op_layer_norm_1/Sum[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm/Squeeze (Tenso [()]                 0           tf_op_layer_norm/Sqrt[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_1/Squeeze (Ten [()]                 0           tf_op_layer_norm_1/Sqrt[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [()]                 0           tf_op_layer_norm/Squeeze[0][0]   \n",
      "                                                                 tf_op_layer_norm_1/Squeeze[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss/Mul ( [()]                 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss/Sum ( [()]                 0           tf_op_layer_weighted_loss/Mul[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss/Sum_1 [()]                 0           tf_op_layer_weighted_loss/Sum[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss/value [()]                 0           tf_op_layer_weighted_loss/Sum_1[0\n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf_op_layer_weighted_loss/value[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(1, None, 20)]      0           symmetric_operator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 1, 20)]      0           symmetric_operator[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(1, None, 20)]      0           f_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 1, 20)]      0           f_encoder[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_5 (TensorFlowOp [(None, None, 20)]   0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_4 (TensorFlowOp [(None, None, 20)]   0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 20)]         0           tf_op_layer_add_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 20)]         0           tf_op_layer_add_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_1 (TensorFlowOp [(None, 20)]         0           tf_op_layer_Reshape_1[0][0]      \n",
      "                                                                 tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_1 (TensorFlo [(None, 20)]         0           tf_op_layer_sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_2/mul (TensorF [(None, 20)]         0           tf_op_layer_Square_1[0][0]       \n",
      "                                                                 tf_op_layer_Square_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_3/mul (TensorF [(None, 20)]         0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_2/Sum (TensorF [(1, 1)]             0           tf_op_layer_norm_2/mul[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_3/Sum (TensorF [(1, 1)]             0           tf_op_layer_norm_3/mul[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_2/Sqrt (Tensor [(1, 1)]             0           tf_op_layer_norm_2/Sum[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_3/Sqrt (Tensor [(1, 1)]             0           tf_op_layer_norm_3/Sum[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_2/Squeeze (Ten [()]                 0           tf_op_layer_norm_2/Sqrt[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_norm_3/Squeeze (Ten [()]                 0           tf_op_layer_norm_3/Sqrt[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv_1 (TensorFl [()]                 0           tf_op_layer_norm_2/Squeeze[0][0] \n",
      "                                                                 tf_op_layer_norm_3/Squeeze[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss_1/Mul [()]                 0           tf_op_layer_truediv_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss_1/Sum [()]                 0           tf_op_layer_weighted_loss_1/Mul[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss_1/Sum [()]                 0           tf_op_layer_weighted_loss_1/Sum[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_weighted_loss_1/val [()]                 0           tf_op_layer_weighted_loss_1/Sum_1\n",
      "__________________________________________________________________________________________________\n",
      "add_loss_1 (AddLoss)            ()                   0           tf_op_layer_weighted_loss_1/value\n",
      "==================================================================================================\n",
      "Total params: 209,080\n",
      "Trainable params: 209,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "u_enc.summary()\n",
    "u_dec.summary()\n",
    "f_enc.summary()\n",
    "f_dec.summary()\n",
    "linked_aec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training options\n",
    "# Validation data\n",
    "val_data = [(data_val_u, data_val_f), \n",
    "            (data_val_u, data_val_f, data_val_f)]\n",
    "val_data = [(data_val_u, data_val_f), \n",
    "            (data_val_u, data_val_f, data_val_f, data_val_u)]\n",
    "# Callback functions\n",
    "cbs = [keras.callbacks.ModelCheckpoint(\"dae.tf\", save_best_only=True),\n",
    "       keras.callbacks.EarlyStopping()]\n",
    "# Other options\n",
    "fit_options = dict(batch_size = 20, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4798 samples, validate on 1200 samples\n",
      "Epoch 1/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 6.1132 - u_decoder_loss: 0.7067 - f_decoder_loss: 0.6516 - f_decoder_1_loss: 1.0649 - u_decoder_1_loss: 1.6118 - val_loss: 4.6892 - val_u_decoder_loss: 0.6417 - val_f_decoder_loss: 0.4301 - val_f_decoder_1_loss: 0.7172 - val_u_decoder_1_loss: 1.7438\n",
      "Epoch 2/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 3.9957 - u_decoder_loss: 0.5999 - f_decoder_loss: 0.4135 - f_decoder_1_loss: 0.6525 - u_decoder_1_loss: 1.4599 - val_loss: 5.4096 - val_u_decoder_loss: 0.6073 - val_f_decoder_loss: 0.7425 - val_f_decoder_1_loss: 1.0980 - val_u_decoder_1_loss: 1.8348\n",
      "Epoch 3/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 4.6713 - u_decoder_loss: 0.5998 - f_decoder_loss: 0.5328 - f_decoder_1_loss: 0.8677 - u_decoder_1_loss: 1.4924 - val_loss: 4.1916 - val_u_decoder_loss: 0.5484 - val_f_decoder_loss: 0.3763 - val_f_decoder_1_loss: 0.6010 - val_u_decoder_1_loss: 1.4170\n",
      "Epoch 4/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 4.3676 - u_decoder_loss: 0.5414 - f_decoder_loss: 0.4716 - f_decoder_1_loss: 0.7017 - u_decoder_1_loss: 1.4148 - val_loss: 3.6832 - val_u_decoder_loss: 0.5919 - val_f_decoder_loss: 0.2837 - val_f_decoder_1_loss: 0.4554 - val_u_decoder_1_loss: 1.4921\n",
      "Epoch 5/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 3.7031 - u_decoder_loss: 0.5059 - f_decoder_loss: 0.3327 - f_decoder_1_loss: 0.5375 - u_decoder_1_loss: 1.3466 - val_loss: 4.2497 - val_u_decoder_loss: 0.4892 - val_f_decoder_loss: 0.4709 - val_f_decoder_1_loss: 0.9809 - val_u_decoder_1_loss: 1.3400\n",
      "Epoch 6/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 4.3611 - u_decoder_loss: 0.4648 - f_decoder_loss: 0.4237 - f_decoder_1_loss: 0.7229 - u_decoder_1_loss: 1.3148 - val_loss: 4.3968 - val_u_decoder_loss: 0.4851 - val_f_decoder_loss: 0.4534 - val_f_decoder_1_loss: 0.7407 - val_u_decoder_1_loss: 1.4107\n",
      "Epoch 7/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 4.6909 - u_decoder_loss: 0.4744 - f_decoder_loss: 0.4053 - f_decoder_1_loss: 0.8647 - u_decoder_1_loss: 1.3882 - val_loss: 4.8168 - val_u_decoder_loss: 0.4112 - val_f_decoder_loss: 0.3184 - val_f_decoder_1_loss: 1.1179 - val_u_decoder_1_loss: 1.2026\n",
      "Epoch 8/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 4.1029 - u_decoder_loss: 0.4068 - f_decoder_loss: 0.3752 - f_decoder_1_loss: 0.8377 - u_decoder_1_loss: 1.2832 - val_loss: 3.3752 - val_u_decoder_loss: 0.4306 - val_f_decoder_loss: 0.2904 - val_f_decoder_1_loss: 0.4743 - val_u_decoder_1_loss: 1.4643\n",
      "Epoch 9/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 3.8857 - u_decoder_loss: 0.3894 - f_decoder_loss: 0.3684 - f_decoder_1_loss: 0.6643 - u_decoder_1_loss: 1.2329 - val_loss: 4.0512 - val_u_decoder_loss: 0.3587 - val_f_decoder_loss: 0.3458 - val_f_decoder_1_loss: 0.8163 - val_u_decoder_1_loss: 1.2353\n",
      "Epoch 10/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 3.7637 - u_decoder_loss: 0.4144 - f_decoder_loss: 0.3051 - f_decoder_1_loss: 0.6145 - u_decoder_1_loss: 1.3289 - val_loss: 3.8407 - val_u_decoder_loss: 0.3680 - val_f_decoder_loss: 0.2486 - val_f_decoder_1_loss: 0.8777 - val_u_decoder_1_loss: 1.2249\n",
      "Epoch 11/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 3.0837 - u_decoder_loss: 0.3572 - f_decoder_loss: 0.2493 - f_decoder_1_loss: 0.4986 - u_decoder_1_loss: 1.1811 - val_loss: 3.2325 - val_u_decoder_loss: 0.3676 - val_f_decoder_loss: 0.2599 - val_f_decoder_1_loss: 0.5110 - val_u_decoder_1_loss: 1.3417\n",
      "Epoch 12/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 3.3719 - u_decoder_loss: 0.3759 - f_decoder_loss: 0.2788 - f_decoder_1_loss: 0.5447 - u_decoder_1_loss: 1.2252 - val_loss: 2.7336 - val_u_decoder_loss: 0.3125 - val_f_decoder_loss: 0.2289 - val_f_decoder_1_loss: 0.4164 - val_u_decoder_1_loss: 1.1324\n",
      "Epoch 13/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 3.0588 - u_decoder_loss: 0.3362 - f_decoder_loss: 0.3154 - f_decoder_1_loss: 0.5291 - u_decoder_1_loss: 1.1970 - val_loss: 4.4306 - val_u_decoder_loss: 0.3683 - val_f_decoder_loss: 0.3676 - val_f_decoder_1_loss: 0.6751 - val_u_decoder_1_loss: 1.3437\n",
      "Epoch 14/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 5.0386 - u_decoder_loss: 0.3510 - f_decoder_loss: 0.4841 - f_decoder_1_loss: 0.9383 - u_decoder_1_loss: 1.2739 - val_loss: 2.7000 - val_u_decoder_loss: 0.3120 - val_f_decoder_loss: 0.1899 - val_f_decoder_1_loss: 0.4265 - val_u_decoder_1_loss: 1.1308\n",
      "Epoch 15/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.9739 - u_decoder_loss: 0.3094 - f_decoder_loss: 0.3368 - f_decoder_1_loss: 0.5076 - u_decoder_1_loss: 1.1534 - val_loss: 2.5455 - val_u_decoder_loss: 0.3356 - val_f_decoder_loss: 0.1502 - val_f_decoder_1_loss: 0.3182 - val_u_decoder_1_loss: 1.2002\n",
      "Epoch 16/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.5712 - u_decoder_loss: 0.3022 - f_decoder_loss: 0.2017 - f_decoder_1_loss: 0.4014 - u_decoder_1_loss: 1.0995 - val_loss: 2.9623 - val_u_decoder_loss: 0.2966 - val_f_decoder_loss: 0.2903 - val_f_decoder_1_loss: 0.4373 - val_u_decoder_1_loss: 1.2800\n",
      "Epoch 17/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 2.8535 - u_decoder_loss: 0.3098 - f_decoder_loss: 0.2536 - f_decoder_1_loss: 0.4680 - u_decoder_1_loss: 1.1093 - val_loss: 2.9356 - val_u_decoder_loss: 0.3091 - val_f_decoder_loss: 0.1867 - val_f_decoder_1_loss: 0.5264 - val_u_decoder_1_loss: 1.0951\n",
      "Epoch 18/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 3.3312 - u_decoder_loss: 0.3043 - f_decoder_loss: 0.3120 - f_decoder_1_loss: 0.5755 - u_decoder_1_loss: 1.2131 - val_loss: 2.4015 - val_u_decoder_loss: 0.3085 - val_f_decoder_loss: 0.1611 - val_f_decoder_1_loss: 0.3052 - val_u_decoder_1_loss: 1.0434\n",
      "Epoch 19/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4353 - u_decoder_loss: 0.2803 - f_decoder_loss: 0.1879 - f_decoder_1_loss: 0.3327 - u_decoder_1_loss: 1.0337 - val_loss: 2.2137 - val_u_decoder_loss: 0.2378 - val_f_decoder_loss: 0.1156 - val_f_decoder_1_loss: 0.2795 - val_u_decoder_1_loss: 1.0601\n",
      "Epoch 20/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4499 - u_decoder_loss: 0.2667 - f_decoder_loss: 0.1672 - f_decoder_1_loss: 0.3617 - u_decoder_1_loss: 1.0152 - val_loss: 2.9105 - val_u_decoder_loss: 0.3827 - val_f_decoder_loss: 0.1670 - val_f_decoder_1_loss: 0.4084 - val_u_decoder_1_loss: 1.3085\n",
      "Epoch 21/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 2.7300 - u_decoder_loss: 0.2890 - f_decoder_loss: 0.2375 - f_decoder_1_loss: 0.4183 - u_decoder_1_loss: 1.0351 - val_loss: 2.5145 - val_u_decoder_loss: 0.2777 - val_f_decoder_loss: 0.1764 - val_f_decoder_1_loss: 0.3175 - val_u_decoder_1_loss: 1.2034\n",
      "Epoch 22/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 2.8827 - u_decoder_loss: 0.2624 - f_decoder_loss: 0.3040 - f_decoder_1_loss: 0.5261 - u_decoder_1_loss: 1.0552 - val_loss: 3.0810 - val_u_decoder_loss: 0.3351 - val_f_decoder_loss: 0.2501 - val_f_decoder_1_loss: 0.4723 - val_u_decoder_1_loss: 1.0413\n",
      "Epoch 23/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 3.1400 - u_decoder_loss: 0.3050 - f_decoder_loss: 0.2060 - f_decoder_1_loss: 0.4919 - u_decoder_1_loss: 1.0430 - val_loss: 3.0888 - val_u_decoder_loss: 0.2616 - val_f_decoder_loss: 0.1672 - val_f_decoder_1_loss: 0.6571 - val_u_decoder_1_loss: 1.1109\n",
      "Epoch 24/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.3256 - u_decoder_loss: 0.2654 - f_decoder_loss: 0.1498 - f_decoder_1_loss: 0.3375 - u_decoder_1_loss: 1.0002 - val_loss: 1.8614 - val_u_decoder_loss: 0.2371 - val_f_decoder_loss: 0.0855 - val_f_decoder_1_loss: 0.2645 - val_u_decoder_1_loss: 0.8611\n",
      "Epoch 25/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 2.2355 - u_decoder_loss: 0.2687 - f_decoder_loss: 0.1376 - f_decoder_1_loss: 0.2560 - u_decoder_1_loss: 1.0689 - val_loss: 2.6036 - val_u_decoder_loss: 0.3715 - val_f_decoder_loss: 0.1686 - val_f_decoder_1_loss: 0.3361 - val_u_decoder_1_loss: 1.1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.8592 - u_decoder_loss: 0.2812 - f_decoder_loss: 0.2366 - f_decoder_1_loss: 0.4750 - u_decoder_1_loss: 1.0401 - val_loss: 2.6836 - val_u_decoder_loss: 0.2464 - val_f_decoder_loss: 0.2133 - val_f_decoder_1_loss: 0.6771 - val_u_decoder_1_loss: 0.8155\n",
      "Epoch 27/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4184 - u_decoder_loss: 0.2525 - f_decoder_loss: 0.1903 - f_decoder_1_loss: 0.3742 - u_decoder_1_loss: 0.9873 - val_loss: 2.4365 - val_u_decoder_loss: 0.2192 - val_f_decoder_loss: 0.1574 - val_f_decoder_1_loss: 0.3624 - val_u_decoder_1_loss: 1.1345\n",
      "Epoch 28/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.3029 - u_decoder_loss: 0.2411 - f_decoder_loss: 0.1772 - f_decoder_1_loss: 0.3183 - u_decoder_1_loss: 0.9816 - val_loss: 4.0160 - val_u_decoder_loss: 0.2895 - val_f_decoder_loss: 0.2655 - val_f_decoder_1_loss: 0.9758 - val_u_decoder_1_loss: 1.1759\n",
      "Epoch 29/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 2.5771 - u_decoder_loss: 0.2704 - f_decoder_loss: 0.1526 - f_decoder_1_loss: 0.3679 - u_decoder_1_loss: 1.1084 - val_loss: 2.3386 - val_u_decoder_loss: 0.2457 - val_f_decoder_loss: 0.2186 - val_f_decoder_1_loss: 0.3256 - val_u_decoder_1_loss: 1.0018\n",
      "Epoch 30/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.8596 - u_decoder_loss: 0.2389 - f_decoder_loss: 0.3088 - f_decoder_1_loss: 0.6164 - u_decoder_1_loss: 0.9702 - val_loss: 2.4589 - val_u_decoder_loss: 0.2292 - val_f_decoder_loss: 0.1806 - val_f_decoder_1_loss: 0.4377 - val_u_decoder_1_loss: 0.9941\n",
      "Epoch 31/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.4588 - u_decoder_loss: 0.2599 - f_decoder_loss: 0.1926 - f_decoder_1_loss: 0.3518 - u_decoder_1_loss: 1.0480 - val_loss: 2.7141 - val_u_decoder_loss: 0.2537 - val_f_decoder_loss: 0.1888 - val_f_decoder_1_loss: 0.4937 - val_u_decoder_1_loss: 0.9862\n",
      "Epoch 32/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.6627 - u_decoder_loss: 0.2572 - f_decoder_loss: 0.1775 - f_decoder_1_loss: 0.3433 - u_decoder_1_loss: 1.0800 - val_loss: 2.5707 - val_u_decoder_loss: 0.2514 - val_f_decoder_loss: 0.1695 - val_f_decoder_1_loss: 0.3669 - val_u_decoder_1_loss: 1.0873\n",
      "Epoch 33/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4030 - u_decoder_loss: 0.2249 - f_decoder_loss: 0.2119 - f_decoder_1_loss: 0.3568 - u_decoder_1_loss: 0.9938 - val_loss: 2.8520 - val_u_decoder_loss: 0.2333 - val_f_decoder_loss: 0.1563 - val_f_decoder_1_loss: 0.5408 - val_u_decoder_1_loss: 1.2188\n",
      "Epoch 34/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.5541 - u_decoder_loss: 0.2307 - f_decoder_loss: 0.2092 - f_decoder_1_loss: 0.4562 - u_decoder_1_loss: 0.9434 - val_loss: 3.5338 - val_u_decoder_loss: 0.3330 - val_f_decoder_loss: 0.2379 - val_f_decoder_1_loss: 0.5732 - val_u_decoder_1_loss: 1.4229\n",
      "Epoch 35/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.3542 - u_decoder_loss: 0.2360 - f_decoder_loss: 0.1492 - f_decoder_1_loss: 0.3842 - u_decoder_1_loss: 0.9864 - val_loss: 2.2048 - val_u_decoder_loss: 0.2175 - val_f_decoder_loss: 0.1729 - val_f_decoder_1_loss: 0.3787 - val_u_decoder_1_loss: 0.8978\n",
      "Epoch 36/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.1887 - u_decoder_loss: 0.2219 - f_decoder_loss: 0.1506 - f_decoder_1_loss: 0.3056 - u_decoder_1_loss: 0.9279 - val_loss: 1.9556 - val_u_decoder_loss: 0.2088 - val_f_decoder_loss: 0.1046 - val_f_decoder_1_loss: 0.2733 - val_u_decoder_1_loss: 0.7892\n",
      "Epoch 37/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 2.4140 - u_decoder_loss: 0.2537 - f_decoder_loss: 0.1731 - f_decoder_1_loss: 0.3573 - u_decoder_1_loss: 1.0079 - val_loss: 3.0040 - val_u_decoder_loss: 0.3603 - val_f_decoder_loss: 0.1774 - val_f_decoder_1_loss: 0.4831 - val_u_decoder_1_loss: 1.0774\n",
      "Epoch 38/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.3560 - u_decoder_loss: 0.2277 - f_decoder_loss: 0.2138 - f_decoder_1_loss: 0.4509 - u_decoder_1_loss: 0.8753 - val_loss: 3.3635 - val_u_decoder_loss: 0.2769 - val_f_decoder_loss: 0.2098 - val_f_decoder_1_loss: 0.7283 - val_u_decoder_1_loss: 1.2978\n",
      "Epoch 39/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 2.4350 - u_decoder_loss: 0.2150 - f_decoder_loss: 0.1666 - f_decoder_1_loss: 0.4450 - u_decoder_1_loss: 0.9180 - val_loss: 3.0222 - val_u_decoder_loss: 0.3281 - val_f_decoder_loss: 0.2226 - val_f_decoder_1_loss: 0.4358 - val_u_decoder_1_loss: 1.4038\n",
      "Epoch 40/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.9655 - u_decoder_loss: 0.2181 - f_decoder_loss: 0.1119 - f_decoder_1_loss: 0.2316 - u_decoder_1_loss: 0.8868 - val_loss: 1.9646 - val_u_decoder_loss: 0.2010 - val_f_decoder_loss: 0.0773 - val_f_decoder_1_loss: 0.2850 - val_u_decoder_1_loss: 0.8919\n",
      "Epoch 41/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 2.2871 - u_decoder_loss: 0.2308 - f_decoder_loss: 0.1757 - f_decoder_1_loss: 0.3250 - u_decoder_1_loss: 0.9539 - val_loss: 2.3203 - val_u_decoder_loss: 0.2694 - val_f_decoder_loss: 0.1731 - val_f_decoder_1_loss: 0.3145 - val_u_decoder_1_loss: 0.9887\n",
      "Epoch 42/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 2.5045 - u_decoder_loss: 0.2427 - f_decoder_loss: 0.1825 - f_decoder_1_loss: 0.3511 - u_decoder_1_loss: 1.0408 - val_loss: 2.0520 - val_u_decoder_loss: 0.2523 - val_f_decoder_loss: 0.1413 - val_f_decoder_1_loss: 0.3626 - val_u_decoder_1_loss: 0.7991\n",
      "Epoch 43/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.7534 - u_decoder_loss: 0.1872 - f_decoder_loss: 0.1459 - f_decoder_1_loss: 0.2368 - u_decoder_1_loss: 0.7856 - val_loss: 1.6907 - val_u_decoder_loss: 0.1759 - val_f_decoder_loss: 0.0883 - val_f_decoder_1_loss: 0.2256 - val_u_decoder_1_loss: 0.8612\n",
      "Epoch 44/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.5166 - u_decoder_loss: 0.1705 - f_decoder_loss: 0.0748 - f_decoder_1_loss: 0.1438 - u_decoder_1_loss: 0.7905 - val_loss: 2.2588 - val_u_decoder_loss: 0.2044 - val_f_decoder_loss: 0.1339 - val_f_decoder_1_loss: 0.3294 - val_u_decoder_1_loss: 1.0664\n",
      "Epoch 45/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 2.5930 - u_decoder_loss: 0.2102 - f_decoder_loss: 0.3881 - f_decoder_1_loss: 0.6082 - u_decoder_1_loss: 0.8579 - val_loss: 2.9268 - val_u_decoder_loss: 0.3057 - val_f_decoder_loss: 0.2045 - val_f_decoder_1_loss: 0.4734 - val_u_decoder_1_loss: 1.1205\n",
      "Epoch 46/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4702 - u_decoder_loss: 0.2343 - f_decoder_loss: 0.1762 - f_decoder_1_loss: 0.4270 - u_decoder_1_loss: 0.9592 - val_loss: 2.6122 - val_u_decoder_loss: 0.1930 - val_f_decoder_loss: 0.1518 - val_f_decoder_1_loss: 0.6339 - val_u_decoder_1_loss: 0.8770\n",
      "Epoch 47/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 2.0455 - u_decoder_loss: 0.2037 - f_decoder_loss: 0.1399 - f_decoder_1_loss: 0.3268 - u_decoder_1_loss: 0.8902 - val_loss: 1.9642 - val_u_decoder_loss: 0.1908 - val_f_decoder_loss: 0.1111 - val_f_decoder_1_loss: 0.3876 - val_u_decoder_1_loss: 0.7753\n",
      "Epoch 48/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.7629 - u_decoder_loss: 0.1815 - f_decoder_loss: 0.0968 - f_decoder_1_loss: 0.2192 - u_decoder_1_loss: 0.8316 - val_loss: 1.9021 - val_u_decoder_loss: 0.1908 - val_f_decoder_loss: 0.0976 - val_f_decoder_1_loss: 0.2220 - val_u_decoder_1_loss: 0.9756\n",
      "Epoch 49/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.8752 - u_decoder_loss: 0.2161 - f_decoder_loss: 0.1001 - f_decoder_1_loss: 0.1880 - u_decoder_1_loss: 0.9361 - val_loss: 2.1954 - val_u_decoder_loss: 0.2481 - val_f_decoder_loss: 0.1415 - val_f_decoder_1_loss: 0.3580 - val_u_decoder_1_loss: 0.9701\n",
      "Epoch 50/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.4310 - u_decoder_loss: 0.2223 - f_decoder_loss: 0.2561 - f_decoder_1_loss: 0.5424 - u_decoder_1_loss: 0.8322 - val_loss: 1.9723 - val_u_decoder_loss: 0.1787 - val_f_decoder_loss: 0.1318 - val_f_decoder_1_loss: 0.2912 - val_u_decoder_1_loss: 0.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 2.2556 - u_decoder_loss: 0.1720 - f_decoder_loss: 0.1840 - f_decoder_1_loss: 0.4452 - u_decoder_1_loss: 0.7429 - val_loss: 2.5635 - val_u_decoder_loss: 0.2144 - val_f_decoder_loss: 0.1199 - val_f_decoder_1_loss: 0.4180 - val_u_decoder_1_loss: 1.1876\n",
      "Epoch 52/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.9126 - u_decoder_loss: 0.2142 - f_decoder_loss: 0.1063 - f_decoder_1_loss: 0.2116 - u_decoder_1_loss: 0.8635 - val_loss: 2.0952 - val_u_decoder_loss: 0.1824 - val_f_decoder_loss: 0.0662 - val_f_decoder_1_loss: 0.2282 - val_u_decoder_1_loss: 1.2357\n",
      "Epoch 53/500\n",
      "4798/4798 [==============================] - 1s 191us/sample - loss: 1.9568 - u_decoder_loss: 0.1703 - f_decoder_loss: 0.1267 - f_decoder_1_loss: 0.3614 - u_decoder_1_loss: 0.7985 - val_loss: 2.6688 - val_u_decoder_loss: 0.2061 - val_f_decoder_loss: 0.2081 - val_f_decoder_1_loss: 0.5482 - val_u_decoder_1_loss: 1.1524\n",
      "Epoch 54/500\n",
      "4798/4798 [==============================] - 1s 190us/sample - loss: 2.0426 - u_decoder_loss: 0.1862 - f_decoder_loss: 0.1522 - f_decoder_1_loss: 0.3232 - u_decoder_1_loss: 0.8541 - val_loss: 1.9266 - val_u_decoder_loss: 0.2017 - val_f_decoder_loss: 0.0991 - val_f_decoder_1_loss: 0.3371 - val_u_decoder_1_loss: 0.8250\n",
      "Epoch 55/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 1.6039 - u_decoder_loss: 0.1785 - f_decoder_loss: 0.0954 - f_decoder_1_loss: 0.1990 - u_decoder_1_loss: 0.7876 - val_loss: 1.4637 - val_u_decoder_loss: 0.1571 - val_f_decoder_loss: 0.0536 - val_f_decoder_1_loss: 0.1875 - val_u_decoder_1_loss: 0.7437\n",
      "Epoch 56/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.9174 - u_decoder_loss: 0.1963 - f_decoder_loss: 0.1288 - f_decoder_1_loss: 0.2632 - u_decoder_1_loss: 0.8380 - val_loss: 1.7264 - val_u_decoder_loss: 0.1617 - val_f_decoder_loss: 0.1017 - val_f_decoder_1_loss: 0.3097 - val_u_decoder_1_loss: 0.7546\n",
      "Epoch 57/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 2.1928 - u_decoder_loss: 0.1840 - f_decoder_loss: 0.1951 - f_decoder_1_loss: 0.4836 - u_decoder_1_loss: 0.8103 - val_loss: 3.3321 - val_u_decoder_loss: 0.1890 - val_f_decoder_loss: 0.2726 - val_f_decoder_1_loss: 1.0424 - val_u_decoder_1_loss: 0.7795\n",
      "Epoch 58/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.1588 - u_decoder_loss: 0.2286 - f_decoder_loss: 0.1556 - f_decoder_1_loss: 0.3041 - u_decoder_1_loss: 0.8873 - val_loss: 2.2412 - val_u_decoder_loss: 0.2682 - val_f_decoder_loss: 0.1399 - val_f_decoder_1_loss: 0.2271 - val_u_decoder_1_loss: 1.0719\n",
      "Epoch 59/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.8410 - u_decoder_loss: 0.1931 - f_decoder_loss: 0.1112 - f_decoder_1_loss: 0.2129 - u_decoder_1_loss: 0.8922 - val_loss: 1.8504 - val_u_decoder_loss: 0.1936 - val_f_decoder_loss: 0.1095 - val_f_decoder_1_loss: 0.2908 - val_u_decoder_1_loss: 0.8553\n",
      "Epoch 60/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.6009 - u_decoder_loss: 0.1601 - f_decoder_loss: 0.1090 - f_decoder_1_loss: 0.2003 - u_decoder_1_loss: 0.7647 - val_loss: 2.1555 - val_u_decoder_loss: 0.1898 - val_f_decoder_loss: 0.0803 - val_f_decoder_1_loss: 0.3175 - val_u_decoder_1_loss: 1.0855\n",
      "Epoch 61/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.8752 - u_decoder_loss: 0.1903 - f_decoder_loss: 0.1425 - f_decoder_1_loss: 0.3008 - u_decoder_1_loss: 0.8229 - val_loss: 1.5591 - val_u_decoder_loss: 0.1168 - val_f_decoder_loss: 0.1671 - val_f_decoder_1_loss: 0.2856 - val_u_decoder_1_loss: 0.6409\n",
      "Epoch 62/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.9895 - u_decoder_loss: 0.1767 - f_decoder_loss: 0.1633 - f_decoder_1_loss: 0.2791 - u_decoder_1_loss: 0.7915 - val_loss: 2.1925 - val_u_decoder_loss: 0.1525 - val_f_decoder_loss: 0.1573 - val_f_decoder_1_loss: 0.3231 - val_u_decoder_1_loss: 1.0957\n",
      "Epoch 63/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.8595 - u_decoder_loss: 0.1652 - f_decoder_loss: 0.1598 - f_decoder_1_loss: 0.3713 - u_decoder_1_loss: 0.7253 - val_loss: 1.5790 - val_u_decoder_loss: 0.1464 - val_f_decoder_loss: 0.0953 - val_f_decoder_1_loss: 0.2522 - val_u_decoder_1_loss: 0.7131\n",
      "Epoch 64/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.7705 - u_decoder_loss: 0.1939 - f_decoder_loss: 0.1019 - f_decoder_1_loss: 0.1647 - u_decoder_1_loss: 0.8617 - val_loss: 1.8002 - val_u_decoder_loss: 0.1902 - val_f_decoder_loss: 0.1145 - val_f_decoder_1_loss: 0.2897 - val_u_decoder_1_loss: 0.7822\n",
      "Epoch 65/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5897 - u_decoder_loss: 0.1536 - f_decoder_loss: 0.1276 - f_decoder_1_loss: 0.2215 - u_decoder_1_loss: 0.7337 - val_loss: 1.9415 - val_u_decoder_loss: 0.1993 - val_f_decoder_loss: 0.1211 - val_f_decoder_1_loss: 0.3812 - val_u_decoder_1_loss: 0.8624\n",
      "Epoch 66/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.6798 - u_decoder_loss: 0.1577 - f_decoder_loss: 0.1105 - f_decoder_1_loss: 0.3370 - u_decoder_1_loss: 0.6825 - val_loss: 1.9013 - val_u_decoder_loss: 0.1893 - val_f_decoder_loss: 0.1016 - val_f_decoder_1_loss: 0.3633 - val_u_decoder_1_loss: 0.8719\n",
      "Epoch 67/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 2.2658 - u_decoder_loss: 0.2216 - f_decoder_loss: 0.1502 - f_decoder_1_loss: 0.3140 - u_decoder_1_loss: 0.9185 - val_loss: 3.0583 - val_u_decoder_loss: 0.1914 - val_f_decoder_loss: 0.1363 - val_f_decoder_1_loss: 0.6459 - val_u_decoder_1_loss: 0.8239\n",
      "Epoch 68/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.7105 - u_decoder_loss: 0.1565 - f_decoder_loss: 0.1224 - f_decoder_1_loss: 0.2464 - u_decoder_1_loss: 0.7230 - val_loss: 1.6828 - val_u_decoder_loss: 0.1548 - val_f_decoder_loss: 0.0853 - val_f_decoder_1_loss: 0.3105 - val_u_decoder_1_loss: 0.7867\n",
      "Epoch 69/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.7140 - u_decoder_loss: 0.1520 - f_decoder_loss: 0.1278 - f_decoder_1_loss: 0.3012 - u_decoder_1_loss: 0.7702 - val_loss: 1.7179 - val_u_decoder_loss: 0.1509 - val_f_decoder_loss: 0.0639 - val_f_decoder_1_loss: 0.4166 - val_u_decoder_1_loss: 0.7148\n",
      "Epoch 70/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.5925 - u_decoder_loss: 0.1732 - f_decoder_loss: 0.0933 - f_decoder_1_loss: 0.1809 - u_decoder_1_loss: 0.7874 - val_loss: 1.4685 - val_u_decoder_loss: 0.1346 - val_f_decoder_loss: 0.0474 - val_f_decoder_1_loss: 0.2153 - val_u_decoder_1_loss: 0.6866\n",
      "Epoch 71/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.7758 - u_decoder_loss: 0.1836 - f_decoder_loss: 0.1016 - f_decoder_1_loss: 0.2501 - u_decoder_1_loss: 0.7643 - val_loss: 1.9844 - val_u_decoder_loss: 0.1833 - val_f_decoder_loss: 0.1034 - val_f_decoder_1_loss: 0.6075 - val_u_decoder_1_loss: 0.5958\n",
      "Epoch 72/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.7339 - u_decoder_loss: 0.1431 - f_decoder_loss: 0.1852 - f_decoder_1_loss: 0.3164 - u_decoder_1_loss: 0.7279 - val_loss: 1.8279 - val_u_decoder_loss: 0.1597 - val_f_decoder_loss: 0.1704 - val_f_decoder_1_loss: 0.3449 - val_u_decoder_1_loss: 0.7410\n",
      "Epoch 73/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.7532 - u_decoder_loss: 0.1424 - f_decoder_loss: 0.1602 - f_decoder_1_loss: 0.3380 - u_decoder_1_loss: 0.6856 - val_loss: 1.6295 - val_u_decoder_loss: 0.1566 - val_f_decoder_loss: 0.1110 - val_f_decoder_1_loss: 0.3118 - val_u_decoder_1_loss: 0.6823\n",
      "Epoch 74/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4107 - u_decoder_loss: 0.1599 - f_decoder_loss: 0.0974 - f_decoder_1_loss: 0.1998 - u_decoder_1_loss: 0.6368 - val_loss: 1.2652 - val_u_decoder_loss: 0.1050 - val_f_decoder_loss: 0.0529 - val_f_decoder_1_loss: 0.2373 - val_u_decoder_1_loss: 0.5947\n",
      "Epoch 75/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.2712 - u_decoder_loss: 0.1280 - f_decoder_loss: 0.0748 - f_decoder_1_loss: 0.1227 - u_decoder_1_loss: 0.6586 - val_loss: 1.5124 - val_u_decoder_loss: 0.1486 - val_f_decoder_loss: 0.0729 - val_f_decoder_1_loss: 0.2093 - val_u_decoder_1_loss: 0.8212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.6827 - u_decoder_loss: 0.1677 - f_decoder_loss: 0.1259 - f_decoder_1_loss: 0.2286 - u_decoder_1_loss: 0.7653 - val_loss: 1.6731 - val_u_decoder_loss: 0.1786 - val_f_decoder_loss: 0.1210 - val_f_decoder_1_loss: 0.2730 - val_u_decoder_1_loss: 0.7557\n",
      "Epoch 77/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.6974 - u_decoder_loss: 0.1706 - f_decoder_loss: 0.1263 - f_decoder_1_loss: 0.2481 - u_decoder_1_loss: 0.7759 - val_loss: 3.1466 - val_u_decoder_loss: 0.5644 - val_f_decoder_loss: 0.1516 - val_f_decoder_1_loss: 0.6344 - val_u_decoder_1_loss: 1.1062\n",
      "Epoch 78/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.6867 - u_decoder_loss: 0.1778 - f_decoder_loss: 0.1206 - f_decoder_1_loss: 0.2797 - u_decoder_1_loss: 0.6902 - val_loss: 2.8677 - val_u_decoder_loss: 0.1265 - val_f_decoder_loss: 0.1042 - val_f_decoder_1_loss: 0.6304 - val_u_decoder_1_loss: 0.6728\n",
      "Epoch 79/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.8346 - u_decoder_loss: 0.1516 - f_decoder_loss: 0.1548 - f_decoder_1_loss: 0.3317 - u_decoder_1_loss: 0.7680 - val_loss: 2.3088 - val_u_decoder_loss: 0.1841 - val_f_decoder_loss: 0.1240 - val_f_decoder_1_loss: 0.2665 - val_u_decoder_1_loss: 0.9794\n",
      "Epoch 80/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.8306 - u_decoder_loss: 0.1588 - f_decoder_loss: 0.1815 - f_decoder_1_loss: 0.3273 - u_decoder_1_loss: 0.7019 - val_loss: 2.1971 - val_u_decoder_loss: 0.1408 - val_f_decoder_loss: 0.1909 - val_f_decoder_1_loss: 0.5691 - val_u_decoder_1_loss: 0.6694\n",
      "Epoch 81/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.4159 - u_decoder_loss: 0.1341 - f_decoder_loss: 0.0853 - f_decoder_1_loss: 0.2134 - u_decoder_1_loss: 0.6649 - val_loss: 1.3482 - val_u_decoder_loss: 0.1459 - val_f_decoder_loss: 0.0456 - val_f_decoder_1_loss: 0.2142 - val_u_decoder_1_loss: 0.6888\n",
      "Epoch 82/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5245 - u_decoder_loss: 0.1507 - f_decoder_loss: 0.0928 - f_decoder_1_loss: 0.2286 - u_decoder_1_loss: 0.7179 - val_loss: 1.5840 - val_u_decoder_loss: 0.2016 - val_f_decoder_loss: 0.0786 - val_f_decoder_1_loss: 0.2053 - val_u_decoder_1_loss: 0.7783\n",
      "Epoch 83/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.6071 - u_decoder_loss: 0.1488 - f_decoder_loss: 0.1072 - f_decoder_1_loss: 0.2049 - u_decoder_1_loss: 0.7951 - val_loss: 1.9937 - val_u_decoder_loss: 0.1934 - val_f_decoder_loss: 0.0934 - val_f_decoder_1_loss: 0.3073 - val_u_decoder_1_loss: 0.9848\n",
      "Epoch 84/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.3270 - u_decoder_loss: 0.1516 - f_decoder_loss: 0.0694 - f_decoder_1_loss: 0.1379 - u_decoder_1_loss: 0.6480 - val_loss: 1.8069 - val_u_decoder_loss: 0.1572 - val_f_decoder_loss: 0.0766 - val_f_decoder_1_loss: 0.3566 - val_u_decoder_1_loss: 0.7264\n",
      "Epoch 85/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.6395 - u_decoder_loss: 0.1448 - f_decoder_loss: 0.1051 - f_decoder_1_loss: 0.2622 - u_decoder_1_loss: 0.6911 - val_loss: 1.7105 - val_u_decoder_loss: 0.2252 - val_f_decoder_loss: 0.1020 - val_f_decoder_1_loss: 0.2684 - val_u_decoder_1_loss: 0.8092\n",
      "Epoch 86/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.5524 - u_decoder_loss: 0.1437 - f_decoder_loss: 0.1163 - f_decoder_1_loss: 0.2219 - u_decoder_1_loss: 0.7033 - val_loss: 1.5888 - val_u_decoder_loss: 0.1523 - val_f_decoder_loss: 0.1178 - val_f_decoder_1_loss: 0.2108 - val_u_decoder_1_loss: 0.7299\n",
      "Epoch 87/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.5749 - u_decoder_loss: 0.1617 - f_decoder_loss: 0.1012 - f_decoder_1_loss: 0.2083 - u_decoder_1_loss: 0.7419 - val_loss: 2.1984 - val_u_decoder_loss: 0.2545 - val_f_decoder_loss: 0.0994 - val_f_decoder_1_loss: 0.4123 - val_u_decoder_1_loss: 0.9988\n",
      "Epoch 88/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.5009 - u_decoder_loss: 0.1380 - f_decoder_loss: 0.1238 - f_decoder_1_loss: 0.2335 - u_decoder_1_loss: 0.6690 - val_loss: 1.4816 - val_u_decoder_loss: 0.1231 - val_f_decoder_loss: 0.1226 - val_f_decoder_1_loss: 0.2179 - val_u_decoder_1_loss: 0.7462\n",
      "Epoch 89/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.5436 - u_decoder_loss: 0.1454 - f_decoder_loss: 0.1221 - f_decoder_1_loss: 0.2451 - u_decoder_1_loss: 0.6938 - val_loss: 1.8605 - val_u_decoder_loss: 0.1918 - val_f_decoder_loss: 0.0917 - val_f_decoder_1_loss: 0.2853 - val_u_decoder_1_loss: 0.8761\n",
      "Epoch 90/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.6513 - u_decoder_loss: 0.1568 - f_decoder_loss: 0.1654 - f_decoder_1_loss: 0.2314 - u_decoder_1_loss: 0.6892 - val_loss: 1.6984 - val_u_decoder_loss: 0.2058 - val_f_decoder_loss: 0.0874 - val_f_decoder_1_loss: 0.2439 - val_u_decoder_1_loss: 0.6822\n",
      "Epoch 91/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.6292 - u_decoder_loss: 0.1460 - f_decoder_loss: 0.1529 - f_decoder_1_loss: 0.2927 - u_decoder_1_loss: 0.6728 - val_loss: 2.1328 - val_u_decoder_loss: 0.2113 - val_f_decoder_loss: 0.1535 - val_f_decoder_1_loss: 0.4482 - val_u_decoder_1_loss: 0.7805\n",
      "Epoch 92/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.6385 - u_decoder_loss: 0.1303 - f_decoder_loss: 0.1284 - f_decoder_1_loss: 0.3055 - u_decoder_1_loss: 0.6245 - val_loss: 1.5931 - val_u_decoder_loss: 0.1316 - val_f_decoder_loss: 0.0561 - val_f_decoder_1_loss: 0.2754 - val_u_decoder_1_loss: 0.7011\n",
      "Epoch 93/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.3903 - u_decoder_loss: 0.1378 - f_decoder_loss: 0.0751 - f_decoder_1_loss: 0.1865 - u_decoder_1_loss: 0.6753 - val_loss: 1.4822 - val_u_decoder_loss: 0.1213 - val_f_decoder_loss: 0.0933 - val_f_decoder_1_loss: 0.1921 - val_u_decoder_1_loss: 0.7753\n",
      "Epoch 94/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5118 - u_decoder_loss: 0.1499 - f_decoder_loss: 0.1244 - f_decoder_1_loss: 0.2626 - u_decoder_1_loss: 0.6340 - val_loss: 1.8623 - val_u_decoder_loss: 0.1661 - val_f_decoder_loss: 0.1456 - val_f_decoder_1_loss: 0.4794 - val_u_decoder_1_loss: 0.6461\n",
      "Epoch 95/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.3502 - u_decoder_loss: 0.1248 - f_decoder_loss: 0.0948 - f_decoder_1_loss: 0.2236 - u_decoder_1_loss: 0.6338 - val_loss: 1.2489 - val_u_decoder_loss: 0.1360 - val_f_decoder_loss: 0.0836 - val_f_decoder_1_loss: 0.2234 - val_u_decoder_1_loss: 0.5601\n",
      "Epoch 96/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.2342 - u_decoder_loss: 0.1332 - f_decoder_loss: 0.0625 - f_decoder_1_loss: 0.1378 - u_decoder_1_loss: 0.6338 - val_loss: 2.0453 - val_u_decoder_loss: 0.2037 - val_f_decoder_loss: 0.1731 - val_f_decoder_1_loss: 0.3138 - val_u_decoder_1_loss: 0.9694\n",
      "Epoch 97/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.3836 - u_decoder_loss: 0.1503 - f_decoder_loss: 0.1038 - f_decoder_1_loss: 0.1768 - u_decoder_1_loss: 0.6230 - val_loss: 1.6851 - val_u_decoder_loss: 0.1620 - val_f_decoder_loss: 0.0760 - val_f_decoder_1_loss: 0.3242 - val_u_decoder_1_loss: 0.7643\n",
      "Epoch 98/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4491 - u_decoder_loss: 0.1353 - f_decoder_loss: 0.1064 - f_decoder_1_loss: 0.2485 - u_decoder_1_loss: 0.6296 - val_loss: 1.5302 - val_u_decoder_loss: 0.1429 - val_f_decoder_loss: 0.0804 - val_f_decoder_1_loss: 0.1766 - val_u_decoder_1_loss: 0.7810\n",
      "Epoch 99/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.4074 - u_decoder_loss: 0.1263 - f_decoder_loss: 0.1047 - f_decoder_1_loss: 0.1894 - u_decoder_1_loss: 0.6619 - val_loss: 1.3914 - val_u_decoder_loss: 0.1696 - val_f_decoder_loss: 0.0389 - val_f_decoder_1_loss: 0.1660 - val_u_decoder_1_loss: 0.7642\n",
      "Epoch 100/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4805 - u_decoder_loss: 0.1448 - f_decoder_loss: 0.0829 - f_decoder_1_loss: 0.1934 - u_decoder_1_loss: 0.7526 - val_loss: 1.6480 - val_u_decoder_loss: 0.2465 - val_f_decoder_loss: 0.0691 - val_f_decoder_1_loss: 0.2615 - val_u_decoder_1_loss: 0.7717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 2.2392 - u_decoder_loss: 0.1721 - f_decoder_loss: 0.1523 - f_decoder_1_loss: 0.4516 - u_decoder_1_loss: 0.7632 - val_loss: 1.7505 - val_u_decoder_loss: 0.1797 - val_f_decoder_loss: 0.1341 - val_f_decoder_1_loss: 0.3339 - val_u_decoder_1_loss: 0.7651\n",
      "Epoch 102/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.2183 - u_decoder_loss: 0.1144 - f_decoder_loss: 0.0821 - f_decoder_1_loss: 0.1606 - u_decoder_1_loss: 0.5939 - val_loss: 1.3176 - val_u_decoder_loss: 0.1389 - val_f_decoder_loss: 0.0703 - val_f_decoder_1_loss: 0.1892 - val_u_decoder_1_loss: 0.6945\n",
      "Epoch 103/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.3663 - u_decoder_loss: 0.1404 - f_decoder_loss: 0.0724 - f_decoder_1_loss: 0.1376 - u_decoder_1_loss: 0.7116 - val_loss: 1.4609 - val_u_decoder_loss: 0.1395 - val_f_decoder_loss: 0.0679 - val_f_decoder_1_loss: 0.3249 - val_u_decoder_1_loss: 0.6352\n",
      "Epoch 104/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 1.4406 - u_decoder_loss: 0.1347 - f_decoder_loss: 0.1022 - f_decoder_1_loss: 0.1746 - u_decoder_1_loss: 0.6893 - val_loss: 1.7620 - val_u_decoder_loss: 0.2034 - val_f_decoder_loss: 0.0703 - val_f_decoder_1_loss: 0.2977 - val_u_decoder_1_loss: 0.7606\n",
      "Epoch 105/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.2686 - u_decoder_loss: 0.1221 - f_decoder_loss: 0.0806 - f_decoder_1_loss: 0.1699 - u_decoder_1_loss: 0.6247 - val_loss: 1.2236 - val_u_decoder_loss: 0.1215 - val_f_decoder_loss: 0.0561 - val_f_decoder_1_loss: 0.1716 - val_u_decoder_1_loss: 0.6338\n",
      "Epoch 106/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.4457 - u_decoder_loss: 0.1467 - f_decoder_loss: 0.1066 - f_decoder_1_loss: 0.2264 - u_decoder_1_loss: 0.6639 - val_loss: 1.8534 - val_u_decoder_loss: 0.1454 - val_f_decoder_loss: 0.2493 - val_f_decoder_1_loss: 0.4484 - val_u_decoder_1_loss: 0.6047\n",
      "Epoch 107/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.5413 - u_decoder_loss: 0.1247 - f_decoder_loss: 0.1396 - f_decoder_1_loss: 0.2298 - u_decoder_1_loss: 0.6398 - val_loss: 1.6250 - val_u_decoder_loss: 0.1374 - val_f_decoder_loss: 0.1189 - val_f_decoder_1_loss: 0.3338 - val_u_decoder_1_loss: 0.6754\n",
      "Epoch 108/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.7480 - u_decoder_loss: 0.1311 - f_decoder_loss: 0.1170 - f_decoder_1_loss: 0.3545 - u_decoder_1_loss: 0.6481 - val_loss: 1.4971 - val_u_decoder_loss: 0.1326 - val_f_decoder_loss: 0.0492 - val_f_decoder_1_loss: 0.3055 - val_u_decoder_1_loss: 0.6821\n",
      "Epoch 109/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2757 - u_decoder_loss: 0.1234 - f_decoder_loss: 0.0742 - f_decoder_1_loss: 0.1333 - u_decoder_1_loss: 0.6717 - val_loss: 2.1044 - val_u_decoder_loss: 0.1477 - val_f_decoder_loss: 0.0583 - val_f_decoder_1_loss: 0.2232 - val_u_decoder_1_loss: 1.3275\n",
      "Epoch 110/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5207 - u_decoder_loss: 0.1387 - f_decoder_loss: 0.1390 - f_decoder_1_loss: 0.2718 - u_decoder_1_loss: 0.6493 - val_loss: 1.7575 - val_u_decoder_loss: 0.2286 - val_f_decoder_loss: 0.0792 - val_f_decoder_1_loss: 0.3978 - val_u_decoder_1_loss: 0.7450\n",
      "Epoch 111/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 2.1016 - u_decoder_loss: 0.1973 - f_decoder_loss: 0.2224 - f_decoder_1_loss: 0.5023 - u_decoder_1_loss: 0.6886 - val_loss: 1.4787 - val_u_decoder_loss: 0.1441 - val_f_decoder_loss: 0.1720 - val_f_decoder_1_loss: 0.2971 - val_u_decoder_1_loss: 0.5920\n",
      "Epoch 112/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.3799 - u_decoder_loss: 0.1453 - f_decoder_loss: 0.0904 - f_decoder_1_loss: 0.1938 - u_decoder_1_loss: 0.6342 - val_loss: 2.0281 - val_u_decoder_loss: 0.1574 - val_f_decoder_loss: 0.0714 - val_f_decoder_1_loss: 0.2771 - val_u_decoder_1_loss: 1.0801\n",
      "Epoch 113/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.3025 - u_decoder_loss: 0.1368 - f_decoder_loss: 0.0668 - f_decoder_1_loss: 0.1100 - u_decoder_1_loss: 0.6983 - val_loss: 1.3192 - val_u_decoder_loss: 0.1673 - val_f_decoder_loss: 0.0688 - val_f_decoder_1_loss: 0.2105 - val_u_decoder_1_loss: 0.6338\n",
      "Epoch 114/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.2125 - u_decoder_loss: 0.1193 - f_decoder_loss: 0.0787 - f_decoder_1_loss: 0.1569 - u_decoder_1_loss: 0.5824 - val_loss: 1.2403 - val_u_decoder_loss: 0.1251 - val_f_decoder_loss: 0.0518 - val_f_decoder_1_loss: 0.2047 - val_u_decoder_1_loss: 0.6648\n",
      "Epoch 115/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.1995 - u_decoder_loss: 0.1172 - f_decoder_loss: 0.0617 - f_decoder_1_loss: 0.1024 - u_decoder_1_loss: 0.6640 - val_loss: 1.7895 - val_u_decoder_loss: 0.1831 - val_f_decoder_loss: 0.0840 - val_f_decoder_1_loss: 0.2783 - val_u_decoder_1_loss: 0.9565\n",
      "Epoch 116/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4573 - u_decoder_loss: 0.1460 - f_decoder_loss: 0.1009 - f_decoder_1_loss: 0.1820 - u_decoder_1_loss: 0.7062 - val_loss: 1.3075 - val_u_decoder_loss: 0.1172 - val_f_decoder_loss: 0.0652 - val_f_decoder_1_loss: 0.2363 - val_u_decoder_1_loss: 0.6508\n",
      "Epoch 117/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.3176 - u_decoder_loss: 0.1194 - f_decoder_loss: 0.0891 - f_decoder_1_loss: 0.1548 - u_decoder_1_loss: 0.6683 - val_loss: 1.4492 - val_u_decoder_loss: 0.1483 - val_f_decoder_loss: 0.0804 - val_f_decoder_1_loss: 0.2136 - val_u_decoder_1_loss: 0.7120\n",
      "Epoch 118/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.3581 - u_decoder_loss: 0.1127 - f_decoder_loss: 0.0891 - f_decoder_1_loss: 0.2032 - u_decoder_1_loss: 0.6306 - val_loss: 1.2477 - val_u_decoder_loss: 0.1446 - val_f_decoder_loss: 0.0610 - val_f_decoder_1_loss: 0.1659 - val_u_decoder_1_loss: 0.6148\n",
      "Epoch 119/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.2152 - u_decoder_loss: 0.1209 - f_decoder_loss: 0.0753 - f_decoder_1_loss: 0.1315 - u_decoder_1_loss: 0.6197 - val_loss: 1.3499 - val_u_decoder_loss: 0.1246 - val_f_decoder_loss: 0.0668 - val_f_decoder_1_loss: 0.2096 - val_u_decoder_1_loss: 0.6953\n",
      "Epoch 120/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.4880 - u_decoder_loss: 0.1439 - f_decoder_loss: 0.0959 - f_decoder_1_loss: 0.1938 - u_decoder_1_loss: 0.7212 - val_loss: 2.1615 - val_u_decoder_loss: 0.1505 - val_f_decoder_loss: 0.0914 - val_f_decoder_1_loss: 0.8745 - val_u_decoder_1_loss: 0.6007\n",
      "Epoch 121/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.3305 - u_decoder_loss: 0.1007 - f_decoder_loss: 0.0854 - f_decoder_1_loss: 0.2572 - u_decoder_1_loss: 0.5504 - val_loss: 2.0375 - val_u_decoder_loss: 0.1431 - val_f_decoder_loss: 0.1521 - val_f_decoder_1_loss: 0.2666 - val_u_decoder_1_loss: 1.1009\n",
      "Epoch 122/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.4189 - u_decoder_loss: 0.1252 - f_decoder_loss: 0.1107 - f_decoder_1_loss: 0.2262 - u_decoder_1_loss: 0.6635 - val_loss: 1.6132 - val_u_decoder_loss: 0.1343 - val_f_decoder_loss: 0.1214 - val_f_decoder_1_loss: 0.3105 - val_u_decoder_1_loss: 0.7020\n",
      "Epoch 123/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.3549 - u_decoder_loss: 0.1201 - f_decoder_loss: 0.1063 - f_decoder_1_loss: 0.1894 - u_decoder_1_loss: 0.6586 - val_loss: 1.3821 - val_u_decoder_loss: 0.1850 - val_f_decoder_loss: 0.0622 - val_f_decoder_1_loss: 0.2312 - val_u_decoder_1_loss: 0.7003\n",
      "Epoch 124/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.1972 - u_decoder_loss: 0.1337 - f_decoder_loss: 0.0666 - f_decoder_1_loss: 0.1385 - u_decoder_1_loss: 0.6012 - val_loss: 1.6546 - val_u_decoder_loss: 0.1355 - val_f_decoder_loss: 0.1718 - val_f_decoder_1_loss: 0.2755 - val_u_decoder_1_loss: 0.7858\n",
      "Epoch 125/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.3220 - u_decoder_loss: 0.1174 - f_decoder_loss: 0.0993 - f_decoder_1_loss: 0.2111 - u_decoder_1_loss: 0.6062 - val_loss: 1.4564 - val_u_decoder_loss: 0.1468 - val_f_decoder_loss: 0.0763 - val_f_decoder_1_loss: 0.3053 - val_u_decoder_1_loss: 0.6761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/500\n",
      "4798/4798 [==============================] - 1s 195us/sample - loss: 1.2891 - u_decoder_loss: 0.1120 - f_decoder_loss: 0.0744 - f_decoder_1_loss: 0.1700 - u_decoder_1_loss: 0.6241 - val_loss: 1.8744 - val_u_decoder_loss: 0.1382 - val_f_decoder_loss: 0.0798 - val_f_decoder_1_loss: 0.4290 - val_u_decoder_1_loss: 0.7273\n",
      "Epoch 127/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.7414 - u_decoder_loss: 0.1347 - f_decoder_loss: 0.1643 - f_decoder_1_loss: 0.4071 - u_decoder_1_loss: 0.6280 - val_loss: 1.2688 - val_u_decoder_loss: 0.1214 - val_f_decoder_loss: 0.0756 - val_f_decoder_1_loss: 0.2073 - val_u_decoder_1_loss: 0.6007\n",
      "Epoch 128/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.2342 - u_decoder_loss: 0.1224 - f_decoder_loss: 0.0916 - f_decoder_1_loss: 0.1766 - u_decoder_1_loss: 0.5736 - val_loss: 1.2131 - val_u_decoder_loss: 0.1267 - val_f_decoder_loss: 0.0541 - val_f_decoder_1_loss: 0.1812 - val_u_decoder_1_loss: 0.6351\n",
      "Epoch 129/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 1.2595 - u_decoder_loss: 0.1216 - f_decoder_loss: 0.0915 - f_decoder_1_loss: 0.1497 - u_decoder_1_loss: 0.6333 - val_loss: 1.2548 - val_u_decoder_loss: 0.1610 - val_f_decoder_loss: 0.0661 - val_f_decoder_1_loss: 0.1652 - val_u_decoder_1_loss: 0.6130\n",
      "Epoch 130/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.5870 - u_decoder_loss: 0.1368 - f_decoder_loss: 0.1223 - f_decoder_1_loss: 0.3381 - u_decoder_1_loss: 0.6324 - val_loss: 1.9405 - val_u_decoder_loss: 0.1587 - val_f_decoder_loss: 0.1984 - val_f_decoder_1_loss: 0.4964 - val_u_decoder_1_loss: 0.5578\n",
      "Epoch 131/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.2751 - u_decoder_loss: 0.1156 - f_decoder_loss: 0.0871 - f_decoder_1_loss: 0.1907 - u_decoder_1_loss: 0.5803 - val_loss: 1.3403 - val_u_decoder_loss: 0.1042 - val_f_decoder_loss: 0.0439 - val_f_decoder_1_loss: 0.1819 - val_u_decoder_1_loss: 0.7491\n",
      "Epoch 132/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0326 - u_decoder_loss: 0.0865 - f_decoder_loss: 0.0634 - f_decoder_1_loss: 0.1195 - u_decoder_1_loss: 0.5620 - val_loss: 1.5521 - val_u_decoder_loss: 0.1332 - val_f_decoder_loss: 0.0821 - val_f_decoder_1_loss: 0.2614 - val_u_decoder_1_loss: 0.8147\n",
      "Epoch 133/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 1.1186 - u_decoder_loss: 0.0898 - f_decoder_loss: 0.0911 - f_decoder_1_loss: 0.1794 - u_decoder_1_loss: 0.5122 - val_loss: 1.5888 - val_u_decoder_loss: 0.1629 - val_f_decoder_loss: 0.0931 - val_f_decoder_1_loss: 0.1831 - val_u_decoder_1_loss: 0.8113\n",
      "Epoch 134/500\n",
      "4798/4798 [==============================] - 1s 194us/sample - loss: 1.6092 - u_decoder_loss: 0.1902 - f_decoder_loss: 0.1099 - f_decoder_1_loss: 0.1452 - u_decoder_1_loss: 0.7869 - val_loss: 1.3919 - val_u_decoder_loss: 0.1303 - val_f_decoder_loss: 0.0687 - val_f_decoder_1_loss: 0.2021 - val_u_decoder_1_loss: 0.7315\n",
      "Epoch 135/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0957 - u_decoder_loss: 0.1149 - f_decoder_loss: 0.0604 - f_decoder_1_loss: 0.1135 - u_decoder_1_loss: 0.5739 - val_loss: 1.4659 - val_u_decoder_loss: 0.2157 - val_f_decoder_loss: 0.0934 - val_f_decoder_1_loss: 0.2946 - val_u_decoder_1_loss: 0.5774\n",
      "Epoch 136/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5723 - u_decoder_loss: 0.1328 - f_decoder_loss: 0.1618 - f_decoder_1_loss: 0.3915 - u_decoder_1_loss: 0.5519 - val_loss: 1.4750 - val_u_decoder_loss: 0.2072 - val_f_decoder_loss: 0.1054 - val_f_decoder_1_loss: 0.2364 - val_u_decoder_1_loss: 0.5972\n",
      "Epoch 137/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.4715 - u_decoder_loss: 0.1309 - f_decoder_loss: 0.1501 - f_decoder_1_loss: 0.2275 - u_decoder_1_loss: 0.6282 - val_loss: 1.5505 - val_u_decoder_loss: 0.1958 - val_f_decoder_loss: 0.0866 - val_f_decoder_1_loss: 0.2360 - val_u_decoder_1_loss: 0.7268\n",
      "Epoch 138/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 1.0885 - u_decoder_loss: 0.1153 - f_decoder_loss: 0.0570 - f_decoder_1_loss: 0.1123 - u_decoder_1_loss: 0.5754 - val_loss: 1.0751 - val_u_decoder_loss: 0.0966 - val_f_decoder_loss: 0.0472 - val_f_decoder_1_loss: 0.1689 - val_u_decoder_1_loss: 0.5640\n",
      "Epoch 139/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0617 - u_decoder_loss: 0.1018 - f_decoder_loss: 0.0638 - f_decoder_1_loss: 0.1168 - u_decoder_1_loss: 0.5683 - val_loss: 1.4231 - val_u_decoder_loss: 0.1113 - val_f_decoder_loss: 0.0936 - val_f_decoder_1_loss: 0.2172 - val_u_decoder_1_loss: 0.7166\n",
      "Epoch 140/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.0281 - u_decoder_loss: 0.1033 - f_decoder_loss: 0.0519 - f_decoder_1_loss: 0.1013 - u_decoder_1_loss: 0.5637 - val_loss: 1.1679 - val_u_decoder_loss: 0.1102 - val_f_decoder_loss: 0.0602 - val_f_decoder_1_loss: 0.2367 - val_u_decoder_1_loss: 0.5491\n",
      "Epoch 141/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4327 - u_decoder_loss: 0.1226 - f_decoder_loss: 0.0988 - f_decoder_1_loss: 0.2247 - u_decoder_1_loss: 0.6761 - val_loss: 1.8547 - val_u_decoder_loss: 0.1463 - val_f_decoder_loss: 0.1334 - val_f_decoder_1_loss: 0.2835 - val_u_decoder_1_loss: 0.9039\n",
      "Epoch 142/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.3924 - u_decoder_loss: 0.1182 - f_decoder_loss: 0.0874 - f_decoder_1_loss: 0.1389 - u_decoder_1_loss: 0.7074 - val_loss: 4.6749 - val_u_decoder_loss: 0.4419 - val_f_decoder_loss: 0.1002 - val_f_decoder_1_loss: 0.1860 - val_u_decoder_1_loss: 3.2468\n",
      "Epoch 143/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.4109 - u_decoder_loss: 0.1547 - f_decoder_loss: 0.0923 - f_decoder_1_loss: 0.1677 - u_decoder_1_loss: 0.6798 - val_loss: 1.4013 - val_u_decoder_loss: 0.1068 - val_f_decoder_loss: 0.0643 - val_f_decoder_1_loss: 0.3375 - val_u_decoder_1_loss: 0.6289\n",
      "Epoch 144/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.0614 - u_decoder_loss: 0.0940 - f_decoder_loss: 0.0673 - f_decoder_1_loss: 0.1857 - u_decoder_1_loss: 0.4709 - val_loss: 1.5287 - val_u_decoder_loss: 0.1877 - val_f_decoder_loss: 0.0578 - val_f_decoder_1_loss: 0.3082 - val_u_decoder_1_loss: 0.5786\n",
      "Epoch 145/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 1.2461 - u_decoder_loss: 0.1182 - f_decoder_loss: 0.0700 - f_decoder_1_loss: 0.1663 - u_decoder_1_loss: 0.6131 - val_loss: 1.4058 - val_u_decoder_loss: 0.1263 - val_f_decoder_loss: 0.0873 - val_f_decoder_1_loss: 0.1639 - val_u_decoder_1_loss: 0.6333\n",
      "Epoch 146/500\n",
      "4798/4798 [==============================] - 1s 193us/sample - loss: 1.2537 - u_decoder_loss: 0.1154 - f_decoder_loss: 0.0847 - f_decoder_1_loss: 0.2004 - u_decoder_1_loss: 0.5786 - val_loss: 1.2040 - val_u_decoder_loss: 0.1257 - val_f_decoder_loss: 0.0555 - val_f_decoder_1_loss: 0.2044 - val_u_decoder_1_loss: 0.5658\n",
      "Epoch 147/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.0049 - u_decoder_loss: 0.0926 - f_decoder_loss: 0.0644 - f_decoder_1_loss: 0.1261 - u_decoder_1_loss: 0.4859 - val_loss: 1.3260 - val_u_decoder_loss: 0.1019 - val_f_decoder_loss: 0.0726 - val_f_decoder_1_loss: 0.2171 - val_u_decoder_1_loss: 0.7037\n",
      "Epoch 148/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0708 - u_decoder_loss: 0.0906 - f_decoder_loss: 0.0893 - f_decoder_1_loss: 0.1441 - u_decoder_1_loss: 0.5134 - val_loss: 1.4319 - val_u_decoder_loss: 0.1553 - val_f_decoder_loss: 0.0743 - val_f_decoder_1_loss: 0.1414 - val_u_decoder_1_loss: 0.8101\n",
      "Epoch 149/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.5368 - u_decoder_loss: 0.1208 - f_decoder_loss: 0.1148 - f_decoder_1_loss: 0.2502 - u_decoder_1_loss: 0.6089 - val_loss: 1.2813 - val_u_decoder_loss: 0.1494 - val_f_decoder_loss: 0.0647 - val_f_decoder_1_loss: 0.1857 - val_u_decoder_1_loss: 0.6206\n",
      "Epoch 150/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.1832 - u_decoder_loss: 0.1127 - f_decoder_loss: 0.0763 - f_decoder_1_loss: 0.1794 - u_decoder_1_loss: 0.5903 - val_loss: 1.4016 - val_u_decoder_loss: 0.1611 - val_f_decoder_loss: 0.0949 - val_f_decoder_1_loss: 0.2055 - val_u_decoder_1_loss: 0.6867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.2108 - u_decoder_loss: 0.1019 - f_decoder_loss: 0.1285 - f_decoder_1_loss: 0.1718 - u_decoder_1_loss: 0.5742 - val_loss: 1.2926 - val_u_decoder_loss: 0.1362 - val_f_decoder_loss: 0.1566 - val_f_decoder_1_loss: 0.2085 - val_u_decoder_1_loss: 0.5316\n",
      "Epoch 152/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.3616 - u_decoder_loss: 0.0964 - f_decoder_loss: 0.1121 - f_decoder_1_loss: 0.2768 - u_decoder_1_loss: 0.4758 - val_loss: 1.2561 - val_u_decoder_loss: 0.1155 - val_f_decoder_loss: 0.0927 - val_f_decoder_1_loss: 0.2157 - val_u_decoder_1_loss: 0.5905\n",
      "Epoch 153/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.4083 - u_decoder_loss: 0.1532 - f_decoder_loss: 0.0896 - f_decoder_1_loss: 0.1917 - u_decoder_1_loss: 0.6188 - val_loss: 1.3381 - val_u_decoder_loss: 0.1114 - val_f_decoder_loss: 0.0809 - val_f_decoder_1_loss: 0.2704 - val_u_decoder_1_loss: 0.5457\n",
      "Epoch 154/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.1905 - u_decoder_loss: 0.1198 - f_decoder_loss: 0.0703 - f_decoder_1_loss: 0.1064 - u_decoder_1_loss: 0.6474 - val_loss: 1.7773 - val_u_decoder_loss: 0.2276 - val_f_decoder_loss: 0.0795 - val_f_decoder_1_loss: 0.2201 - val_u_decoder_1_loss: 0.9379\n",
      "Epoch 155/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.4362 - u_decoder_loss: 0.1086 - f_decoder_loss: 0.1152 - f_decoder_1_loss: 0.3095 - u_decoder_1_loss: 0.5676 - val_loss: 1.3213 - val_u_decoder_loss: 0.0988 - val_f_decoder_loss: 0.0717 - val_f_decoder_1_loss: 0.2466 - val_u_decoder_1_loss: 0.6698\n",
      "Epoch 156/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0151 - u_decoder_loss: 0.0867 - f_decoder_loss: 0.0690 - f_decoder_1_loss: 0.1182 - u_decoder_1_loss: 0.5180 - val_loss: 1.3383 - val_u_decoder_loss: 0.1185 - val_f_decoder_loss: 0.1332 - val_f_decoder_1_loss: 0.2845 - val_u_decoder_1_loss: 0.5240\n",
      "Epoch 157/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0156 - u_decoder_loss: 0.0885 - f_decoder_loss: 0.0755 - f_decoder_1_loss: 0.1545 - u_decoder_1_loss: 0.4578 - val_loss: 1.1218 - val_u_decoder_loss: 0.1109 - val_f_decoder_loss: 0.0423 - val_f_decoder_1_loss: 0.1643 - val_u_decoder_1_loss: 0.6029\n",
      "Epoch 158/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.1627 - u_decoder_loss: 0.1113 - f_decoder_loss: 0.0664 - f_decoder_1_loss: 0.1597 - u_decoder_1_loss: 0.6015 - val_loss: 1.7830 - val_u_decoder_loss: 0.2608 - val_f_decoder_loss: 0.0825 - val_f_decoder_1_loss: 0.2647 - val_u_decoder_1_loss: 0.7891\n",
      "Epoch 159/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.1596 - u_decoder_loss: 0.1081 - f_decoder_loss: 0.0874 - f_decoder_1_loss: 0.1328 - u_decoder_1_loss: 0.5818 - val_loss: 1.5918 - val_u_decoder_loss: 0.1340 - val_f_decoder_loss: 0.0956 - val_f_decoder_1_loss: 0.1890 - val_u_decoder_1_loss: 0.8562\n",
      "Epoch 160/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2263 - u_decoder_loss: 0.1092 - f_decoder_loss: 0.0807 - f_decoder_1_loss: 0.2060 - u_decoder_1_loss: 0.5623 - val_loss: 1.4613 - val_u_decoder_loss: 0.1590 - val_f_decoder_loss: 0.1035 - val_f_decoder_1_loss: 0.2772 - val_u_decoder_1_loss: 0.6223\n",
      "Epoch 161/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.7699 - u_decoder_loss: 0.1214 - f_decoder_loss: 0.1508 - f_decoder_1_loss: 0.3827 - u_decoder_1_loss: 0.5993 - val_loss: 1.5362 - val_u_decoder_loss: 0.1413 - val_f_decoder_loss: 0.1533 - val_f_decoder_1_loss: 0.1969 - val_u_decoder_1_loss: 0.7759\n",
      "Epoch 162/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9393 - u_decoder_loss: 0.0916 - f_decoder_loss: 0.0517 - f_decoder_1_loss: 0.0833 - u_decoder_1_loss: 0.5270 - val_loss: 1.5075 - val_u_decoder_loss: 0.1216 - val_f_decoder_loss: 0.0597 - val_f_decoder_1_loss: 0.1638 - val_u_decoder_1_loss: 0.9349\n",
      "Epoch 163/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.6627 - u_decoder_loss: 0.1675 - f_decoder_loss: 0.1206 - f_decoder_1_loss: 0.2259 - u_decoder_1_loss: 0.7564 - val_loss: 1.1666 - val_u_decoder_loss: 0.1099 - val_f_decoder_loss: 0.0597 - val_f_decoder_1_loss: 0.2330 - val_u_decoder_1_loss: 0.5143\n",
      "Epoch 164/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0554 - u_decoder_loss: 0.1115 - f_decoder_loss: 0.0571 - f_decoder_1_loss: 0.1091 - u_decoder_1_loss: 0.5671 - val_loss: 1.1479 - val_u_decoder_loss: 0.1292 - val_f_decoder_loss: 0.0381 - val_f_decoder_1_loss: 0.1738 - val_u_decoder_1_loss: 0.6031\n",
      "Epoch 165/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9709 - u_decoder_loss: 0.0923 - f_decoder_loss: 0.0608 - f_decoder_1_loss: 0.0993 - u_decoder_1_loss: 0.5095 - val_loss: 1.0311 - val_u_decoder_loss: 0.0842 - val_f_decoder_loss: 0.0451 - val_f_decoder_1_loss: 0.1521 - val_u_decoder_1_loss: 0.5999\n",
      "Epoch 166/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0771 - u_decoder_loss: 0.1250 - f_decoder_loss: 0.0598 - f_decoder_1_loss: 0.0934 - u_decoder_1_loss: 0.5715 - val_loss: 1.1088 - val_u_decoder_loss: 0.1237 - val_f_decoder_loss: 0.0478 - val_f_decoder_1_loss: 0.1669 - val_u_decoder_1_loss: 0.5856\n",
      "Epoch 167/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.1286 - u_decoder_loss: 0.1113 - f_decoder_loss: 0.0815 - f_decoder_1_loss: 0.1612 - u_decoder_1_loss: 0.5439 - val_loss: 1.4337 - val_u_decoder_loss: 0.1561 - val_f_decoder_loss: 0.0644 - val_f_decoder_1_loss: 0.2980 - val_u_decoder_1_loss: 0.6133\n",
      "Epoch 168/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0453 - u_decoder_loss: 0.0927 - f_decoder_loss: 0.0543 - f_decoder_1_loss: 0.1284 - u_decoder_1_loss: 0.5443 - val_loss: 1.0839 - val_u_decoder_loss: 0.1116 - val_f_decoder_loss: 0.0437 - val_f_decoder_1_loss: 0.1664 - val_u_decoder_1_loss: 0.5444\n",
      "Epoch 169/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0436 - u_decoder_loss: 0.0979 - f_decoder_loss: 0.0646 - f_decoder_1_loss: 0.1193 - u_decoder_1_loss: 0.5475 - val_loss: 1.1525 - val_u_decoder_loss: 0.1158 - val_f_decoder_loss: 0.0762 - val_f_decoder_1_loss: 0.2411 - val_u_decoder_1_loss: 0.4894\n",
      "Epoch 170/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.1030 - u_decoder_loss: 0.0970 - f_decoder_loss: 0.0840 - f_decoder_1_loss: 0.1985 - u_decoder_1_loss: 0.4898 - val_loss: 2.4915 - val_u_decoder_loss: 0.1681 - val_f_decoder_loss: 0.3439 - val_f_decoder_1_loss: 0.8995 - val_u_decoder_1_loss: 0.7287\n",
      "Epoch 171/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.4704 - u_decoder_loss: 0.1047 - f_decoder_loss: 0.1581 - f_decoder_1_loss: 0.3606 - u_decoder_1_loss: 0.5576 - val_loss: 1.2971 - val_u_decoder_loss: 0.1382 - val_f_decoder_loss: 0.1103 - val_f_decoder_1_loss: 0.2759 - val_u_decoder_1_loss: 0.5208\n",
      "Epoch 172/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.1073 - u_decoder_loss: 0.0844 - f_decoder_loss: 0.0779 - f_decoder_1_loss: 0.1714 - u_decoder_1_loss: 0.4961 - val_loss: 1.4803 - val_u_decoder_loss: 0.1257 - val_f_decoder_loss: 0.0529 - val_f_decoder_1_loss: 0.1340 - val_u_decoder_1_loss: 0.8795\n",
      "Epoch 173/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.1520 - u_decoder_loss: 0.1061 - f_decoder_loss: 0.0555 - f_decoder_1_loss: 0.1043 - u_decoder_1_loss: 0.6321 - val_loss: 1.7509 - val_u_decoder_loss: 0.1118 - val_f_decoder_loss: 0.1000 - val_f_decoder_1_loss: 0.1959 - val_u_decoder_1_loss: 0.9868\n",
      "Epoch 174/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.2868 - u_decoder_loss: 0.1181 - f_decoder_loss: 0.0664 - f_decoder_1_loss: 0.1430 - u_decoder_1_loss: 0.6311 - val_loss: 1.1666 - val_u_decoder_loss: 0.1091 - val_f_decoder_loss: 0.0476 - val_f_decoder_1_loss: 0.1785 - val_u_decoder_1_loss: 0.5818\n",
      "Epoch 175/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0246 - u_decoder_loss: 0.0805 - f_decoder_loss: 0.0839 - f_decoder_1_loss: 0.1474 - u_decoder_1_loss: 0.5172 - val_loss: 1.2232 - val_u_decoder_loss: 0.0944 - val_f_decoder_loss: 0.1062 - val_f_decoder_1_loss: 0.2432 - val_u_decoder_1_loss: 0.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2123 - u_decoder_loss: 0.0865 - f_decoder_loss: 0.0798 - f_decoder_1_loss: 0.1975 - u_decoder_1_loss: 0.5124 - val_loss: 1.2866 - val_u_decoder_loss: 0.1115 - val_f_decoder_loss: 0.0611 - val_f_decoder_1_loss: 0.2786 - val_u_decoder_1_loss: 0.5720\n",
      "Epoch 177/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.5298 - u_decoder_loss: 0.1220 - f_decoder_loss: 0.1272 - f_decoder_1_loss: 0.2824 - u_decoder_1_loss: 0.5563 - val_loss: 1.8533 - val_u_decoder_loss: 0.2816 - val_f_decoder_loss: 0.0933 - val_f_decoder_1_loss: 0.2510 - val_u_decoder_1_loss: 0.7859\n",
      "Epoch 178/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0478 - u_decoder_loss: 0.1049 - f_decoder_loss: 0.0515 - f_decoder_1_loss: 0.1385 - u_decoder_1_loss: 0.5185 - val_loss: 1.2107 - val_u_decoder_loss: 0.1285 - val_f_decoder_loss: 0.0837 - val_f_decoder_1_loss: 0.2099 - val_u_decoder_1_loss: 0.5619\n",
      "Epoch 179/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8962 - u_decoder_loss: 0.0834 - f_decoder_loss: 0.0589 - f_decoder_1_loss: 0.1135 - u_decoder_1_loss: 0.4587 - val_loss: 1.0861 - val_u_decoder_loss: 0.1337 - val_f_decoder_loss: 0.0393 - val_f_decoder_1_loss: 0.1417 - val_u_decoder_1_loss: 0.5674\n",
      "Epoch 180/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.1567 - u_decoder_loss: 0.1225 - f_decoder_loss: 0.0769 - f_decoder_1_loss: 0.1859 - u_decoder_1_loss: 0.5248 - val_loss: 1.1515 - val_u_decoder_loss: 0.1140 - val_f_decoder_loss: 0.0884 - val_f_decoder_1_loss: 0.2936 - val_u_decoder_1_loss: 0.4616\n",
      "Epoch 181/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0203 - u_decoder_loss: 0.0961 - f_decoder_loss: 0.0619 - f_decoder_1_loss: 0.1292 - u_decoder_1_loss: 0.5323 - val_loss: 1.2028 - val_u_decoder_loss: 0.1268 - val_f_decoder_loss: 0.0400 - val_f_decoder_1_loss: 0.1755 - val_u_decoder_1_loss: 0.6145\n",
      "Epoch 182/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.2313 - u_decoder_loss: 0.1271 - f_decoder_loss: 0.0926 - f_decoder_1_loss: 0.1256 - u_decoder_1_loss: 0.5731 - val_loss: 1.5817 - val_u_decoder_loss: 0.1973 - val_f_decoder_loss: 0.1132 - val_f_decoder_1_loss: 0.2119 - val_u_decoder_1_loss: 0.8203\n",
      "Epoch 183/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.2250 - u_decoder_loss: 0.1084 - f_decoder_loss: 0.1039 - f_decoder_1_loss: 0.1999 - u_decoder_1_loss: 0.5238 - val_loss: 1.1140 - val_u_decoder_loss: 0.1124 - val_f_decoder_loss: 0.0405 - val_f_decoder_1_loss: 0.1959 - val_u_decoder_1_loss: 0.4837\n",
      "Epoch 184/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8378 - u_decoder_loss: 0.0809 - f_decoder_loss: 0.0422 - f_decoder_1_loss: 0.0745 - u_decoder_1_loss: 0.4820 - val_loss: 1.0465 - val_u_decoder_loss: 0.1124 - val_f_decoder_loss: 0.0463 - val_f_decoder_1_loss: 0.1141 - val_u_decoder_1_loss: 0.5591\n",
      "Epoch 185/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.2705 - u_decoder_loss: 0.0979 - f_decoder_loss: 0.0917 - f_decoder_1_loss: 0.1786 - u_decoder_1_loss: 0.6131 - val_loss: 1.1952 - val_u_decoder_loss: 0.1252 - val_f_decoder_loss: 0.0408 - val_f_decoder_1_loss: 0.1632 - val_u_decoder_1_loss: 0.6752\n",
      "Epoch 186/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9810 - u_decoder_loss: 0.0838 - f_decoder_loss: 0.0797 - f_decoder_1_loss: 0.1894 - u_decoder_1_loss: 0.4456 - val_loss: 1.2771 - val_u_decoder_loss: 0.1233 - val_f_decoder_loss: 0.0724 - val_f_decoder_1_loss: 0.2470 - val_u_decoder_1_loss: 0.6089\n",
      "Epoch 187/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0403 - u_decoder_loss: 0.0969 - f_decoder_loss: 0.0628 - f_decoder_1_loss: 0.1190 - u_decoder_1_loss: 0.5460 - val_loss: 1.3533 - val_u_decoder_loss: 0.2166 - val_f_decoder_loss: 0.0485 - val_f_decoder_1_loss: 0.1338 - val_u_decoder_1_loss: 0.6565\n",
      "Epoch 188/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.2122 - u_decoder_loss: 0.1089 - f_decoder_loss: 0.0812 - f_decoder_1_loss: 0.1918 - u_decoder_1_loss: 0.5708 - val_loss: 1.0306 - val_u_decoder_loss: 0.1257 - val_f_decoder_loss: 0.0455 - val_f_decoder_1_loss: 0.2095 - val_u_decoder_1_loss: 0.4843\n",
      "Epoch 189/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 0.9133 - u_decoder_loss: 0.0826 - f_decoder_loss: 0.0604 - f_decoder_1_loss: 0.1484 - u_decoder_1_loss: 0.4414 - val_loss: 1.2482 - val_u_decoder_loss: 0.1503 - val_f_decoder_loss: 0.0456 - val_f_decoder_1_loss: 0.1961 - val_u_decoder_1_loss: 0.6294\n",
      "Epoch 190/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0950 - u_decoder_loss: 0.0915 - f_decoder_loss: 0.0778 - f_decoder_1_loss: 0.1704 - u_decoder_1_loss: 0.4851 - val_loss: 0.9940 - val_u_decoder_loss: 0.1068 - val_f_decoder_loss: 0.0728 - val_f_decoder_1_loss: 0.1645 - val_u_decoder_1_loss: 0.4642\n",
      "Epoch 191/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0690 - u_decoder_loss: 0.1011 - f_decoder_loss: 0.0668 - f_decoder_1_loss: 0.1228 - u_decoder_1_loss: 0.5451 - val_loss: 1.4679 - val_u_decoder_loss: 0.1466 - val_f_decoder_loss: 0.2101 - val_f_decoder_1_loss: 0.1769 - val_u_decoder_1_loss: 0.6280\n",
      "Epoch 192/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.1227 - u_decoder_loss: 0.0938 - f_decoder_loss: 0.0887 - f_decoder_1_loss: 0.1245 - u_decoder_1_loss: 0.5573 - val_loss: 1.0351 - val_u_decoder_loss: 0.1131 - val_f_decoder_loss: 0.0366 - val_f_decoder_1_loss: 0.1006 - val_u_decoder_1_loss: 0.6179\n",
      "Epoch 193/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.7700 - u_decoder_loss: 0.0726 - f_decoder_loss: 0.0318 - f_decoder_1_loss: 0.0612 - u_decoder_1_loss: 0.4582 - val_loss: 0.9445 - val_u_decoder_loss: 0.1096 - val_f_decoder_loss: 0.0528 - val_f_decoder_1_loss: 0.1301 - val_u_decoder_1_loss: 0.4734\n",
      "Epoch 194/500\n",
      "4798/4798 [==============================] - 1s 193us/sample - loss: 1.3883 - u_decoder_loss: 0.1343 - f_decoder_loss: 0.0929 - f_decoder_1_loss: 0.2255 - u_decoder_1_loss: 0.6266 - val_loss: 1.2414 - val_u_decoder_loss: 0.1421 - val_f_decoder_loss: 0.0778 - val_f_decoder_1_loss: 0.2184 - val_u_decoder_1_loss: 0.5451\n",
      "Epoch 195/500\n",
      "4798/4798 [==============================] - 1s 194us/sample - loss: 0.9168 - u_decoder_loss: 0.0869 - f_decoder_loss: 0.0556 - f_decoder_1_loss: 0.1393 - u_decoder_1_loss: 0.4416 - val_loss: 0.8759 - val_u_decoder_loss: 0.0938 - val_f_decoder_loss: 0.0282 - val_f_decoder_1_loss: 0.0999 - val_u_decoder_1_loss: 0.5218\n",
      "Epoch 196/500\n",
      "4798/4798 [==============================] - 1s 205us/sample - loss: 1.0343 - u_decoder_loss: 0.0869 - f_decoder_loss: 0.0837 - f_decoder_1_loss: 0.1640 - u_decoder_1_loss: 0.4553 - val_loss: 1.6455 - val_u_decoder_loss: 0.1520 - val_f_decoder_loss: 0.2625 - val_f_decoder_1_loss: 0.2752 - val_u_decoder_1_loss: 0.5635\n",
      "Epoch 197/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.1926 - u_decoder_loss: 0.1089 - f_decoder_loss: 0.1039 - f_decoder_1_loss: 0.2073 - u_decoder_1_loss: 0.4769 - val_loss: 1.4214 - val_u_decoder_loss: 0.1078 - val_f_decoder_loss: 0.1051 - val_f_decoder_1_loss: 0.4495 - val_u_decoder_1_loss: 0.5478\n",
      "Epoch 198/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 1.2852 - u_decoder_loss: 0.1328 - f_decoder_loss: 0.0840 - f_decoder_1_loss: 0.1737 - u_decoder_1_loss: 0.6297 - val_loss: 1.4062 - val_u_decoder_loss: 0.1243 - val_f_decoder_loss: 0.0757 - val_f_decoder_1_loss: 0.2914 - val_u_decoder_1_loss: 0.6508\n",
      "Epoch 199/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.9771 - u_decoder_loss: 0.0835 - f_decoder_loss: 0.0674 - f_decoder_1_loss: 0.1578 - u_decoder_1_loss: 0.4822 - val_loss: 1.1047 - val_u_decoder_loss: 0.0921 - val_f_decoder_loss: 0.0555 - val_f_decoder_1_loss: 0.2099 - val_u_decoder_1_loss: 0.5723\n",
      "Epoch 200/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8581 - u_decoder_loss: 0.0759 - f_decoder_loss: 0.0547 - f_decoder_1_loss: 0.1079 - u_decoder_1_loss: 0.4528 - val_loss: 1.3548 - val_u_decoder_loss: 0.1227 - val_f_decoder_loss: 0.0605 - val_f_decoder_1_loss: 0.2894 - val_u_decoder_1_loss: 0.6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.1251 - u_decoder_loss: 0.1033 - f_decoder_loss: 0.0926 - f_decoder_1_loss: 0.1840 - u_decoder_1_loss: 0.4873 - val_loss: 1.2147 - val_u_decoder_loss: 0.1037 - val_f_decoder_loss: 0.0714 - val_f_decoder_1_loss: 0.2472 - val_u_decoder_1_loss: 0.4979\n",
      "Epoch 202/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.1065 - u_decoder_loss: 0.0904 - f_decoder_loss: 0.0664 - f_decoder_1_loss: 0.1170 - u_decoder_1_loss: 0.5923 - val_loss: 1.0732 - val_u_decoder_loss: 0.1200 - val_f_decoder_loss: 0.0655 - val_f_decoder_1_loss: 0.1707 - val_u_decoder_1_loss: 0.5338\n",
      "Epoch 203/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9163 - u_decoder_loss: 0.0777 - f_decoder_loss: 0.0628 - f_decoder_1_loss: 0.0956 - u_decoder_1_loss: 0.4808 - val_loss: 0.9732 - val_u_decoder_loss: 0.0753 - val_f_decoder_loss: 0.0309 - val_f_decoder_1_loss: 0.1353 - val_u_decoder_1_loss: 0.5313\n",
      "Epoch 204/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 0.8311 - u_decoder_loss: 0.0684 - f_decoder_loss: 0.0569 - f_decoder_1_loss: 0.1292 - u_decoder_1_loss: 0.3855 - val_loss: 1.5124 - val_u_decoder_loss: 0.0945 - val_f_decoder_loss: 0.1088 - val_f_decoder_1_loss: 0.3536 - val_u_decoder_1_loss: 0.7139\n",
      "Epoch 205/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 1.4188 - u_decoder_loss: 0.1235 - f_decoder_loss: 0.1053 - f_decoder_1_loss: 0.2528 - u_decoder_1_loss: 0.5781 - val_loss: 1.3017 - val_u_decoder_loss: 0.1124 - val_f_decoder_loss: 0.1117 - val_f_decoder_1_loss: 0.2353 - val_u_decoder_1_loss: 0.5745\n",
      "Epoch 206/500\n",
      "4798/4798 [==============================] - 1s 188us/sample - loss: 0.8591 - u_decoder_loss: 0.0818 - f_decoder_loss: 0.0482 - f_decoder_1_loss: 0.1084 - u_decoder_1_loss: 0.4243 - val_loss: 1.3693 - val_u_decoder_loss: 0.0997 - val_f_decoder_loss: 0.0545 - val_f_decoder_1_loss: 0.2448 - val_u_decoder_1_loss: 0.7616\n",
      "Epoch 207/500\n",
      "4798/4798 [==============================] - 1s 194us/sample - loss: 0.9401 - u_decoder_loss: 0.1022 - f_decoder_loss: 0.0593 - f_decoder_1_loss: 0.0999 - u_decoder_1_loss: 0.5051 - val_loss: 1.0291 - val_u_decoder_loss: 0.1319 - val_f_decoder_loss: 0.0558 - val_f_decoder_1_loss: 0.1716 - val_u_decoder_1_loss: 0.4585\n",
      "Epoch 208/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8898 - u_decoder_loss: 0.0921 - f_decoder_loss: 0.0538 - f_decoder_1_loss: 0.0944 - u_decoder_1_loss: 0.4720 - val_loss: 1.0021 - val_u_decoder_loss: 0.0949 - val_f_decoder_loss: 0.0348 - val_f_decoder_1_loss: 0.1261 - val_u_decoder_1_loss: 0.5972\n",
      "Epoch 209/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0439 - u_decoder_loss: 0.0872 - f_decoder_loss: 0.0770 - f_decoder_1_loss: 0.1902 - u_decoder_1_loss: 0.4654 - val_loss: 1.6733 - val_u_decoder_loss: 0.1315 - val_f_decoder_loss: 0.1378 - val_f_decoder_1_loss: 0.4831 - val_u_decoder_1_loss: 0.5482\n",
      "Epoch 210/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.2090 - u_decoder_loss: 0.1052 - f_decoder_loss: 0.1335 - f_decoder_1_loss: 0.2112 - u_decoder_1_loss: 0.4910 - val_loss: 1.7319 - val_u_decoder_loss: 0.1213 - val_f_decoder_loss: 0.1455 - val_f_decoder_1_loss: 0.3133 - val_u_decoder_1_loss: 0.8557\n",
      "Epoch 211/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0733 - u_decoder_loss: 0.0893 - f_decoder_loss: 0.0684 - f_decoder_1_loss: 0.1246 - u_decoder_1_loss: 0.5986 - val_loss: 1.0277 - val_u_decoder_loss: 0.0843 - val_f_decoder_loss: 0.0453 - val_f_decoder_1_loss: 0.1704 - val_u_decoder_1_loss: 0.5358\n",
      "Epoch 212/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9781 - u_decoder_loss: 0.1008 - f_decoder_loss: 0.0570 - f_decoder_1_loss: 0.1158 - u_decoder_1_loss: 0.4808 - val_loss: 0.9624 - val_u_decoder_loss: 0.1222 - val_f_decoder_loss: 0.0479 - val_f_decoder_1_loss: 0.1440 - val_u_decoder_1_loss: 0.4563\n",
      "Epoch 213/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9279 - u_decoder_loss: 0.0853 - f_decoder_loss: 0.0517 - f_decoder_1_loss: 0.1354 - u_decoder_1_loss: 0.4776 - val_loss: 1.3899 - val_u_decoder_loss: 0.0939 - val_f_decoder_loss: 0.0841 - val_f_decoder_1_loss: 0.1420 - val_u_decoder_1_loss: 0.8005\n",
      "Epoch 214/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.1302 - u_decoder_loss: 0.0910 - f_decoder_loss: 0.0795 - f_decoder_1_loss: 0.1404 - u_decoder_1_loss: 0.5446 - val_loss: 0.8505 - val_u_decoder_loss: 0.1022 - val_f_decoder_loss: 0.0257 - val_f_decoder_1_loss: 0.1362 - val_u_decoder_1_loss: 0.4309\n",
      "Epoch 215/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7521 - u_decoder_loss: 0.0778 - f_decoder_loss: 0.0405 - f_decoder_1_loss: 0.0856 - u_decoder_1_loss: 0.4031 - val_loss: 1.0740 - val_u_decoder_loss: 0.0943 - val_f_decoder_loss: 0.0285 - val_f_decoder_1_loss: 0.1042 - val_u_decoder_1_loss: 0.7063\n",
      "Epoch 216/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.9179 - u_decoder_loss: 0.0843 - f_decoder_loss: 0.0690 - f_decoder_1_loss: 0.1333 - u_decoder_1_loss: 0.4366 - val_loss: 1.4379 - val_u_decoder_loss: 0.1352 - val_f_decoder_loss: 0.1029 - val_f_decoder_1_loss: 0.4018 - val_u_decoder_1_loss: 0.5689\n",
      "Epoch 217/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.9531 - u_decoder_loss: 0.0788 - f_decoder_loss: 0.0773 - f_decoder_1_loss: 0.1221 - u_decoder_1_loss: 0.4843 - val_loss: 0.8893 - val_u_decoder_loss: 0.1168 - val_f_decoder_loss: 0.0392 - val_f_decoder_1_loss: 0.1143 - val_u_decoder_1_loss: 0.4577\n",
      "Epoch 218/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2349 - u_decoder_loss: 0.1279 - f_decoder_loss: 0.0964 - f_decoder_1_loss: 0.1622 - u_decoder_1_loss: 0.5916 - val_loss: 1.2660 - val_u_decoder_loss: 0.1469 - val_f_decoder_loss: 0.0786 - val_f_decoder_1_loss: 0.1902 - val_u_decoder_1_loss: 0.6064\n",
      "Epoch 219/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.1848 - u_decoder_loss: 0.1110 - f_decoder_loss: 0.0875 - f_decoder_1_loss: 0.1974 - u_decoder_1_loss: 0.5068 - val_loss: 1.7987 - val_u_decoder_loss: 0.1911 - val_f_decoder_loss: 0.1467 - val_f_decoder_1_loss: 0.3760 - val_u_decoder_1_loss: 0.5992\n",
      "Epoch 220/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.4182 - u_decoder_loss: 0.1214 - f_decoder_loss: 0.0995 - f_decoder_1_loss: 0.2381 - u_decoder_1_loss: 0.5853 - val_loss: 1.3837 - val_u_decoder_loss: 0.1222 - val_f_decoder_loss: 0.0902 - val_f_decoder_1_loss: 0.2117 - val_u_decoder_1_loss: 0.7061\n",
      "Epoch 221/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.9841 - u_decoder_loss: 0.0819 - f_decoder_loss: 0.0522 - f_decoder_1_loss: 0.1048 - u_decoder_1_loss: 0.5513 - val_loss: 1.2763 - val_u_decoder_loss: 0.1265 - val_f_decoder_loss: 0.0509 - val_f_decoder_1_loss: 0.1698 - val_u_decoder_1_loss: 0.7027\n",
      "Epoch 222/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9327 - u_decoder_loss: 0.0843 - f_decoder_loss: 0.0607 - f_decoder_1_loss: 0.0812 - u_decoder_1_loss: 0.4997 - val_loss: 1.2235 - val_u_decoder_loss: 0.0954 - val_f_decoder_loss: 0.0448 - val_f_decoder_1_loss: 0.1391 - val_u_decoder_1_loss: 0.7585\n",
      "Epoch 223/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7794 - u_decoder_loss: 0.0710 - f_decoder_loss: 0.0429 - f_decoder_1_loss: 0.0753 - u_decoder_1_loss: 0.4429 - val_loss: 0.9925 - val_u_decoder_loss: 0.1025 - val_f_decoder_loss: 0.0256 - val_f_decoder_1_loss: 0.1694 - val_u_decoder_1_loss: 0.5463\n",
      "Epoch 224/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 1.0244 - u_decoder_loss: 0.0799 - f_decoder_loss: 0.0741 - f_decoder_1_loss: 0.1463 - u_decoder_1_loss: 0.4977 - val_loss: 1.4281 - val_u_decoder_loss: 0.1065 - val_f_decoder_loss: 0.1216 - val_f_decoder_1_loss: 0.2758 - val_u_decoder_1_loss: 0.5998\n",
      "Epoch 225/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0822 - u_decoder_loss: 0.0902 - f_decoder_loss: 0.0945 - f_decoder_1_loss: 0.1770 - u_decoder_1_loss: 0.4653 - val_loss: 1.1348 - val_u_decoder_loss: 0.1200 - val_f_decoder_loss: 0.0517 - val_f_decoder_1_loss: 0.2071 - val_u_decoder_1_loss: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.1567 - u_decoder_loss: 0.0980 - f_decoder_loss: 0.0702 - f_decoder_1_loss: 0.1594 - u_decoder_1_loss: 0.5703 - val_loss: 1.4676 - val_u_decoder_loss: 0.1081 - val_f_decoder_loss: 0.1157 - val_f_decoder_1_loss: 0.2350 - val_u_decoder_1_loss: 0.6677\n",
      "Epoch 227/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0372 - u_decoder_loss: 0.0895 - f_decoder_loss: 0.0672 - f_decoder_1_loss: 0.1308 - u_decoder_1_loss: 0.5402 - val_loss: 2.2992 - val_u_decoder_loss: 0.1394 - val_f_decoder_loss: 0.0554 - val_f_decoder_1_loss: 0.1885 - val_u_decoder_1_loss: 1.5142\n",
      "Epoch 228/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9641 - u_decoder_loss: 0.0786 - f_decoder_loss: 0.0615 - f_decoder_1_loss: 0.1353 - u_decoder_1_loss: 0.4965 - val_loss: 1.2568 - val_u_decoder_loss: 0.1419 - val_f_decoder_loss: 0.0979 - val_f_decoder_1_loss: 0.2565 - val_u_decoder_1_loss: 0.5794\n",
      "Epoch 229/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9643 - u_decoder_loss: 0.0971 - f_decoder_loss: 0.0609 - f_decoder_1_loss: 0.1033 - u_decoder_1_loss: 0.5264 - val_loss: 1.0073 - val_u_decoder_loss: 0.0983 - val_f_decoder_loss: 0.0365 - val_f_decoder_1_loss: 0.2044 - val_u_decoder_1_loss: 0.5144\n",
      "Epoch 230/500\n",
      "4798/4798 [==============================] - 1s 176us/sample - loss: 1.1714 - u_decoder_loss: 0.0924 - f_decoder_loss: 0.0676 - f_decoder_1_loss: 0.1506 - u_decoder_1_loss: 0.5941 - val_loss: 1.3626 - val_u_decoder_loss: 0.1432 - val_f_decoder_loss: 0.0501 - val_f_decoder_1_loss: 0.1828 - val_u_decoder_1_loss: 0.7516\n",
      "Epoch 231/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0381 - u_decoder_loss: 0.1042 - f_decoder_loss: 0.0678 - f_decoder_1_loss: 0.1050 - u_decoder_1_loss: 0.5430 - val_loss: 1.0941 - val_u_decoder_loss: 0.1037 - val_f_decoder_loss: 0.0612 - val_f_decoder_1_loss: 0.1780 - val_u_decoder_1_loss: 0.5352\n",
      "Epoch 232/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9322 - u_decoder_loss: 0.0782 - f_decoder_loss: 0.0546 - f_decoder_1_loss: 0.1232 - u_decoder_1_loss: 0.4724 - val_loss: 0.9797 - val_u_decoder_loss: 0.1064 - val_f_decoder_loss: 0.0305 - val_f_decoder_1_loss: 0.1316 - val_u_decoder_1_loss: 0.5241\n",
      "Epoch 233/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7932 - u_decoder_loss: 0.0677 - f_decoder_loss: 0.0460 - f_decoder_1_loss: 0.1008 - u_decoder_1_loss: 0.4331 - val_loss: 1.1298 - val_u_decoder_loss: 0.1232 - val_f_decoder_loss: 0.0533 - val_f_decoder_1_loss: 0.1499 - val_u_decoder_1_loss: 0.6264\n",
      "Epoch 234/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.1106 - u_decoder_loss: 0.0910 - f_decoder_loss: 0.0668 - f_decoder_1_loss: 0.1647 - u_decoder_1_loss: 0.5805 - val_loss: 1.2260 - val_u_decoder_loss: 0.1359 - val_f_decoder_loss: 0.0759 - val_f_decoder_1_loss: 0.2079 - val_u_decoder_1_loss: 0.5885\n",
      "Epoch 235/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8940 - u_decoder_loss: 0.0760 - f_decoder_loss: 0.0753 - f_decoder_1_loss: 0.1640 - u_decoder_1_loss: 0.4012 - val_loss: 1.7544 - val_u_decoder_loss: 0.1260 - val_f_decoder_loss: 0.1004 - val_f_decoder_1_loss: 0.3746 - val_u_decoder_1_loss: 0.8075\n",
      "Epoch 236/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.1351 - u_decoder_loss: 0.0965 - f_decoder_loss: 0.0803 - f_decoder_1_loss: 0.2099 - u_decoder_1_loss: 0.4653 - val_loss: 1.0717 - val_u_decoder_loss: 0.1369 - val_f_decoder_loss: 0.0392 - val_f_decoder_1_loss: 0.1792 - val_u_decoder_1_loss: 0.5459\n",
      "Epoch 237/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8172 - u_decoder_loss: 0.0737 - f_decoder_loss: 0.0410 - f_decoder_1_loss: 0.0949 - u_decoder_1_loss: 0.4315 - val_loss: 0.9544 - val_u_decoder_loss: 0.0669 - val_f_decoder_loss: 0.0311 - val_f_decoder_1_loss: 0.1767 - val_u_decoder_1_loss: 0.5272\n",
      "Epoch 238/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.0859 - u_decoder_loss: 0.1041 - f_decoder_loss: 0.0810 - f_decoder_1_loss: 0.1623 - u_decoder_1_loss: 0.4911 - val_loss: 1.3869 - val_u_decoder_loss: 0.1262 - val_f_decoder_loss: 0.1106 - val_f_decoder_1_loss: 0.2604 - val_u_decoder_1_loss: 0.6193\n",
      "Epoch 239/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.2601 - u_decoder_loss: 0.1279 - f_decoder_loss: 0.0697 - f_decoder_1_loss: 0.1784 - u_decoder_1_loss: 0.6076 - val_loss: 1.4211 - val_u_decoder_loss: 0.1383 - val_f_decoder_loss: 0.0985 - val_f_decoder_1_loss: 0.3494 - val_u_decoder_1_loss: 0.4868\n",
      "Epoch 240/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8914 - u_decoder_loss: 0.0758 - f_decoder_loss: 0.0578 - f_decoder_1_loss: 0.1305 - u_decoder_1_loss: 0.4362 - val_loss: 1.0088 - val_u_decoder_loss: 0.1218 - val_f_decoder_loss: 0.0505 - val_f_decoder_1_loss: 0.1405 - val_u_decoder_1_loss: 0.5119\n",
      "Epoch 241/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8694 - u_decoder_loss: 0.0855 - f_decoder_loss: 0.0583 - f_decoder_1_loss: 0.0911 - u_decoder_1_loss: 0.4758 - val_loss: 0.8566 - val_u_decoder_loss: 0.0863 - val_f_decoder_loss: 0.0290 - val_f_decoder_1_loss: 0.1296 - val_u_decoder_1_loss: 0.4801\n",
      "Epoch 242/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.7520 - u_decoder_loss: 0.0685 - f_decoder_loss: 0.0437 - f_decoder_1_loss: 0.0920 - u_decoder_1_loss: 0.3789 - val_loss: 0.8992 - val_u_decoder_loss: 0.1158 - val_f_decoder_loss: 0.0553 - val_f_decoder_1_loss: 0.1408 - val_u_decoder_1_loss: 0.4101\n",
      "Epoch 243/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9407 - u_decoder_loss: 0.0797 - f_decoder_loss: 0.0618 - f_decoder_1_loss: 0.0923 - u_decoder_1_loss: 0.5118 - val_loss: 1.3991 - val_u_decoder_loss: 0.1150 - val_f_decoder_loss: 0.1091 - val_f_decoder_1_loss: 0.2092 - val_u_decoder_1_loss: 0.6813\n",
      "Epoch 244/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0290 - u_decoder_loss: 0.0884 - f_decoder_loss: 0.0664 - f_decoder_1_loss: 0.1160 - u_decoder_1_loss: 0.5359 - val_loss: 1.0961 - val_u_decoder_loss: 0.1154 - val_f_decoder_loss: 0.0451 - val_f_decoder_1_loss: 0.2127 - val_u_decoder_1_loss: 0.5251\n",
      "Epoch 245/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.2920 - u_decoder_loss: 0.1136 - f_decoder_loss: 0.1000 - f_decoder_1_loss: 0.2352 - u_decoder_1_loss: 0.5512 - val_loss: 1.5481 - val_u_decoder_loss: 0.1465 - val_f_decoder_loss: 0.0968 - val_f_decoder_1_loss: 0.2969 - val_u_decoder_1_loss: 0.5683\n",
      "Epoch 246/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.3287 - u_decoder_loss: 0.1312 - f_decoder_loss: 0.0929 - f_decoder_1_loss: 0.1505 - u_decoder_1_loss: 0.6315 - val_loss: 1.1675 - val_u_decoder_loss: 0.1333 - val_f_decoder_loss: 0.0691 - val_f_decoder_1_loss: 0.2409 - val_u_decoder_1_loss: 0.4864\n",
      "Epoch 247/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 0.7703 - u_decoder_loss: 0.0650 - f_decoder_loss: 0.0510 - f_decoder_1_loss: 0.1133 - u_decoder_1_loss: 0.3769 - val_loss: 1.0770 - val_u_decoder_loss: 0.1260 - val_f_decoder_loss: 0.0704 - val_f_decoder_1_loss: 0.2314 - val_u_decoder_1_loss: 0.4882\n",
      "Epoch 248/500\n",
      "4798/4798 [==============================] - 1s 191us/sample - loss: 0.9555 - u_decoder_loss: 0.0811 - f_decoder_loss: 0.0569 - f_decoder_1_loss: 0.1133 - u_decoder_1_loss: 0.5265 - val_loss: 0.9525 - val_u_decoder_loss: 0.1141 - val_f_decoder_loss: 0.0289 - val_f_decoder_1_loss: 0.1114 - val_u_decoder_1_loss: 0.5383\n",
      "Epoch 249/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 0.8947 - u_decoder_loss: 0.0845 - f_decoder_loss: 0.0557 - f_decoder_1_loss: 0.1008 - u_decoder_1_loss: 0.5008 - val_loss: 1.1604 - val_u_decoder_loss: 0.1069 - val_f_decoder_loss: 0.0437 - val_f_decoder_1_loss: 0.1410 - val_u_decoder_1_loss: 0.6719\n",
      "Epoch 250/500\n",
      "4798/4798 [==============================] - 1s 193us/sample - loss: 0.9282 - u_decoder_loss: 0.0743 - f_decoder_loss: 0.0467 - f_decoder_1_loss: 0.1194 - u_decoder_1_loss: 0.4512 - val_loss: 1.1851 - val_u_decoder_loss: 0.1006 - val_f_decoder_loss: 0.0714 - val_f_decoder_1_loss: 0.2129 - val_u_decoder_1_loss: 0.5015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/500\n",
      "4798/4798 [==============================] - 1s 191us/sample - loss: 1.1285 - u_decoder_loss: 0.0870 - f_decoder_loss: 0.0997 - f_decoder_1_loss: 0.2152 - u_decoder_1_loss: 0.4425 - val_loss: 1.0154 - val_u_decoder_loss: 0.1021 - val_f_decoder_loss: 0.0485 - val_f_decoder_1_loss: 0.1934 - val_u_decoder_1_loss: 0.5105\n",
      "Epoch 252/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 0.7122 - u_decoder_loss: 0.0611 - f_decoder_loss: 0.0338 - f_decoder_1_loss: 0.0728 - u_decoder_1_loss: 0.4059 - val_loss: 1.0673 - val_u_decoder_loss: 0.1174 - val_f_decoder_loss: 0.0308 - val_f_decoder_1_loss: 0.1244 - val_u_decoder_1_loss: 0.6470\n",
      "Epoch 253/500\n",
      "4798/4798 [==============================] - 1s 190us/sample - loss: 0.7709 - u_decoder_loss: 0.0650 - f_decoder_loss: 0.0488 - f_decoder_1_loss: 0.0951 - u_decoder_1_loss: 0.4214 - val_loss: 1.0886 - val_u_decoder_loss: 0.0990 - val_f_decoder_loss: 0.1208 - val_f_decoder_1_loss: 0.2418 - val_u_decoder_1_loss: 0.4684\n",
      "Epoch 254/500\n",
      "4798/4798 [==============================] - 1s 191us/sample - loss: 1.0413 - u_decoder_loss: 0.0922 - f_decoder_loss: 0.0876 - f_decoder_1_loss: 0.2047 - u_decoder_1_loss: 0.4375 - val_loss: 1.3005 - val_u_decoder_loss: 0.1373 - val_f_decoder_loss: 0.0602 - val_f_decoder_1_loss: 0.1855 - val_u_decoder_1_loss: 0.7054\n",
      "Epoch 255/500\n",
      "4798/4798 [==============================] - 1s 188us/sample - loss: 1.0069 - u_decoder_loss: 0.0931 - f_decoder_loss: 0.0754 - f_decoder_1_loss: 0.1613 - u_decoder_1_loss: 0.4661 - val_loss: 0.8714 - val_u_decoder_loss: 0.0879 - val_f_decoder_loss: 0.0291 - val_f_decoder_1_loss: 0.1499 - val_u_decoder_1_loss: 0.4711\n",
      "Epoch 256/500\n",
      "4798/4798 [==============================] - 1s 189us/sample - loss: 0.6291 - u_decoder_loss: 0.0666 - f_decoder_loss: 0.0285 - f_decoder_1_loss: 0.0623 - u_decoder_1_loss: 0.3585 - val_loss: 1.1326 - val_u_decoder_loss: 0.1781 - val_f_decoder_loss: 0.0382 - val_f_decoder_1_loss: 0.1643 - val_u_decoder_1_loss: 0.5970\n",
      "Epoch 257/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 0.7780 - u_decoder_loss: 0.0787 - f_decoder_loss: 0.0556 - f_decoder_1_loss: 0.0791 - u_decoder_1_loss: 0.4115 - val_loss: 0.9521 - val_u_decoder_loss: 0.1224 - val_f_decoder_loss: 0.0460 - val_f_decoder_1_loss: 0.1067 - val_u_decoder_1_loss: 0.5405\n",
      "Epoch 258/500\n",
      "4798/4798 [==============================] - 1s 188us/sample - loss: 0.8911 - u_decoder_loss: 0.0716 - f_decoder_loss: 0.0661 - f_decoder_1_loss: 0.1298 - u_decoder_1_loss: 0.4452 - val_loss: 1.0879 - val_u_decoder_loss: 0.1170 - val_f_decoder_loss: 0.0463 - val_f_decoder_1_loss: 0.1092 - val_u_decoder_1_loss: 0.6352\n",
      "Epoch 259/500\n",
      "4798/4798 [==============================] - 1s 190us/sample - loss: 0.8277 - u_decoder_loss: 0.0741 - f_decoder_loss: 0.0504 - f_decoder_1_loss: 0.0690 - u_decoder_1_loss: 0.4599 - val_loss: 1.1069 - val_u_decoder_loss: 0.0828 - val_f_decoder_loss: 0.0478 - val_f_decoder_1_loss: 0.1323 - val_u_decoder_1_loss: 0.5814\n",
      "Epoch 260/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.1386 - u_decoder_loss: 0.1068 - f_decoder_loss: 0.0705 - f_decoder_1_loss: 0.1180 - u_decoder_1_loss: 0.5819 - val_loss: 1.1539 - val_u_decoder_loss: 0.1228 - val_f_decoder_loss: 0.0483 - val_f_decoder_1_loss: 0.1507 - val_u_decoder_1_loss: 0.6678\n",
      "Epoch 261/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.2699 - u_decoder_loss: 0.0999 - f_decoder_loss: 0.0818 - f_decoder_1_loss: 0.2092 - u_decoder_1_loss: 0.6251 - val_loss: 1.2415 - val_u_decoder_loss: 0.1195 - val_f_decoder_loss: 0.0677 - val_f_decoder_1_loss: 0.1813 - val_u_decoder_1_loss: 0.6298\n",
      "Epoch 262/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 1.2675 - u_decoder_loss: 0.0969 - f_decoder_loss: 0.0680 - f_decoder_1_loss: 0.1452 - u_decoder_1_loss: 0.6499 - val_loss: 1.4275 - val_u_decoder_loss: 0.1146 - val_f_decoder_loss: 0.0913 - val_f_decoder_1_loss: 0.2643 - val_u_decoder_1_loss: 0.6229\n",
      "Epoch 263/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 0.9074 - u_decoder_loss: 0.0772 - f_decoder_loss: 0.0502 - f_decoder_1_loss: 0.0775 - u_decoder_1_loss: 0.5256 - val_loss: 0.9802 - val_u_decoder_loss: 0.1033 - val_f_decoder_loss: 0.0394 - val_f_decoder_1_loss: 0.1330 - val_u_decoder_1_loss: 0.5512\n",
      "Epoch 264/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 0.7632 - u_decoder_loss: 0.0799 - f_decoder_loss: 0.0346 - f_decoder_1_loss: 0.0782 - u_decoder_1_loss: 0.4339 - val_loss: 0.9729 - val_u_decoder_loss: 0.0897 - val_f_decoder_loss: 0.0405 - val_f_decoder_1_loss: 0.1892 - val_u_decoder_1_loss: 0.4990\n",
      "Epoch 265/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.9546 - u_decoder_loss: 0.0877 - f_decoder_loss: 0.0597 - f_decoder_1_loss: 0.0934 - u_decoder_1_loss: 0.5123 - val_loss: 1.3396 - val_u_decoder_loss: 0.1655 - val_f_decoder_loss: 0.0794 - val_f_decoder_1_loss: 0.2604 - val_u_decoder_1_loss: 0.5802\n",
      "Epoch 266/500\n",
      "4798/4798 [==============================] - 1s 186us/sample - loss: 0.7673 - u_decoder_loss: 0.0672 - f_decoder_loss: 0.0445 - f_decoder_1_loss: 0.0989 - u_decoder_1_loss: 0.3703 - val_loss: 1.1245 - val_u_decoder_loss: 0.0864 - val_f_decoder_loss: 0.0754 - val_f_decoder_1_loss: 0.2028 - val_u_decoder_1_loss: 0.5038\n",
      "Epoch 267/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8889 - u_decoder_loss: 0.0768 - f_decoder_loss: 0.0671 - f_decoder_1_loss: 0.1539 - u_decoder_1_loss: 0.3888 - val_loss: 1.2512 - val_u_decoder_loss: 0.1210 - val_f_decoder_loss: 0.0829 - val_f_decoder_1_loss: 0.1744 - val_u_decoder_1_loss: 0.6118\n",
      "Epoch 268/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9053 - u_decoder_loss: 0.0653 - f_decoder_loss: 0.0972 - f_decoder_1_loss: 0.1514 - u_decoder_1_loss: 0.4242 - val_loss: 1.8975 - val_u_decoder_loss: 0.1886 - val_f_decoder_loss: 0.1243 - val_f_decoder_1_loss: 0.7468 - val_u_decoder_1_loss: 0.5193\n",
      "Epoch 269/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9544 - u_decoder_loss: 0.0816 - f_decoder_loss: 0.0621 - f_decoder_1_loss: 0.1431 - u_decoder_1_loss: 0.4445 - val_loss: 1.2877 - val_u_decoder_loss: 0.1133 - val_f_decoder_loss: 0.0704 - val_f_decoder_1_loss: 0.2011 - val_u_decoder_1_loss: 0.6020\n",
      "Epoch 270/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.8704 - u_decoder_loss: 0.0720 - f_decoder_loss: 0.0595 - f_decoder_1_loss: 0.1255 - u_decoder_1_loss: 0.4072 - val_loss: 1.0495 - val_u_decoder_loss: 0.1237 - val_f_decoder_loss: 0.0505 - val_f_decoder_1_loss: 0.1701 - val_u_decoder_1_loss: 0.5364\n",
      "Epoch 271/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9548 - u_decoder_loss: 0.1027 - f_decoder_loss: 0.0847 - f_decoder_1_loss: 0.1800 - u_decoder_1_loss: 0.4054 - val_loss: 0.9168 - val_u_decoder_loss: 0.1301 - val_f_decoder_loss: 0.0366 - val_f_decoder_1_loss: 0.1302 - val_u_decoder_1_loss: 0.4587\n",
      "Epoch 272/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.9423 - u_decoder_loss: 0.0807 - f_decoder_loss: 0.0795 - f_decoder_1_loss: 0.2145 - u_decoder_1_loss: 0.3747 - val_loss: 1.9899 - val_u_decoder_loss: 0.1608 - val_f_decoder_loss: 0.1049 - val_f_decoder_1_loss: 0.5753 - val_u_decoder_1_loss: 0.7468\n",
      "Epoch 273/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.2047 - u_decoder_loss: 0.1244 - f_decoder_loss: 0.0812 - f_decoder_1_loss: 0.1563 - u_decoder_1_loss: 0.5685 - val_loss: 2.0764 - val_u_decoder_loss: 0.1097 - val_f_decoder_loss: 0.5801 - val_f_decoder_1_loss: 0.1696 - val_u_decoder_1_loss: 0.7992\n",
      "Epoch 274/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8362 - u_decoder_loss: 0.0611 - f_decoder_loss: 0.0753 - f_decoder_1_loss: 0.1323 - u_decoder_1_loss: 0.4206 - val_loss: 0.9696 - val_u_decoder_loss: 0.1096 - val_f_decoder_loss: 0.0278 - val_f_decoder_1_loss: 0.1171 - val_u_decoder_1_loss: 0.5562\n",
      "Epoch 275/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 0.9664 - u_decoder_loss: 0.1104 - f_decoder_loss: 0.0442 - f_decoder_1_loss: 0.1037 - u_decoder_1_loss: 0.5098 - val_loss: 1.2569 - val_u_decoder_loss: 0.1313 - val_f_decoder_loss: 0.1480 - val_f_decoder_1_loss: 0.2290 - val_u_decoder_1_loss: 0.5025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0580 - u_decoder_loss: 0.0803 - f_decoder_loss: 0.0813 - f_decoder_1_loss: 0.1763 - u_decoder_1_loss: 0.4079 - val_loss: 1.0441 - val_u_decoder_loss: 0.0896 - val_f_decoder_loss: 0.0465 - val_f_decoder_1_loss: 0.2025 - val_u_decoder_1_loss: 0.5239\n",
      "Epoch 277/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.6953 - u_decoder_loss: 0.0693 - f_decoder_loss: 0.0335 - f_decoder_1_loss: 0.0691 - u_decoder_1_loss: 0.3776 - val_loss: 1.0016 - val_u_decoder_loss: 0.0946 - val_f_decoder_loss: 0.0465 - val_f_decoder_1_loss: 0.2069 - val_u_decoder_1_loss: 0.4889\n",
      "Epoch 278/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.6416 - u_decoder_loss: 0.0568 - f_decoder_loss: 0.0352 - f_decoder_1_loss: 0.0638 - u_decoder_1_loss: 0.3818 - val_loss: 0.9028 - val_u_decoder_loss: 0.0852 - val_f_decoder_loss: 0.0265 - val_f_decoder_1_loss: 0.1503 - val_u_decoder_1_loss: 0.4927\n",
      "Epoch 279/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7697 - u_decoder_loss: 0.0832 - f_decoder_loss: 0.0355 - f_decoder_1_loss: 0.0645 - u_decoder_1_loss: 0.4569 - val_loss: 1.7871 - val_u_decoder_loss: 0.1205 - val_f_decoder_loss: 0.0431 - val_f_decoder_1_loss: 0.1664 - val_u_decoder_1_loss: 1.1882\n",
      "Epoch 280/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0236 - u_decoder_loss: 0.0938 - f_decoder_loss: 0.0841 - f_decoder_1_loss: 0.1534 - u_decoder_1_loss: 0.5056 - val_loss: 1.0514 - val_u_decoder_loss: 0.1068 - val_f_decoder_loss: 0.0926 - val_f_decoder_1_loss: 0.1932 - val_u_decoder_1_loss: 0.4764\n",
      "Epoch 281/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 1.0994 - u_decoder_loss: 0.0701 - f_decoder_loss: 0.0954 - f_decoder_1_loss: 0.2639 - u_decoder_1_loss: 0.4221 - val_loss: 1.9235 - val_u_decoder_loss: 0.1061 - val_f_decoder_loss: 0.1294 - val_f_decoder_1_loss: 0.5848 - val_u_decoder_1_loss: 0.7360\n",
      "Epoch 282/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9907 - u_decoder_loss: 0.0799 - f_decoder_loss: 0.0945 - f_decoder_1_loss: 0.1902 - u_decoder_1_loss: 0.4450 - val_loss: 1.0470 - val_u_decoder_loss: 0.1036 - val_f_decoder_loss: 0.0990 - val_f_decoder_1_loss: 0.1598 - val_u_decoder_1_loss: 0.5114\n",
      "Epoch 283/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6993 - u_decoder_loss: 0.0568 - f_decoder_loss: 0.0430 - f_decoder_1_loss: 0.0960 - u_decoder_1_loss: 0.3665 - val_loss: 1.3158 - val_u_decoder_loss: 0.1191 - val_f_decoder_loss: 0.0628 - val_f_decoder_1_loss: 0.2384 - val_u_decoder_1_loss: 0.6543\n",
      "Epoch 284/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8313 - u_decoder_loss: 0.0743 - f_decoder_loss: 0.0468 - f_decoder_1_loss: 0.1274 - u_decoder_1_loss: 0.4223 - val_loss: 1.1097 - val_u_decoder_loss: 0.0981 - val_f_decoder_loss: 0.0810 - val_f_decoder_1_loss: 0.2388 - val_u_decoder_1_loss: 0.5023\n",
      "Epoch 285/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0247 - u_decoder_loss: 0.0925 - f_decoder_loss: 0.0886 - f_decoder_1_loss: 0.1459 - u_decoder_1_loss: 0.4943 - val_loss: 0.9447 - val_u_decoder_loss: 0.1058 - val_f_decoder_loss: 0.0623 - val_f_decoder_1_loss: 0.1630 - val_u_decoder_1_loss: 0.4341\n",
      "Epoch 286/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6682 - u_decoder_loss: 0.0673 - f_decoder_loss: 0.0436 - f_decoder_1_loss: 0.0771 - u_decoder_1_loss: 0.3543 - val_loss: 1.1206 - val_u_decoder_loss: 0.1016 - val_f_decoder_loss: 0.0413 - val_f_decoder_1_loss: 0.1566 - val_u_decoder_1_loss: 0.5773\n",
      "Epoch 287/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0495 - u_decoder_loss: 0.0804 - f_decoder_loss: 0.0893 - f_decoder_1_loss: 0.1498 - u_decoder_1_loss: 0.4535 - val_loss: 1.4817 - val_u_decoder_loss: 0.1294 - val_f_decoder_loss: 0.2471 - val_f_decoder_1_loss: 0.2086 - val_u_decoder_1_loss: 0.5881\n",
      "Epoch 288/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.9166 - u_decoder_loss: 0.0772 - f_decoder_loss: 0.0678 - f_decoder_1_loss: 0.1095 - u_decoder_1_loss: 0.4546 - val_loss: 1.0805 - val_u_decoder_loss: 0.1054 - val_f_decoder_loss: 0.0443 - val_f_decoder_1_loss: 0.1826 - val_u_decoder_1_loss: 0.5316\n",
      "Epoch 289/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0016 - u_decoder_loss: 0.0812 - f_decoder_loss: 0.0735 - f_decoder_1_loss: 0.1490 - u_decoder_1_loss: 0.4897 - val_loss: 1.0975 - val_u_decoder_loss: 0.1325 - val_f_decoder_loss: 0.0423 - val_f_decoder_1_loss: 0.1430 - val_u_decoder_1_loss: 0.6017\n",
      "Epoch 290/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.9153 - u_decoder_loss: 0.0866 - f_decoder_loss: 0.0496 - f_decoder_1_loss: 0.0781 - u_decoder_1_loss: 0.5261 - val_loss: 1.4723 - val_u_decoder_loss: 0.1251 - val_f_decoder_loss: 0.0449 - val_f_decoder_1_loss: 0.1609 - val_u_decoder_1_loss: 0.9165\n",
      "Epoch 291/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 1.0027 - u_decoder_loss: 0.0864 - f_decoder_loss: 0.0764 - f_decoder_1_loss: 0.1478 - u_decoder_1_loss: 0.5002 - val_loss: 1.0104 - val_u_decoder_loss: 0.1103 - val_f_decoder_loss: 0.0471 - val_f_decoder_1_loss: 0.1475 - val_u_decoder_1_loss: 0.5178\n",
      "Epoch 292/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9153 - u_decoder_loss: 0.0872 - f_decoder_loss: 0.0490 - f_decoder_1_loss: 0.1093 - u_decoder_1_loss: 0.4317 - val_loss: 1.0616 - val_u_decoder_loss: 0.1148 - val_f_decoder_loss: 0.0493 - val_f_decoder_1_loss: 0.2081 - val_u_decoder_1_loss: 0.4413\n",
      "Epoch 293/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.7180 - u_decoder_loss: 0.1110 - f_decoder_loss: 0.2393 - f_decoder_1_loss: 0.5079 - u_decoder_1_loss: 0.4434 - val_loss: 1.0973 - val_u_decoder_loss: 0.1138 - val_f_decoder_loss: 0.0527 - val_f_decoder_1_loss: 0.2356 - val_u_decoder_1_loss: 0.4990\n",
      "Epoch 294/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.7744 - u_decoder_loss: 0.0727 - f_decoder_loss: 0.0376 - f_decoder_1_loss: 0.1087 - u_decoder_1_loss: 0.4097 - val_loss: 2.1192 - val_u_decoder_loss: 0.1674 - val_f_decoder_loss: 0.1029 - val_f_decoder_1_loss: 0.1832 - val_u_decoder_1_loss: 1.2655\n",
      "Epoch 295/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9369 - u_decoder_loss: 0.0803 - f_decoder_loss: 0.0487 - f_decoder_1_loss: 0.1069 - u_decoder_1_loss: 0.5013 - val_loss: 0.9721 - val_u_decoder_loss: 0.1188 - val_f_decoder_loss: 0.0298 - val_f_decoder_1_loss: 0.1297 - val_u_decoder_1_loss: 0.5376\n",
      "Epoch 296/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8467 - u_decoder_loss: 0.0769 - f_decoder_loss: 0.0402 - f_decoder_1_loss: 0.1047 - u_decoder_1_loss: 0.4657 - val_loss: 1.0454 - val_u_decoder_loss: 0.1396 - val_f_decoder_loss: 0.0402 - val_f_decoder_1_loss: 0.1602 - val_u_decoder_1_loss: 0.5218\n",
      "Epoch 297/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8848 - u_decoder_loss: 0.0825 - f_decoder_loss: 0.0449 - f_decoder_1_loss: 0.0873 - u_decoder_1_loss: 0.5053 - val_loss: 1.4473 - val_u_decoder_loss: 0.1086 - val_f_decoder_loss: 0.0888 - val_f_decoder_1_loss: 0.3277 - val_u_decoder_1_loss: 0.6261\n",
      "Epoch 298/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8589 - u_decoder_loss: 0.0692 - f_decoder_loss: 0.0753 - f_decoder_1_loss: 0.1349 - u_decoder_1_loss: 0.4103 - val_loss: 0.8889 - val_u_decoder_loss: 0.0873 - val_f_decoder_loss: 0.0344 - val_f_decoder_1_loss: 0.1310 - val_u_decoder_1_loss: 0.4976\n",
      "Epoch 299/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7346 - u_decoder_loss: 0.0738 - f_decoder_loss: 0.0353 - f_decoder_1_loss: 0.0638 - u_decoder_1_loss: 0.4329 - val_loss: 1.0149 - val_u_decoder_loss: 0.0942 - val_f_decoder_loss: 0.0300 - val_f_decoder_1_loss: 0.1720 - val_u_decoder_1_loss: 0.5660\n",
      "Epoch 300/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9560 - u_decoder_loss: 0.0687 - f_decoder_loss: 0.0591 - f_decoder_1_loss: 0.1530 - u_decoder_1_loss: 0.4316 - val_loss: 1.7762 - val_u_decoder_loss: 0.2341 - val_f_decoder_loss: 0.1015 - val_f_decoder_1_loss: 0.3126 - val_u_decoder_1_loss: 0.6979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8284 - u_decoder_loss: 0.0740 - f_decoder_loss: 0.0743 - f_decoder_1_loss: 0.1024 - u_decoder_1_loss: 0.3973 - val_loss: 0.8593 - val_u_decoder_loss: 0.0803 - val_f_decoder_loss: 0.0314 - val_f_decoder_1_loss: 0.1383 - val_u_decoder_1_loss: 0.4681\n",
      "Epoch 302/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8743 - u_decoder_loss: 0.0871 - f_decoder_loss: 0.0477 - f_decoder_1_loss: 0.0919 - u_decoder_1_loss: 0.4910 - val_loss: 0.9893 - val_u_decoder_loss: 0.1187 - val_f_decoder_loss: 0.0514 - val_f_decoder_1_loss: 0.1756 - val_u_decoder_1_loss: 0.4634\n",
      "Epoch 303/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8578 - u_decoder_loss: 0.0785 - f_decoder_loss: 0.0457 - f_decoder_1_loss: 0.1051 - u_decoder_1_loss: 0.4679 - val_loss: 0.8886 - val_u_decoder_loss: 0.1089 - val_f_decoder_loss: 0.0299 - val_f_decoder_1_loss: 0.1170 - val_u_decoder_1_loss: 0.5029\n",
      "Epoch 304/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7411 - u_decoder_loss: 0.0725 - f_decoder_loss: 0.0383 - f_decoder_1_loss: 0.0754 - u_decoder_1_loss: 0.4192 - val_loss: 1.0588 - val_u_decoder_loss: 0.1282 - val_f_decoder_loss: 0.0363 - val_f_decoder_1_loss: 0.1447 - val_u_decoder_1_loss: 0.5342\n",
      "Epoch 305/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.8868 - u_decoder_loss: 0.0627 - f_decoder_loss: 0.0540 - f_decoder_1_loss: 0.1416 - u_decoder_1_loss: 0.3762 - val_loss: 0.9665 - val_u_decoder_loss: 0.1188 - val_f_decoder_loss: 0.0384 - val_f_decoder_1_loss: 0.2008 - val_u_decoder_1_loss: 0.4210\n",
      "Epoch 306/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7419 - u_decoder_loss: 0.0623 - f_decoder_loss: 0.0448 - f_decoder_1_loss: 0.0998 - u_decoder_1_loss: 0.4011 - val_loss: 0.9229 - val_u_decoder_loss: 0.1042 - val_f_decoder_loss: 0.0508 - val_f_decoder_1_loss: 0.1616 - val_u_decoder_1_loss: 0.4712\n",
      "Epoch 307/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.7666 - u_decoder_loss: 0.1801 - f_decoder_loss: 0.1398 - f_decoder_1_loss: 0.2682 - u_decoder_1_loss: 0.6796 - val_loss: 2.0110 - val_u_decoder_loss: 0.1589 - val_f_decoder_loss: 0.1118 - val_f_decoder_1_loss: 0.2468 - val_u_decoder_1_loss: 1.0221\n",
      "Epoch 308/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.8549 - u_decoder_loss: 0.0872 - f_decoder_loss: 0.0525 - f_decoder_1_loss: 0.1221 - u_decoder_1_loss: 0.4215 - val_loss: 0.8877 - val_u_decoder_loss: 0.0824 - val_f_decoder_loss: 0.0436 - val_f_decoder_1_loss: 0.1415 - val_u_decoder_1_loss: 0.4623\n",
      "Epoch 309/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7711 - u_decoder_loss: 0.0619 - f_decoder_loss: 0.0414 - f_decoder_1_loss: 0.0978 - u_decoder_1_loss: 0.4194 - val_loss: 0.9787 - val_u_decoder_loss: 0.0881 - val_f_decoder_loss: 0.0379 - val_f_decoder_1_loss: 0.1261 - val_u_decoder_1_loss: 0.5538\n",
      "Epoch 310/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6495 - u_decoder_loss: 0.0540 - f_decoder_loss: 0.0341 - f_decoder_1_loss: 0.0788 - u_decoder_1_loss: 0.3603 - val_loss: 0.9514 - val_u_decoder_loss: 0.1055 - val_f_decoder_loss: 0.0661 - val_f_decoder_1_loss: 0.1749 - val_u_decoder_1_loss: 0.4516\n",
      "Epoch 311/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.5464 - u_decoder_loss: 0.0539 - f_decoder_loss: 0.0307 - f_decoder_1_loss: 0.0543 - u_decoder_1_loss: 0.3105 - val_loss: 1.2107 - val_u_decoder_loss: 0.0923 - val_f_decoder_loss: 0.0296 - val_f_decoder_1_loss: 0.1135 - val_u_decoder_1_loss: 0.7954\n",
      "Epoch 312/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8851 - u_decoder_loss: 0.0902 - f_decoder_loss: 0.0442 - f_decoder_1_loss: 0.0977 - u_decoder_1_loss: 0.4740 - val_loss: 1.1982 - val_u_decoder_loss: 0.1560 - val_f_decoder_loss: 0.0542 - val_f_decoder_1_loss: 0.2717 - val_u_decoder_1_loss: 0.4367\n",
      "Epoch 313/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.9596 - u_decoder_loss: 0.0825 - f_decoder_loss: 0.0829 - f_decoder_1_loss: 0.2059 - u_decoder_1_loss: 0.3825 - val_loss: 1.2756 - val_u_decoder_loss: 0.1422 - val_f_decoder_loss: 0.0690 - val_f_decoder_1_loss: 0.2271 - val_u_decoder_1_loss: 0.6209\n",
      "Epoch 314/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.8518 - u_decoder_loss: 0.0844 - f_decoder_loss: 0.0554 - f_decoder_1_loss: 0.1509 - u_decoder_1_loss: 0.4090 - val_loss: 1.2103 - val_u_decoder_loss: 0.1196 - val_f_decoder_loss: 0.0722 - val_f_decoder_1_loss: 0.2368 - val_u_decoder_1_loss: 0.5648\n",
      "Epoch 315/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.8759 - u_decoder_loss: 0.0734 - f_decoder_loss: 0.0610 - f_decoder_1_loss: 0.1663 - u_decoder_1_loss: 0.4028 - val_loss: 1.2430 - val_u_decoder_loss: 0.1144 - val_f_decoder_loss: 0.1238 - val_f_decoder_1_loss: 0.2992 - val_u_decoder_1_loss: 0.4905\n",
      "Epoch 316/500\n",
      "4798/4798 [==============================] - 1s 176us/sample - loss: 0.9198 - u_decoder_loss: 0.0825 - f_decoder_loss: 0.0642 - f_decoder_1_loss: 0.1011 - u_decoder_1_loss: 0.4555 - val_loss: 1.2874 - val_u_decoder_loss: 0.1080 - val_f_decoder_loss: 0.0671 - val_f_decoder_1_loss: 0.2185 - val_u_decoder_1_loss: 0.6432\n",
      "Epoch 317/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7078 - u_decoder_loss: 0.0664 - f_decoder_loss: 0.0433 - f_decoder_1_loss: 0.0673 - u_decoder_1_loss: 0.3915 - val_loss: 0.9358 - val_u_decoder_loss: 0.0896 - val_f_decoder_loss: 0.0231 - val_f_decoder_1_loss: 0.0937 - val_u_decoder_1_loss: 0.5702\n",
      "Epoch 318/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7689 - u_decoder_loss: 0.0637 - f_decoder_loss: 0.0487 - f_decoder_1_loss: 0.0866 - u_decoder_1_loss: 0.4252 - val_loss: 1.2365 - val_u_decoder_loss: 0.1210 - val_f_decoder_loss: 0.0878 - val_f_decoder_1_loss: 0.2582 - val_u_decoder_1_loss: 0.5608\n",
      "Epoch 319/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9510 - u_decoder_loss: 0.0753 - f_decoder_loss: 0.0884 - f_decoder_1_loss: 0.1949 - u_decoder_1_loss: 0.4132 - val_loss: 0.7416 - val_u_decoder_loss: 0.0672 - val_f_decoder_loss: 0.0252 - val_f_decoder_1_loss: 0.0957 - val_u_decoder_1_loss: 0.4501\n",
      "Epoch 320/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6967 - u_decoder_loss: 0.0663 - f_decoder_loss: 0.0350 - f_decoder_1_loss: 0.0664 - u_decoder_1_loss: 0.4062 - val_loss: 1.5947 - val_u_decoder_loss: 0.1502 - val_f_decoder_loss: 0.0610 - val_f_decoder_1_loss: 0.2068 - val_u_decoder_1_loss: 0.8516\n",
      "Epoch 321/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 1.0227 - u_decoder_loss: 0.0867 - f_decoder_loss: 0.0416 - f_decoder_1_loss: 0.1343 - u_decoder_1_loss: 0.5206 - val_loss: 1.7895 - val_u_decoder_loss: 0.1472 - val_f_decoder_loss: 0.0702 - val_f_decoder_1_loss: 0.5450 - val_u_decoder_1_loss: 0.5831\n",
      "Epoch 322/500\n",
      "4798/4798 [==============================] - 1s 176us/sample - loss: 1.5596 - u_decoder_loss: 0.1189 - f_decoder_loss: 0.1407 - f_decoder_1_loss: 0.3053 - u_decoder_1_loss: 0.6408 - val_loss: 1.2653 - val_u_decoder_loss: 0.0949 - val_f_decoder_loss: 0.1142 - val_f_decoder_1_loss: 0.2100 - val_u_decoder_1_loss: 0.6548\n",
      "Epoch 323/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.7823 - u_decoder_loss: 0.0683 - f_decoder_loss: 0.0465 - f_decoder_1_loss: 0.0855 - u_decoder_1_loss: 0.4076 - val_loss: 0.9090 - val_u_decoder_loss: 0.0550 - val_f_decoder_loss: 0.0291 - val_f_decoder_1_loss: 0.1711 - val_u_decoder_1_loss: 0.4955\n",
      "Epoch 324/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.6913 - u_decoder_loss: 0.0603 - f_decoder_loss: 0.0290 - f_decoder_1_loss: 0.0628 - u_decoder_1_loss: 0.4194 - val_loss: 0.9446 - val_u_decoder_loss: 0.1051 - val_f_decoder_loss: 0.0485 - val_f_decoder_1_loss: 0.1367 - val_u_decoder_1_loss: 0.5389\n",
      "Epoch 325/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7750 - u_decoder_loss: 0.0796 - f_decoder_loss: 0.0372 - f_decoder_1_loss: 0.0642 - u_decoder_1_loss: 0.4572 - val_loss: 0.9918 - val_u_decoder_loss: 0.0899 - val_f_decoder_loss: 0.0450 - val_f_decoder_1_loss: 0.1338 - val_u_decoder_1_loss: 0.5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.8708 - u_decoder_loss: 0.0763 - f_decoder_loss: 0.0494 - f_decoder_1_loss: 0.1063 - u_decoder_1_loss: 0.4707 - val_loss: 1.1741 - val_u_decoder_loss: 0.0737 - val_f_decoder_loss: 0.0459 - val_f_decoder_1_loss: 0.1860 - val_u_decoder_1_loss: 0.6978\n",
      "Epoch 327/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8305 - u_decoder_loss: 0.0796 - f_decoder_loss: 0.0396 - f_decoder_1_loss: 0.0837 - u_decoder_1_loss: 0.4726 - val_loss: 0.9825 - val_u_decoder_loss: 0.0786 - val_f_decoder_loss: 0.0473 - val_f_decoder_1_loss: 0.1052 - val_u_decoder_1_loss: 0.5994\n",
      "Epoch 328/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7342 - u_decoder_loss: 0.0588 - f_decoder_loss: 0.0482 - f_decoder_1_loss: 0.0973 - u_decoder_1_loss: 0.4128 - val_loss: 1.2968 - val_u_decoder_loss: 0.0737 - val_f_decoder_loss: 0.0838 - val_f_decoder_1_loss: 0.2051 - val_u_decoder_1_loss: 0.7153\n",
      "Epoch 329/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9875 - u_decoder_loss: 0.0819 - f_decoder_loss: 0.0664 - f_decoder_1_loss: 0.1064 - u_decoder_1_loss: 0.5184 - val_loss: 1.4759 - val_u_decoder_loss: 0.1202 - val_f_decoder_loss: 0.0689 - val_f_decoder_1_loss: 0.1440 - val_u_decoder_1_loss: 0.7981\n",
      "Epoch 330/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0364 - u_decoder_loss: 0.0863 - f_decoder_loss: 0.0681 - f_decoder_1_loss: 0.1984 - u_decoder_1_loss: 0.4621 - val_loss: 1.4621 - val_u_decoder_loss: 0.1392 - val_f_decoder_loss: 0.1169 - val_f_decoder_1_loss: 0.3218 - val_u_decoder_1_loss: 0.5357\n",
      "Epoch 331/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8519 - u_decoder_loss: 0.0708 - f_decoder_loss: 0.0600 - f_decoder_1_loss: 0.1112 - u_decoder_1_loss: 0.4491 - val_loss: 1.2093 - val_u_decoder_loss: 0.0958 - val_f_decoder_loss: 0.0478 - val_f_decoder_1_loss: 0.1791 - val_u_decoder_1_loss: 0.6798\n",
      "Epoch 332/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.4763 - u_decoder_loss: 0.1058 - f_decoder_loss: 0.1352 - f_decoder_1_loss: 0.3896 - u_decoder_1_loss: 0.4742 - val_loss: 1.1773 - val_u_decoder_loss: 0.0947 - val_f_decoder_loss: 0.0787 - val_f_decoder_1_loss: 0.2146 - val_u_decoder_1_loss: 0.5165\n",
      "Epoch 333/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9059 - u_decoder_loss: 0.0843 - f_decoder_loss: 0.0588 - f_decoder_1_loss: 0.1231 - u_decoder_1_loss: 0.4693 - val_loss: 1.0006 - val_u_decoder_loss: 0.1064 - val_f_decoder_loss: 0.0439 - val_f_decoder_1_loss: 0.1159 - val_u_decoder_1_loss: 0.5484\n",
      "Epoch 334/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.7154 - u_decoder_loss: 0.0697 - f_decoder_loss: 0.0378 - f_decoder_1_loss: 0.0775 - u_decoder_1_loss: 0.3947 - val_loss: 0.9313 - val_u_decoder_loss: 0.1035 - val_f_decoder_loss: 0.0422 - val_f_decoder_1_loss: 0.1476 - val_u_decoder_1_loss: 0.4908\n",
      "Epoch 335/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.8050 - u_decoder_loss: 0.0738 - f_decoder_loss: 0.0489 - f_decoder_1_loss: 0.0797 - u_decoder_1_loss: 0.4473 - val_loss: 0.9203 - val_u_decoder_loss: 0.1026 - val_f_decoder_loss: 0.0471 - val_f_decoder_1_loss: 0.1302 - val_u_decoder_1_loss: 0.5041\n",
      "Epoch 336/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8227 - u_decoder_loss: 0.0672 - f_decoder_loss: 0.0467 - f_decoder_1_loss: 0.0755 - u_decoder_1_loss: 0.4069 - val_loss: 0.8801 - val_u_decoder_loss: 0.0915 - val_f_decoder_loss: 0.0483 - val_f_decoder_1_loss: 0.1344 - val_u_decoder_1_loss: 0.4587\n",
      "Epoch 337/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.5932 - u_decoder_loss: 0.0494 - f_decoder_loss: 0.0257 - f_decoder_1_loss: 0.0396 - u_decoder_1_loss: 0.3758 - val_loss: 0.8437 - val_u_decoder_loss: 0.0804 - val_f_decoder_loss: 0.0357 - val_f_decoder_1_loss: 0.1166 - val_u_decoder_1_loss: 0.5043\n",
      "Epoch 338/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 1.0542 - u_decoder_loss: 0.1216 - f_decoder_loss: 0.0686 - f_decoder_1_loss: 0.1793 - u_decoder_1_loss: 0.4716 - val_loss: 2.4523 - val_u_decoder_loss: 0.2467 - val_f_decoder_loss: 0.4412 - val_f_decoder_1_loss: 0.5863 - val_u_decoder_1_loss: 0.7876\n",
      "Epoch 339/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2567 - u_decoder_loss: 0.1165 - f_decoder_loss: 0.1261 - f_decoder_1_loss: 0.2485 - u_decoder_1_loss: 0.5185 - val_loss: 0.9664 - val_u_decoder_loss: 0.1019 - val_f_decoder_loss: 0.0489 - val_f_decoder_1_loss: 0.1502 - val_u_decoder_1_loss: 0.5060\n",
      "Epoch 340/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7594 - u_decoder_loss: 0.0800 - f_decoder_loss: 0.0415 - f_decoder_1_loss: 0.0866 - u_decoder_1_loss: 0.4164 - val_loss: 0.8282 - val_u_decoder_loss: 0.0651 - val_f_decoder_loss: 0.0225 - val_f_decoder_1_loss: 0.1167 - val_u_decoder_1_loss: 0.4904\n",
      "Epoch 341/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.6383 - u_decoder_loss: 0.0633 - f_decoder_loss: 0.0253 - f_decoder_1_loss: 0.0498 - u_decoder_1_loss: 0.3970 - val_loss: 0.9821 - val_u_decoder_loss: 0.0645 - val_f_decoder_loss: 0.0382 - val_f_decoder_1_loss: 0.1964 - val_u_decoder_1_loss: 0.5238\n",
      "Epoch 342/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7925 - u_decoder_loss: 0.0572 - f_decoder_loss: 0.0460 - f_decoder_1_loss: 0.1528 - u_decoder_1_loss: 0.4012 - val_loss: 1.0911 - val_u_decoder_loss: 0.0912 - val_f_decoder_loss: 0.0286 - val_f_decoder_1_loss: 0.1426 - val_u_decoder_1_loss: 0.6630\n",
      "Epoch 343/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 0.8390 - u_decoder_loss: 0.0729 - f_decoder_loss: 0.0502 - f_decoder_1_loss: 0.1006 - u_decoder_1_loss: 0.4146 - val_loss: 1.0214 - val_u_decoder_loss: 0.0586 - val_f_decoder_loss: 0.0529 - val_f_decoder_1_loss: 0.2452 - val_u_decoder_1_loss: 0.4532\n",
      "Epoch 344/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8756 - u_decoder_loss: 0.0674 - f_decoder_loss: 0.0503 - f_decoder_1_loss: 0.0905 - u_decoder_1_loss: 0.4878 - val_loss: 1.4782 - val_u_decoder_loss: 0.1695 - val_f_decoder_loss: 0.0662 - val_f_decoder_1_loss: 0.1519 - val_u_decoder_1_loss: 0.8007\n",
      "Epoch 345/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8460 - u_decoder_loss: 0.0865 - f_decoder_loss: 0.0458 - f_decoder_1_loss: 0.0802 - u_decoder_1_loss: 0.4733 - val_loss: 0.8971 - val_u_decoder_loss: 0.0856 - val_f_decoder_loss: 0.0336 - val_f_decoder_1_loss: 0.1379 - val_u_decoder_1_loss: 0.4880\n",
      "Epoch 346/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.7266 - u_decoder_loss: 0.0890 - f_decoder_loss: 0.0364 - f_decoder_1_loss: 0.0795 - u_decoder_1_loss: 0.3770 - val_loss: 1.2105 - val_u_decoder_loss: 0.0778 - val_f_decoder_loss: 0.0774 - val_f_decoder_1_loss: 0.2779 - val_u_decoder_1_loss: 0.5549\n",
      "Epoch 347/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9262 - u_decoder_loss: 0.0756 - f_decoder_loss: 0.0688 - f_decoder_1_loss: 0.1196 - u_decoder_1_loss: 0.4571 - val_loss: 0.9353 - val_u_decoder_loss: 0.0875 - val_f_decoder_loss: 0.0460 - val_f_decoder_1_loss: 0.1596 - val_u_decoder_1_loss: 0.4829\n",
      "Epoch 348/500\n",
      "4798/4798 [==============================] - 1s 187us/sample - loss: 1.0298 - u_decoder_loss: 0.0956 - f_decoder_loss: 0.0576 - f_decoder_1_loss: 0.1642 - u_decoder_1_loss: 0.4542 - val_loss: 1.3263 - val_u_decoder_loss: 0.1130 - val_f_decoder_loss: 0.0892 - val_f_decoder_1_loss: 0.2820 - val_u_decoder_1_loss: 0.5443\n",
      "Epoch 349/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8592 - u_decoder_loss: 0.0711 - f_decoder_loss: 0.0547 - f_decoder_1_loss: 0.1149 - u_decoder_1_loss: 0.4434 - val_loss: 1.0341 - val_u_decoder_loss: 0.0728 - val_f_decoder_loss: 0.0310 - val_f_decoder_1_loss: 0.1800 - val_u_decoder_1_loss: 0.5765\n",
      "Epoch 350/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8136 - u_decoder_loss: 0.0717 - f_decoder_loss: 0.0592 - f_decoder_1_loss: 0.0900 - u_decoder_1_loss: 0.4265 - val_loss: 0.9220 - val_u_decoder_loss: 0.0651 - val_f_decoder_loss: 0.0457 - val_f_decoder_1_loss: 0.1842 - val_u_decoder_1_loss: 0.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8307 - u_decoder_loss: 0.0831 - f_decoder_loss: 0.0397 - f_decoder_1_loss: 0.0943 - u_decoder_1_loss: 0.4442 - val_loss: 0.8855 - val_u_decoder_loss: 0.0668 - val_f_decoder_loss: 0.0803 - val_f_decoder_1_loss: 0.1912 - val_u_decoder_1_loss: 0.4087\n",
      "Epoch 352/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7821 - u_decoder_loss: 0.0569 - f_decoder_loss: 0.0652 - f_decoder_1_loss: 0.1304 - u_decoder_1_loss: 0.3865 - val_loss: 0.9447 - val_u_decoder_loss: 0.0607 - val_f_decoder_loss: 0.0581 - val_f_decoder_1_loss: 0.1506 - val_u_decoder_1_loss: 0.4969\n",
      "Epoch 353/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7607 - u_decoder_loss: 0.0696 - f_decoder_loss: 0.0459 - f_decoder_1_loss: 0.0866 - u_decoder_1_loss: 0.4129 - val_loss: 0.9498 - val_u_decoder_loss: 0.0875 - val_f_decoder_loss: 0.0472 - val_f_decoder_1_loss: 0.1790 - val_u_decoder_1_loss: 0.4797\n",
      "Epoch 354/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7413 - u_decoder_loss: 0.0668 - f_decoder_loss: 0.0497 - f_decoder_1_loss: 0.0874 - u_decoder_1_loss: 0.4077 - val_loss: 1.2040 - val_u_decoder_loss: 0.0815 - val_f_decoder_loss: 0.0942 - val_f_decoder_1_loss: 0.2025 - val_u_decoder_1_loss: 0.6112\n",
      "Epoch 355/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7531 - u_decoder_loss: 0.0583 - f_decoder_loss: 0.0569 - f_decoder_1_loss: 0.1156 - u_decoder_1_loss: 0.3682 - val_loss: 0.9976 - val_u_decoder_loss: 0.0703 - val_f_decoder_loss: 0.0569 - val_f_decoder_1_loss: 0.1415 - val_u_decoder_1_loss: 0.5413\n",
      "Epoch 356/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.6719 - u_decoder_loss: 0.0550 - f_decoder_loss: 0.0465 - f_decoder_1_loss: 0.0811 - u_decoder_1_loss: 0.3555 - val_loss: 1.1504 - val_u_decoder_loss: 0.1025 - val_f_decoder_loss: 0.0994 - val_f_decoder_1_loss: 0.1559 - val_u_decoder_1_loss: 0.5356\n",
      "Epoch 357/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 1.0676 - u_decoder_loss: 0.1085 - f_decoder_loss: 0.0766 - f_decoder_1_loss: 0.1521 - u_decoder_1_loss: 0.4751 - val_loss: 1.2696 - val_u_decoder_loss: 0.1147 - val_f_decoder_loss: 0.0546 - val_f_decoder_1_loss: 0.3362 - val_u_decoder_1_loss: 0.4341\n",
      "Epoch 358/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.2237 - u_decoder_loss: 0.0797 - f_decoder_loss: 0.1453 - f_decoder_1_loss: 0.3000 - u_decoder_1_loss: 0.4152 - val_loss: 1.3139 - val_u_decoder_loss: 0.1230 - val_f_decoder_loss: 0.0616 - val_f_decoder_1_loss: 0.2023 - val_u_decoder_1_loss: 0.6646\n",
      "Epoch 359/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9567 - u_decoder_loss: 0.0974 - f_decoder_loss: 0.0446 - f_decoder_1_loss: 0.1010 - u_decoder_1_loss: 0.5125 - val_loss: 0.9099 - val_u_decoder_loss: 0.0795 - val_f_decoder_loss: 0.0429 - val_f_decoder_1_loss: 0.1488 - val_u_decoder_1_loss: 0.4540\n",
      "Epoch 360/500\n",
      "4798/4798 [==============================] - 1s 184us/sample - loss: 1.1612 - u_decoder_loss: 0.1153 - f_decoder_loss: 0.0939 - f_decoder_1_loss: 0.1352 - u_decoder_1_loss: 0.5664 - val_loss: 1.0641 - val_u_decoder_loss: 0.1106 - val_f_decoder_loss: 0.0411 - val_f_decoder_1_loss: 0.1462 - val_u_decoder_1_loss: 0.6337\n",
      "Epoch 361/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7254 - u_decoder_loss: 0.0695 - f_decoder_loss: 0.0404 - f_decoder_1_loss: 0.1158 - u_decoder_1_loss: 0.3828 - val_loss: 0.8082 - val_u_decoder_loss: 0.0780 - val_f_decoder_loss: 0.0275 - val_f_decoder_1_loss: 0.1258 - val_u_decoder_1_loss: 0.4444\n",
      "Epoch 362/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7227 - u_decoder_loss: 0.0608 - f_decoder_loss: 0.0367 - f_decoder_1_loss: 0.0751 - u_decoder_1_loss: 0.4319 - val_loss: 1.0320 - val_u_decoder_loss: 0.0734 - val_f_decoder_loss: 0.0652 - val_f_decoder_1_loss: 0.1363 - val_u_decoder_1_loss: 0.5924\n",
      "Epoch 363/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6895 - u_decoder_loss: 0.0636 - f_decoder_loss: 0.0323 - f_decoder_1_loss: 0.0541 - u_decoder_1_loss: 0.4088 - val_loss: 1.0111 - val_u_decoder_loss: 0.1041 - val_f_decoder_loss: 0.0321 - val_f_decoder_1_loss: 0.1554 - val_u_decoder_1_loss: 0.5260\n",
      "Epoch 364/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7643 - u_decoder_loss: 0.0651 - f_decoder_loss: 0.0521 - f_decoder_1_loss: 0.1181 - u_decoder_1_loss: 0.3747 - val_loss: 0.8156 - val_u_decoder_loss: 0.0795 - val_f_decoder_loss: 0.0278 - val_f_decoder_1_loss: 0.1420 - val_u_decoder_1_loss: 0.4368\n",
      "Epoch 365/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7245 - u_decoder_loss: 0.0630 - f_decoder_loss: 0.0277 - f_decoder_1_loss: 0.0521 - u_decoder_1_loss: 0.4627 - val_loss: 0.9372 - val_u_decoder_loss: 0.0753 - val_f_decoder_loss: 0.0237 - val_f_decoder_1_loss: 0.1327 - val_u_decoder_1_loss: 0.5417\n",
      "Epoch 366/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8568 - u_decoder_loss: 0.0728 - f_decoder_loss: 0.0623 - f_decoder_1_loss: 0.1144 - u_decoder_1_loss: 0.4085 - val_loss: 1.5424 - val_u_decoder_loss: 0.0963 - val_f_decoder_loss: 0.2165 - val_f_decoder_1_loss: 0.3617 - val_u_decoder_1_loss: 0.5472\n",
      "Epoch 367/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0815 - u_decoder_loss: 0.0862 - f_decoder_loss: 0.0979 - f_decoder_1_loss: 0.1769 - u_decoder_1_loss: 0.4121 - val_loss: 0.7959 - val_u_decoder_loss: 0.0854 - val_f_decoder_loss: 0.0261 - val_f_decoder_1_loss: 0.1348 - val_u_decoder_1_loss: 0.4134\n",
      "Epoch 368/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.5772 - u_decoder_loss: 0.0498 - f_decoder_loss: 0.0320 - f_decoder_1_loss: 0.0642 - u_decoder_1_loss: 0.3294 - val_loss: 0.8057 - val_u_decoder_loss: 0.0601 - val_f_decoder_loss: 0.0222 - val_f_decoder_1_loss: 0.1193 - val_u_decoder_1_loss: 0.4620\n",
      "Epoch 369/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7691 - u_decoder_loss: 0.0636 - f_decoder_loss: 0.0464 - f_decoder_1_loss: 0.1234 - u_decoder_1_loss: 0.3804 - val_loss: 1.4344 - val_u_decoder_loss: 0.0727 - val_f_decoder_loss: 0.1377 - val_f_decoder_1_loss: 0.2022 - val_u_decoder_1_loss: 0.7941\n",
      "Epoch 370/500\n",
      "4798/4798 [==============================] - 1s 185us/sample - loss: 0.7683 - u_decoder_loss: 0.0634 - f_decoder_loss: 0.0420 - f_decoder_1_loss: 0.0817 - u_decoder_1_loss: 0.4438 - val_loss: 1.0238 - val_u_decoder_loss: 0.1308 - val_f_decoder_loss: 0.0486 - val_f_decoder_1_loss: 0.1776 - val_u_decoder_1_loss: 0.4805\n",
      "Epoch 371/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7519 - u_decoder_loss: 0.0721 - f_decoder_loss: 0.0484 - f_decoder_1_loss: 0.1511 - u_decoder_1_loss: 0.3324 - val_loss: 0.9779 - val_u_decoder_loss: 0.0879 - val_f_decoder_loss: 0.0516 - val_f_decoder_1_loss: 0.1320 - val_u_decoder_1_loss: 0.5325\n",
      "Epoch 372/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.9933 - u_decoder_loss: 0.0817 - f_decoder_loss: 0.0671 - f_decoder_1_loss: 0.1122 - u_decoder_1_loss: 0.4461 - val_loss: 1.3308 - val_u_decoder_loss: 0.1317 - val_f_decoder_loss: 0.1137 - val_f_decoder_1_loss: 0.2702 - val_u_decoder_1_loss: 0.5132\n",
      "Epoch 373/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7577 - u_decoder_loss: 0.0708 - f_decoder_loss: 0.0441 - f_decoder_1_loss: 0.1051 - u_decoder_1_loss: 0.4031 - val_loss: 0.8784 - val_u_decoder_loss: 0.0702 - val_f_decoder_loss: 0.0625 - val_f_decoder_1_loss: 0.2270 - val_u_decoder_1_loss: 0.3981\n",
      "Epoch 374/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8950 - u_decoder_loss: 0.0936 - f_decoder_loss: 0.0711 - f_decoder_1_loss: 0.1991 - u_decoder_1_loss: 0.3746 - val_loss: 0.9649 - val_u_decoder_loss: 0.0912 - val_f_decoder_loss: 0.0621 - val_f_decoder_1_loss: 0.2326 - val_u_decoder_1_loss: 0.4008\n",
      "Epoch 375/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.7798 - u_decoder_loss: 0.0788 - f_decoder_loss: 0.0373 - f_decoder_1_loss: 0.0996 - u_decoder_1_loss: 0.3952 - val_loss: 1.2937 - val_u_decoder_loss: 0.0764 - val_f_decoder_loss: 0.0603 - val_f_decoder_1_loss: 0.2610 - val_u_decoder_1_loss: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8024 - u_decoder_loss: 0.0700 - f_decoder_loss: 0.0413 - f_decoder_1_loss: 0.0772 - u_decoder_1_loss: 0.4627 - val_loss: 1.0443 - val_u_decoder_loss: 0.0792 - val_f_decoder_loss: 0.0354 - val_f_decoder_1_loss: 0.2079 - val_u_decoder_1_loss: 0.5210\n",
      "Epoch 377/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.8766 - u_decoder_loss: 0.0771 - f_decoder_loss: 0.0601 - f_decoder_1_loss: 0.1126 - u_decoder_1_loss: 0.4685 - val_loss: 1.1755 - val_u_decoder_loss: 0.0823 - val_f_decoder_loss: 0.0817 - val_f_decoder_1_loss: 0.2218 - val_u_decoder_1_loss: 0.5104\n",
      "Epoch 378/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.7197 - u_decoder_loss: 0.0693 - f_decoder_loss: 0.0384 - f_decoder_1_loss: 0.0957 - u_decoder_1_loss: 0.3612 - val_loss: 1.0685 - val_u_decoder_loss: 0.0801 - val_f_decoder_loss: 0.0521 - val_f_decoder_1_loss: 0.2228 - val_u_decoder_1_loss: 0.4561\n",
      "Epoch 379/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6367 - u_decoder_loss: 0.0545 - f_decoder_loss: 0.0379 - f_decoder_1_loss: 0.0833 - u_decoder_1_loss: 0.3456 - val_loss: 0.9058 - val_u_decoder_loss: 0.0572 - val_f_decoder_loss: 0.0578 - val_f_decoder_1_loss: 0.2180 - val_u_decoder_1_loss: 0.4424\n",
      "Epoch 380/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.6094 - u_decoder_loss: 0.0438 - f_decoder_loss: 0.0611 - f_decoder_1_loss: 0.1231 - u_decoder_1_loss: 0.2885 - val_loss: 0.8695 - val_u_decoder_loss: 0.0584 - val_f_decoder_loss: 0.0334 - val_f_decoder_1_loss: 0.1443 - val_u_decoder_1_loss: 0.5026\n",
      "Epoch 381/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0389 - u_decoder_loss: 0.0872 - f_decoder_loss: 0.0653 - f_decoder_1_loss: 0.1570 - u_decoder_1_loss: 0.5347 - val_loss: 1.3443 - val_u_decoder_loss: 0.1761 - val_f_decoder_loss: 0.0879 - val_f_decoder_1_loss: 0.3062 - val_u_decoder_1_loss: 0.5690\n",
      "Epoch 382/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9553 - u_decoder_loss: 0.0810 - f_decoder_loss: 0.0740 - f_decoder_1_loss: 0.1483 - u_decoder_1_loss: 0.4520 - val_loss: 1.3644 - val_u_decoder_loss: 0.1120 - val_f_decoder_loss: 0.0640 - val_f_decoder_1_loss: 0.2310 - val_u_decoder_1_loss: 0.7222\n",
      "Epoch 383/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7104 - u_decoder_loss: 0.0628 - f_decoder_loss: 0.0420 - f_decoder_1_loss: 0.1037 - u_decoder_1_loss: 0.3547 - val_loss: 1.0136 - val_u_decoder_loss: 0.1075 - val_f_decoder_loss: 0.0488 - val_f_decoder_1_loss: 0.2027 - val_u_decoder_1_loss: 0.4792\n",
      "Epoch 384/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 11.6269 - u_decoder_loss: 0.5989 - f_decoder_loss: 0.9152 - f_decoder_1_loss: 1.6860 - u_decoder_1_loss: 3.1288 - val_loss: 2.7289 - val_u_decoder_loss: 0.2595 - val_f_decoder_loss: 0.2591 - val_f_decoder_1_loss: 0.5732 - val_u_decoder_1_loss: 0.8441\n",
      "Epoch 385/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.4990 - u_decoder_loss: 0.1703 - f_decoder_loss: 0.1028 - f_decoder_1_loss: 0.2693 - u_decoder_1_loss: 0.5694 - val_loss: 1.4277 - val_u_decoder_loss: 0.1255 - val_f_decoder_loss: 0.0815 - val_f_decoder_1_loss: 0.2543 - val_u_decoder_1_loss: 0.6444\n",
      "Epoch 386/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9935 - u_decoder_loss: 0.0966 - f_decoder_loss: 0.0574 - f_decoder_1_loss: 0.1643 - u_decoder_1_loss: 0.4590 - val_loss: 1.1242 - val_u_decoder_loss: 0.0921 - val_f_decoder_loss: 0.0502 - val_f_decoder_1_loss: 0.1565 - val_u_decoder_1_loss: 0.5995\n",
      "Epoch 387/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8103 - u_decoder_loss: 0.0805 - f_decoder_loss: 0.0459 - f_decoder_1_loss: 0.1042 - u_decoder_1_loss: 0.4035 - val_loss: 0.8437 - val_u_decoder_loss: 0.0660 - val_f_decoder_loss: 0.0366 - val_f_decoder_1_loss: 0.1328 - val_u_decoder_1_loss: 0.4324\n",
      "Epoch 388/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7186 - u_decoder_loss: 0.0672 - f_decoder_loss: 0.0343 - f_decoder_1_loss: 0.0809 - u_decoder_1_loss: 0.3950 - val_loss: 0.8580 - val_u_decoder_loss: 0.0738 - val_f_decoder_loss: 0.0319 - val_f_decoder_1_loss: 0.1435 - val_u_decoder_1_loss: 0.4473\n",
      "Epoch 389/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7084 - u_decoder_loss: 0.0649 - f_decoder_loss: 0.0311 - f_decoder_1_loss: 0.0786 - u_decoder_1_loss: 0.3989 - val_loss: 0.9962 - val_u_decoder_loss: 0.0779 - val_f_decoder_loss: 0.0406 - val_f_decoder_1_loss: 0.1426 - val_u_decoder_1_loss: 0.4806\n",
      "Epoch 390/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6813 - u_decoder_loss: 0.0623 - f_decoder_loss: 0.0315 - f_decoder_1_loss: 0.0733 - u_decoder_1_loss: 0.3567 - val_loss: 0.9601 - val_u_decoder_loss: 0.0986 - val_f_decoder_loss: 0.0389 - val_f_decoder_1_loss: 0.1190 - val_u_decoder_1_loss: 0.5295\n",
      "Epoch 391/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7732 - u_decoder_loss: 0.0661 - f_decoder_loss: 0.0376 - f_decoder_1_loss: 0.0979 - u_decoder_1_loss: 0.4294 - val_loss: 1.0391 - val_u_decoder_loss: 0.0664 - val_f_decoder_loss: 0.0394 - val_f_decoder_1_loss: 0.1445 - val_u_decoder_1_loss: 0.6229\n",
      "Epoch 392/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6586 - u_decoder_loss: 0.0533 - f_decoder_loss: 0.0322 - f_decoder_1_loss: 0.0944 - u_decoder_1_loss: 0.3074 - val_loss: 0.8130 - val_u_decoder_loss: 0.0637 - val_f_decoder_loss: 0.0351 - val_f_decoder_1_loss: 0.1500 - val_u_decoder_1_loss: 0.4097\n",
      "Epoch 393/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6697 - u_decoder_loss: 0.0673 - f_decoder_loss: 0.0348 - f_decoder_1_loss: 0.0962 - u_decoder_1_loss: 0.3477 - val_loss: 0.8955 - val_u_decoder_loss: 0.0600 - val_f_decoder_loss: 0.0292 - val_f_decoder_1_loss: 0.1608 - val_u_decoder_1_loss: 0.4992\n",
      "Epoch 394/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 0.8543 - u_decoder_loss: 0.0804 - f_decoder_loss: 0.0531 - f_decoder_1_loss: 0.1150 - u_decoder_1_loss: 0.4369 - val_loss: 0.8021 - val_u_decoder_loss: 0.0618 - val_f_decoder_loss: 0.0292 - val_f_decoder_1_loss: 0.1332 - val_u_decoder_1_loss: 0.4357\n",
      "Epoch 395/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7352 - u_decoder_loss: 0.0744 - f_decoder_loss: 0.0392 - f_decoder_1_loss: 0.0785 - u_decoder_1_loss: 0.4146 - val_loss: 1.2214 - val_u_decoder_loss: 0.1455 - val_f_decoder_loss: 0.0863 - val_f_decoder_1_loss: 0.2009 - val_u_decoder_1_loss: 0.5551\n",
      "Epoch 396/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8245 - u_decoder_loss: 0.0661 - f_decoder_loss: 0.0525 - f_decoder_1_loss: 0.1296 - u_decoder_1_loss: 0.3596 - val_loss: 0.8190 - val_u_decoder_loss: 0.0526 - val_f_decoder_loss: 0.0371 - val_f_decoder_1_loss: 0.1390 - val_u_decoder_1_loss: 0.4528\n",
      "Epoch 397/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.5949 - u_decoder_loss: 0.0541 - f_decoder_loss: 0.0296 - f_decoder_1_loss: 0.0710 - u_decoder_1_loss: 0.3396 - val_loss: 0.7815 - val_u_decoder_loss: 0.0587 - val_f_decoder_loss: 0.0366 - val_f_decoder_1_loss: 0.1407 - val_u_decoder_1_loss: 0.4283\n",
      "Epoch 398/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.6449 - u_decoder_loss: 0.0631 - f_decoder_loss: 0.0307 - f_decoder_1_loss: 0.0660 - u_decoder_1_loss: 0.3702 - val_loss: 0.7738 - val_u_decoder_loss: 0.0594 - val_f_decoder_loss: 0.0259 - val_f_decoder_1_loss: 0.1368 - val_u_decoder_1_loss: 0.4151\n",
      "Epoch 399/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.6471 - u_decoder_loss: 0.0596 - f_decoder_loss: 0.0280 - f_decoder_1_loss: 0.0627 - u_decoder_1_loss: 0.3819 - val_loss: 0.8412 - val_u_decoder_loss: 0.0838 - val_f_decoder_loss: 0.0319 - val_f_decoder_1_loss: 0.1311 - val_u_decoder_1_loss: 0.4454\n",
      "Epoch 400/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6247 - u_decoder_loss: 0.0544 - f_decoder_loss: 0.0339 - f_decoder_1_loss: 0.0701 - u_decoder_1_loss: 0.3333 - val_loss: 0.9440 - val_u_decoder_loss: 0.0792 - val_f_decoder_loss: 0.0288 - val_f_decoder_1_loss: 0.1636 - val_u_decoder_1_loss: 0.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.7417 - u_decoder_loss: 0.0751 - f_decoder_loss: 0.0405 - f_decoder_1_loss: 0.0941 - u_decoder_1_loss: 0.3973 - val_loss: 1.1593 - val_u_decoder_loss: 0.1187 - val_f_decoder_loss: 0.0530 - val_f_decoder_1_loss: 0.1563 - val_u_decoder_1_loss: 0.6354\n",
      "Epoch 402/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9289 - u_decoder_loss: 0.0757 - f_decoder_loss: 0.0993 - f_decoder_1_loss: 0.1984 - u_decoder_1_loss: 0.3649 - val_loss: 1.1584 - val_u_decoder_loss: 0.0773 - val_f_decoder_loss: 0.0589 - val_f_decoder_1_loss: 0.2986 - val_u_decoder_1_loss: 0.4929\n",
      "Epoch 403/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7335 - u_decoder_loss: 0.0613 - f_decoder_loss: 0.0353 - f_decoder_1_loss: 0.0846 - u_decoder_1_loss: 0.4246 - val_loss: 0.8851 - val_u_decoder_loss: 0.0939 - val_f_decoder_loss: 0.0331 - val_f_decoder_1_loss: 0.1228 - val_u_decoder_1_loss: 0.5037\n",
      "Epoch 404/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9598 - u_decoder_loss: 0.0917 - f_decoder_loss: 0.0681 - f_decoder_1_loss: 0.1480 - u_decoder_1_loss: 0.4464 - val_loss: 1.7502 - val_u_decoder_loss: 0.1661 - val_f_decoder_loss: 0.0886 - val_f_decoder_1_loss: 0.2208 - val_u_decoder_1_loss: 0.9868\n",
      "Epoch 405/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9215 - u_decoder_loss: 0.0923 - f_decoder_loss: 0.0506 - f_decoder_1_loss: 0.1368 - u_decoder_1_loss: 0.4558 - val_loss: 1.1059 - val_u_decoder_loss: 0.0925 - val_f_decoder_loss: 0.0667 - val_f_decoder_1_loss: 0.2660 - val_u_decoder_1_loss: 0.4411\n",
      "Epoch 406/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7724 - u_decoder_loss: 0.0644 - f_decoder_loss: 0.0564 - f_decoder_1_loss: 0.1090 - u_decoder_1_loss: 0.4035 - val_loss: 1.0299 - val_u_decoder_loss: 0.0876 - val_f_decoder_loss: 0.0474 - val_f_decoder_1_loss: 0.1335 - val_u_decoder_1_loss: 0.6050\n",
      "Epoch 407/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.6393 - u_decoder_loss: 0.0606 - f_decoder_loss: 0.0345 - f_decoder_1_loss: 0.0721 - u_decoder_1_loss: 0.3605 - val_loss: 0.8754 - val_u_decoder_loss: 0.0997 - val_f_decoder_loss: 0.0460 - val_f_decoder_1_loss: 0.1512 - val_u_decoder_1_loss: 0.4513\n",
      "Epoch 408/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6571 - u_decoder_loss: 0.0557 - f_decoder_loss: 0.0453 - f_decoder_1_loss: 0.1153 - u_decoder_1_loss: 0.3322 - val_loss: 0.8309 - val_u_decoder_loss: 0.0833 - val_f_decoder_loss: 0.0433 - val_f_decoder_1_loss: 0.1269 - val_u_decoder_1_loss: 0.4689\n",
      "Epoch 409/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7600 - u_decoder_loss: 0.0844 - f_decoder_loss: 0.0388 - f_decoder_1_loss: 0.0753 - u_decoder_1_loss: 0.4293 - val_loss: 1.0062 - val_u_decoder_loss: 0.1035 - val_f_decoder_loss: 0.0318 - val_f_decoder_1_loss: 0.1411 - val_u_decoder_1_loss: 0.5879\n",
      "Epoch 410/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8972 - u_decoder_loss: 0.0728 - f_decoder_loss: 0.0502 - f_decoder_1_loss: 0.1196 - u_decoder_1_loss: 0.4810 - val_loss: 0.9149 - val_u_decoder_loss: 0.0916 - val_f_decoder_loss: 0.0622 - val_f_decoder_1_loss: 0.1498 - val_u_decoder_1_loss: 0.4473\n",
      "Epoch 411/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.6650 - u_decoder_loss: 0.0665 - f_decoder_loss: 0.0374 - f_decoder_1_loss: 0.0854 - u_decoder_1_loss: 0.3566 - val_loss: 1.0905 - val_u_decoder_loss: 0.0906 - val_f_decoder_loss: 0.0774 - val_f_decoder_1_loss: 0.1791 - val_u_decoder_1_loss: 0.5443\n",
      "Epoch 412/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9595 - u_decoder_loss: 0.0830 - f_decoder_loss: 0.0748 - f_decoder_1_loss: 0.2004 - u_decoder_1_loss: 0.4285 - val_loss: 1.0228 - val_u_decoder_loss: 0.0844 - val_f_decoder_loss: 0.0585 - val_f_decoder_1_loss: 0.1543 - val_u_decoder_1_loss: 0.5478\n",
      "Epoch 413/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.6636 - u_decoder_loss: 0.0672 - f_decoder_loss: 0.0470 - f_decoder_1_loss: 0.0885 - u_decoder_1_loss: 0.3360 - val_loss: 0.7877 - val_u_decoder_loss: 0.0773 - val_f_decoder_loss: 0.0284 - val_f_decoder_1_loss: 0.1253 - val_u_decoder_1_loss: 0.4394\n",
      "Epoch 414/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7729 - u_decoder_loss: 0.0650 - f_decoder_loss: 0.0468 - f_decoder_1_loss: 0.0973 - u_decoder_1_loss: 0.4256 - val_loss: 0.7774 - val_u_decoder_loss: 0.0742 - val_f_decoder_loss: 0.0396 - val_f_decoder_1_loss: 0.1359 - val_u_decoder_1_loss: 0.3857\n",
      "Epoch 415/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7456 - u_decoder_loss: 0.0790 - f_decoder_loss: 0.0449 - f_decoder_1_loss: 0.1025 - u_decoder_1_loss: 0.3815 - val_loss: 1.4085 - val_u_decoder_loss: 0.1676 - val_f_decoder_loss: 0.0759 - val_f_decoder_1_loss: 0.2717 - val_u_decoder_1_loss: 0.7149\n",
      "Epoch 416/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8976 - u_decoder_loss: 0.0898 - f_decoder_loss: 0.0665 - f_decoder_1_loss: 0.1348 - u_decoder_1_loss: 0.4370 - val_loss: 1.2955 - val_u_decoder_loss: 0.1016 - val_f_decoder_loss: 0.1063 - val_f_decoder_1_loss: 0.2740 - val_u_decoder_1_loss: 0.5275\n",
      "Epoch 417/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8345 - u_decoder_loss: 0.0675 - f_decoder_loss: 0.0624 - f_decoder_1_loss: 0.1190 - u_decoder_1_loss: 0.3882 - val_loss: 1.1044 - val_u_decoder_loss: 0.1107 - val_f_decoder_loss: 0.0692 - val_f_decoder_1_loss: 0.2040 - val_u_decoder_1_loss: 0.4936\n",
      "Epoch 418/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 1.0526 - u_decoder_loss: 0.0909 - f_decoder_loss: 0.0784 - f_decoder_1_loss: 0.1733 - u_decoder_1_loss: 0.4738 - val_loss: 1.0889 - val_u_decoder_loss: 0.0848 - val_f_decoder_loss: 0.0512 - val_f_decoder_1_loss: 0.2633 - val_u_decoder_1_loss: 0.4660\n",
      "Epoch 419/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6591 - u_decoder_loss: 0.0558 - f_decoder_loss: 0.0407 - f_decoder_1_loss: 0.1257 - u_decoder_1_loss: 0.3076 - val_loss: 0.9961 - val_u_decoder_loss: 0.0715 - val_f_decoder_loss: 0.0479 - val_f_decoder_1_loss: 0.1621 - val_u_decoder_1_loss: 0.5466\n",
      "Epoch 420/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6037 - u_decoder_loss: 0.0509 - f_decoder_loss: 0.0298 - f_decoder_1_loss: 0.0728 - u_decoder_1_loss: 0.3392 - val_loss: 0.8660 - val_u_decoder_loss: 0.0745 - val_f_decoder_loss: 0.0456 - val_f_decoder_1_loss: 0.1142 - val_u_decoder_1_loss: 0.5017\n",
      "Epoch 421/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6614 - u_decoder_loss: 0.0594 - f_decoder_loss: 0.0407 - f_decoder_1_loss: 0.0705 - u_decoder_1_loss: 0.3801 - val_loss: 0.9631 - val_u_decoder_loss: 0.0964 - val_f_decoder_loss: 0.0716 - val_f_decoder_1_loss: 0.1915 - val_u_decoder_1_loss: 0.4652\n",
      "Epoch 422/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6281 - u_decoder_loss: 0.0606 - f_decoder_loss: 0.0366 - f_decoder_1_loss: 0.0847 - u_decoder_1_loss: 0.3345 - val_loss: 0.9181 - val_u_decoder_loss: 0.0635 - val_f_decoder_loss: 0.0422 - val_f_decoder_1_loss: 0.2318 - val_u_decoder_1_loss: 0.4298\n",
      "Epoch 423/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.2111 - u_decoder_loss: 0.1203 - f_decoder_loss: 0.0859 - f_decoder_1_loss: 0.1789 - u_decoder_1_loss: 0.5680 - val_loss: 1.0650 - val_u_decoder_loss: 0.0978 - val_f_decoder_loss: 0.0566 - val_f_decoder_1_loss: 0.1611 - val_u_decoder_1_loss: 0.5534\n",
      "Epoch 424/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8424 - u_decoder_loss: 0.0712 - f_decoder_loss: 0.0581 - f_decoder_1_loss: 0.1043 - u_decoder_1_loss: 0.4186 - val_loss: 0.9761 - val_u_decoder_loss: 0.0810 - val_f_decoder_loss: 0.0410 - val_f_decoder_1_loss: 0.1161 - val_u_decoder_1_loss: 0.5764\n",
      "Epoch 425/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8528 - u_decoder_loss: 0.0785 - f_decoder_loss: 0.0581 - f_decoder_1_loss: 0.1220 - u_decoder_1_loss: 0.4417 - val_loss: 1.1815 - val_u_decoder_loss: 0.0650 - val_f_decoder_loss: 0.1610 - val_f_decoder_1_loss: 0.3587 - val_u_decoder_1_loss: 0.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8211 - u_decoder_loss: 0.0818 - f_decoder_loss: 0.0622 - f_decoder_1_loss: 0.1107 - u_decoder_1_loss: 0.4328 - val_loss: 1.0667 - val_u_decoder_loss: 0.0962 - val_f_decoder_loss: 0.0531 - val_f_decoder_1_loss: 0.1964 - val_u_decoder_1_loss: 0.5191\n",
      "Epoch 427/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8456 - u_decoder_loss: 0.0865 - f_decoder_loss: 0.0532 - f_decoder_1_loss: 0.1062 - u_decoder_1_loss: 0.4395 - val_loss: 0.7939 - val_u_decoder_loss: 0.0629 - val_f_decoder_loss: 0.0424 - val_f_decoder_1_loss: 0.1527 - val_u_decoder_1_loss: 0.4095\n",
      "Epoch 428/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7333 - u_decoder_loss: 0.0747 - f_decoder_loss: 0.0367 - f_decoder_1_loss: 0.0774 - u_decoder_1_loss: 0.4149 - val_loss: 0.9545 - val_u_decoder_loss: 0.1067 - val_f_decoder_loss: 0.0385 - val_f_decoder_1_loss: 0.1666 - val_u_decoder_1_loss: 0.4954\n",
      "Epoch 429/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7778 - u_decoder_loss: 0.0718 - f_decoder_loss: 0.0584 - f_decoder_1_loss: 0.1022 - u_decoder_1_loss: 0.4056 - val_loss: 0.9970 - val_u_decoder_loss: 0.0755 - val_f_decoder_loss: 0.0995 - val_f_decoder_1_loss: 0.2524 - val_u_decoder_1_loss: 0.3986\n",
      "Epoch 430/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8266 - u_decoder_loss: 0.0591 - f_decoder_loss: 0.0766 - f_decoder_1_loss: 0.1709 - u_decoder_1_loss: 0.3767 - val_loss: 1.3227 - val_u_decoder_loss: 0.1787 - val_f_decoder_loss: 0.0600 - val_f_decoder_1_loss: 0.1623 - val_u_decoder_1_loss: 0.7516\n",
      "Epoch 431/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.1166 - u_decoder_loss: 0.1261 - f_decoder_loss: 0.0802 - f_decoder_1_loss: 0.2367 - u_decoder_1_loss: 0.4525 - val_loss: 1.3203 - val_u_decoder_loss: 0.0927 - val_f_decoder_loss: 0.1306 - val_f_decoder_1_loss: 0.3188 - val_u_decoder_1_loss: 0.5073\n",
      "Epoch 432/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7238 - u_decoder_loss: 0.0695 - f_decoder_loss: 0.0480 - f_decoder_1_loss: 0.0776 - u_decoder_1_loss: 0.3944 - val_loss: 0.8537 - val_u_decoder_loss: 0.0975 - val_f_decoder_loss: 0.0449 - val_f_decoder_1_loss: 0.1200 - val_u_decoder_1_loss: 0.4617\n",
      "Epoch 433/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6112 - u_decoder_loss: 0.0563 - f_decoder_loss: 0.0359 - f_decoder_1_loss: 0.0873 - u_decoder_1_loss: 0.3216 - val_loss: 0.9788 - val_u_decoder_loss: 0.0718 - val_f_decoder_loss: 0.0370 - val_f_decoder_1_loss: 0.1974 - val_u_decoder_1_loss: 0.5198\n",
      "Epoch 434/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.5784 - u_decoder_loss: 0.0485 - f_decoder_loss: 0.0334 - f_decoder_1_loss: 0.0784 - u_decoder_1_loss: 0.3091 - val_loss: 0.8334 - val_u_decoder_loss: 0.0793 - val_f_decoder_loss: 0.0206 - val_f_decoder_1_loss: 0.0916 - val_u_decoder_1_loss: 0.4541\n",
      "Epoch 435/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.7591 - u_decoder_loss: 0.0834 - f_decoder_loss: 0.0413 - f_decoder_1_loss: 0.0695 - u_decoder_1_loss: 0.4250 - val_loss: 0.8543 - val_u_decoder_loss: 0.0818 - val_f_decoder_loss: 0.0593 - val_f_decoder_1_loss: 0.1235 - val_u_decoder_1_loss: 0.4481\n",
      "Epoch 436/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 1.0528 - u_decoder_loss: 0.1001 - f_decoder_loss: 0.0954 - f_decoder_1_loss: 0.2160 - u_decoder_1_loss: 0.4451 - val_loss: 1.1522 - val_u_decoder_loss: 0.1036 - val_f_decoder_loss: 0.0930 - val_f_decoder_1_loss: 0.3183 - val_u_decoder_1_loss: 0.4614\n",
      "Epoch 437/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9607 - u_decoder_loss: 0.0877 - f_decoder_loss: 0.0653 - f_decoder_1_loss: 0.1219 - u_decoder_1_loss: 0.5100 - val_loss: 1.2938 - val_u_decoder_loss: 0.1032 - val_f_decoder_loss: 0.0638 - val_f_decoder_1_loss: 0.1753 - val_u_decoder_1_loss: 0.6951\n",
      "Epoch 438/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.9667 - u_decoder_loss: 0.0956 - f_decoder_loss: 0.0565 - f_decoder_1_loss: 0.0881 - u_decoder_1_loss: 0.5382 - val_loss: 0.9701 - val_u_decoder_loss: 0.0919 - val_f_decoder_loss: 0.0338 - val_f_decoder_1_loss: 0.1277 - val_u_decoder_1_loss: 0.5639\n",
      "Epoch 439/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7554 - u_decoder_loss: 0.0590 - f_decoder_loss: 0.0371 - f_decoder_1_loss: 0.0852 - u_decoder_1_loss: 0.4023 - val_loss: 0.9714 - val_u_decoder_loss: 0.0948 - val_f_decoder_loss: 0.0421 - val_f_decoder_1_loss: 0.1862 - val_u_decoder_1_loss: 0.5069\n",
      "Epoch 440/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6472 - u_decoder_loss: 0.0612 - f_decoder_loss: 0.0398 - f_decoder_1_loss: 0.0899 - u_decoder_1_loss: 0.3376 - val_loss: 0.7993 - val_u_decoder_loss: 0.0649 - val_f_decoder_loss: 0.0348 - val_f_decoder_1_loss: 0.1183 - val_u_decoder_1_loss: 0.4333\n",
      "Epoch 441/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6627 - u_decoder_loss: 0.0537 - f_decoder_loss: 0.0528 - f_decoder_1_loss: 0.0915 - u_decoder_1_loss: 0.3375 - val_loss: 1.1115 - val_u_decoder_loss: 0.1193 - val_f_decoder_loss: 0.0616 - val_f_decoder_1_loss: 0.2464 - val_u_decoder_1_loss: 0.4865\n",
      "Epoch 442/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7164 - u_decoder_loss: 0.0670 - f_decoder_loss: 0.0517 - f_decoder_1_loss: 0.1251 - u_decoder_1_loss: 0.3415 - val_loss: 0.7556 - val_u_decoder_loss: 0.0640 - val_f_decoder_loss: 0.0287 - val_f_decoder_1_loss: 0.1301 - val_u_decoder_1_loss: 0.4021\n",
      "Epoch 443/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8091 - u_decoder_loss: 0.0822 - f_decoder_loss: 0.0416 - f_decoder_1_loss: 0.1023 - u_decoder_1_loss: 0.4344 - val_loss: 1.2920 - val_u_decoder_loss: 0.1192 - val_f_decoder_loss: 0.0824 - val_f_decoder_1_loss: 0.3075 - val_u_decoder_1_loss: 0.5494\n",
      "Epoch 444/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7971 - u_decoder_loss: 0.0711 - f_decoder_loss: 0.0544 - f_decoder_1_loss: 0.0986 - u_decoder_1_loss: 0.4177 - val_loss: 1.0870 - val_u_decoder_loss: 0.1056 - val_f_decoder_loss: 0.0575 - val_f_decoder_1_loss: 0.1347 - val_u_decoder_1_loss: 0.6067\n",
      "Epoch 445/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9697 - u_decoder_loss: 0.0814 - f_decoder_loss: 0.0789 - f_decoder_1_loss: 0.1515 - u_decoder_1_loss: 0.4385 - val_loss: 1.1209 - val_u_decoder_loss: 0.1037 - val_f_decoder_loss: 0.0964 - val_f_decoder_1_loss: 0.1852 - val_u_decoder_1_loss: 0.5598\n",
      "Epoch 446/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8353 - u_decoder_loss: 0.0921 - f_decoder_loss: 0.0582 - f_decoder_1_loss: 0.1992 - u_decoder_1_loss: 0.3193 - val_loss: 1.2417 - val_u_decoder_loss: 0.0697 - val_f_decoder_loss: 0.0612 - val_f_decoder_1_loss: 0.4164 - val_u_decoder_1_loss: 0.5073\n",
      "Epoch 447/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7904 - u_decoder_loss: 0.0605 - f_decoder_loss: 0.0650 - f_decoder_1_loss: 0.1298 - u_decoder_1_loss: 0.3835 - val_loss: 0.7203 - val_u_decoder_loss: 0.0623 - val_f_decoder_loss: 0.0280 - val_f_decoder_1_loss: 0.1255 - val_u_decoder_1_loss: 0.3778\n",
      "Epoch 448/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.5069 - u_decoder_loss: 0.0521 - f_decoder_loss: 0.0230 - f_decoder_1_loss: 0.0420 - u_decoder_1_loss: 0.3048 - val_loss: 0.9834 - val_u_decoder_loss: 0.0776 - val_f_decoder_loss: 0.0362 - val_f_decoder_1_loss: 0.1269 - val_u_decoder_1_loss: 0.5905\n",
      "Epoch 449/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8012 - u_decoder_loss: 0.0893 - f_decoder_loss: 0.0487 - f_decoder_1_loss: 0.0639 - u_decoder_1_loss: 0.4519 - val_loss: 1.2608 - val_u_decoder_loss: 0.1464 - val_f_decoder_loss: 0.0778 - val_f_decoder_1_loss: 0.1778 - val_u_decoder_1_loss: 0.6549\n",
      "Epoch 450/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8299 - u_decoder_loss: 0.0835 - f_decoder_loss: 0.0481 - f_decoder_1_loss: 0.0940 - u_decoder_1_loss: 0.4633 - val_loss: 1.0495 - val_u_decoder_loss: 0.0759 - val_f_decoder_loss: 0.0682 - val_f_decoder_1_loss: 0.2120 - val_u_decoder_1_loss: 0.4666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6679 - u_decoder_loss: 0.0538 - f_decoder_loss: 0.0358 - f_decoder_1_loss: 0.0928 - u_decoder_1_loss: 0.3371 - val_loss: 1.2232 - val_u_decoder_loss: 0.1075 - val_f_decoder_loss: 0.0421 - val_f_decoder_1_loss: 0.1650 - val_u_decoder_1_loss: 0.7415\n",
      "Epoch 452/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8667 - u_decoder_loss: 0.0666 - f_decoder_loss: 0.0598 - f_decoder_1_loss: 0.1307 - u_decoder_1_loss: 0.4585 - val_loss: 1.0486 - val_u_decoder_loss: 0.0732 - val_f_decoder_loss: 0.0454 - val_f_decoder_1_loss: 0.1595 - val_u_decoder_1_loss: 0.6176\n",
      "Epoch 453/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8089 - u_decoder_loss: 0.0701 - f_decoder_loss: 0.0436 - f_decoder_1_loss: 0.1048 - u_decoder_1_loss: 0.4439 - val_loss: 0.9473 - val_u_decoder_loss: 0.1217 - val_f_decoder_loss: 0.0402 - val_f_decoder_1_loss: 0.1705 - val_u_decoder_1_loss: 0.4819\n",
      "Epoch 454/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.6891 - u_decoder_loss: 0.0651 - f_decoder_loss: 0.0400 - f_decoder_1_loss: 0.0841 - u_decoder_1_loss: 0.3797 - val_loss: 0.8205 - val_u_decoder_loss: 0.0843 - val_f_decoder_loss: 0.0348 - val_f_decoder_1_loss: 0.1492 - val_u_decoder_1_loss: 0.4309\n",
      "Epoch 455/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.8547 - u_decoder_loss: 0.0679 - f_decoder_loss: 0.0518 - f_decoder_1_loss: 0.1263 - u_decoder_1_loss: 0.4171 - val_loss: 1.2645 - val_u_decoder_loss: 0.1170 - val_f_decoder_loss: 0.0914 - val_f_decoder_1_loss: 0.3246 - val_u_decoder_1_loss: 0.5012\n",
      "Epoch 456/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8675 - u_decoder_loss: 0.0961 - f_decoder_loss: 0.0726 - f_decoder_1_loss: 0.1721 - u_decoder_1_loss: 0.3501 - val_loss: 1.0913 - val_u_decoder_loss: 0.1110 - val_f_decoder_loss: 0.0803 - val_f_decoder_1_loss: 0.2539 - val_u_decoder_1_loss: 0.4144\n",
      "Epoch 457/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8692 - u_decoder_loss: 0.0681 - f_decoder_loss: 0.0824 - f_decoder_1_loss: 0.1465 - u_decoder_1_loss: 0.4057 - val_loss: 1.1677 - val_u_decoder_loss: 0.1156 - val_f_decoder_loss: 0.0971 - val_f_decoder_1_loss: 0.2042 - val_u_decoder_1_loss: 0.5121\n",
      "Epoch 458/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.6912 - u_decoder_loss: 0.0672 - f_decoder_loss: 0.0403 - f_decoder_1_loss: 0.0924 - u_decoder_1_loss: 0.3546 - val_loss: 0.9151 - val_u_decoder_loss: 0.0829 - val_f_decoder_loss: 0.0426 - val_f_decoder_1_loss: 0.1153 - val_u_decoder_1_loss: 0.5285\n",
      "Epoch 459/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7658 - u_decoder_loss: 0.0705 - f_decoder_loss: 0.0505 - f_decoder_1_loss: 0.0781 - u_decoder_1_loss: 0.4157 - val_loss: 0.8802 - val_u_decoder_loss: 0.0950 - val_f_decoder_loss: 0.0541 - val_f_decoder_1_loss: 0.1253 - val_u_decoder_1_loss: 0.4549\n",
      "Epoch 460/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7606 - u_decoder_loss: 0.0642 - f_decoder_loss: 0.0471 - f_decoder_1_loss: 0.0834 - u_decoder_1_loss: 0.4320 - val_loss: 0.9849 - val_u_decoder_loss: 0.0750 - val_f_decoder_loss: 0.0323 - val_f_decoder_1_loss: 0.1361 - val_u_decoder_1_loss: 0.5678\n",
      "Epoch 461/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.5564 - u_decoder_loss: 0.0516 - f_decoder_loss: 0.0282 - f_decoder_1_loss: 0.0539 - u_decoder_1_loss: 0.3299 - val_loss: 0.8657 - val_u_decoder_loss: 0.0867 - val_f_decoder_loss: 0.0493 - val_f_decoder_1_loss: 0.1479 - val_u_decoder_1_loss: 0.4391\n",
      "Epoch 462/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8545 - u_decoder_loss: 0.0733 - f_decoder_loss: 0.0614 - f_decoder_1_loss: 0.1429 - u_decoder_1_loss: 0.4203 - val_loss: 1.5921 - val_u_decoder_loss: 0.0904 - val_f_decoder_loss: 0.1948 - val_f_decoder_1_loss: 0.4863 - val_u_decoder_1_loss: 0.5714\n",
      "Epoch 463/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8794 - u_decoder_loss: 0.0604 - f_decoder_loss: 0.0673 - f_decoder_1_loss: 0.1509 - u_decoder_1_loss: 0.4219 - val_loss: 1.6096 - val_u_decoder_loss: 0.2025 - val_f_decoder_loss: 0.1058 - val_f_decoder_1_loss: 0.1767 - val_u_decoder_1_loss: 0.6881\n",
      "Epoch 464/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7974 - u_decoder_loss: 0.0885 - f_decoder_loss: 0.0438 - f_decoder_1_loss: 0.0705 - u_decoder_1_loss: 0.4210 - val_loss: 1.3249 - val_u_decoder_loss: 0.1370 - val_f_decoder_loss: 0.0483 - val_f_decoder_1_loss: 0.1486 - val_u_decoder_1_loss: 0.7978\n",
      "Epoch 465/500\n",
      "4798/4798 [==============================] - 1s 177us/sample - loss: 0.9200 - u_decoder_loss: 0.0873 - f_decoder_loss: 0.0526 - f_decoder_1_loss: 0.1236 - u_decoder_1_loss: 0.4735 - val_loss: 0.9935 - val_u_decoder_loss: 0.1045 - val_f_decoder_loss: 0.0337 - val_f_decoder_1_loss: 0.1612 - val_u_decoder_1_loss: 0.5127\n",
      "Epoch 466/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7735 - u_decoder_loss: 0.0744 - f_decoder_loss: 0.0435 - f_decoder_1_loss: 0.0962 - u_decoder_1_loss: 0.4303 - val_loss: 1.1163 - val_u_decoder_loss: 0.0884 - val_f_decoder_loss: 0.0736 - val_f_decoder_1_loss: 0.3005 - val_u_decoder_1_loss: 0.4561\n",
      "Epoch 467/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9386 - u_decoder_loss: 0.0756 - f_decoder_loss: 0.0673 - f_decoder_1_loss: 0.2052 - u_decoder_1_loss: 0.4143 - val_loss: 0.7958 - val_u_decoder_loss: 0.0742 - val_f_decoder_loss: 0.0390 - val_f_decoder_1_loss: 0.1404 - val_u_decoder_1_loss: 0.4127\n",
      "Epoch 468/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9820 - u_decoder_loss: 0.0621 - f_decoder_loss: 0.0786 - f_decoder_1_loss: 0.1644 - u_decoder_1_loss: 0.4235 - val_loss: 1.0936 - val_u_decoder_loss: 0.0844 - val_f_decoder_loss: 0.0861 - val_f_decoder_1_loss: 0.1954 - val_u_decoder_1_loss: 0.5168\n",
      "Epoch 469/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.5889 - u_decoder_loss: 0.0528 - f_decoder_loss: 0.0458 - f_decoder_1_loss: 0.0694 - u_decoder_1_loss: 0.3067 - val_loss: 0.7514 - val_u_decoder_loss: 0.0619 - val_f_decoder_loss: 0.0249 - val_f_decoder_1_loss: 0.1069 - val_u_decoder_1_loss: 0.4443\n",
      "Epoch 470/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.5075 - u_decoder_loss: 0.0481 - f_decoder_loss: 0.0234 - f_decoder_1_loss: 0.0407 - u_decoder_1_loss: 0.3133 - val_loss: 0.8588 - val_u_decoder_loss: 0.0764 - val_f_decoder_loss: 0.0475 - val_f_decoder_1_loss: 0.1379 - val_u_decoder_1_loss: 0.4606\n",
      "Epoch 471/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8190 - u_decoder_loss: 0.0699 - f_decoder_loss: 0.0494 - f_decoder_1_loss: 0.1022 - u_decoder_1_loss: 0.4679 - val_loss: 0.9801 - val_u_decoder_loss: 0.1139 - val_f_decoder_loss: 0.0600 - val_f_decoder_1_loss: 0.1837 - val_u_decoder_1_loss: 0.4123\n",
      "Epoch 472/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7721 - u_decoder_loss: 0.0695 - f_decoder_loss: 0.0581 - f_decoder_1_loss: 0.1066 - u_decoder_1_loss: 0.4083 - val_loss: 1.0009 - val_u_decoder_loss: 0.0937 - val_f_decoder_loss: 0.0784 - val_f_decoder_1_loss: 0.2315 - val_u_decoder_1_loss: 0.4447\n",
      "Epoch 473/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7238 - u_decoder_loss: 0.0781 - f_decoder_loss: 0.0485 - f_decoder_1_loss: 0.1108 - u_decoder_1_loss: 0.3537 - val_loss: 0.7952 - val_u_decoder_loss: 0.0636 - val_f_decoder_loss: 0.0359 - val_f_decoder_1_loss: 0.1329 - val_u_decoder_1_loss: 0.4327\n",
      "Epoch 474/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7226 - u_decoder_loss: 0.0621 - f_decoder_loss: 0.0320 - f_decoder_1_loss: 0.0672 - u_decoder_1_loss: 0.4259 - val_loss: 1.1205 - val_u_decoder_loss: 0.0758 - val_f_decoder_loss: 0.0297 - val_f_decoder_1_loss: 0.1408 - val_u_decoder_1_loss: 0.6973\n",
      "Epoch 475/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7645 - u_decoder_loss: 0.0657 - f_decoder_loss: 0.0476 - f_decoder_1_loss: 0.0964 - u_decoder_1_loss: 0.4166 - val_loss: 0.7751 - val_u_decoder_loss: 0.0785 - val_f_decoder_loss: 0.0315 - val_f_decoder_1_loss: 0.1102 - val_u_decoder_1_loss: 0.4403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7023 - u_decoder_loss: 0.0628 - f_decoder_loss: 0.0320 - f_decoder_1_loss: 0.0800 - u_decoder_1_loss: 0.4010 - val_loss: 1.3102 - val_u_decoder_loss: 0.1125 - val_f_decoder_loss: 0.0425 - val_f_decoder_1_loss: 0.3948 - val_u_decoder_1_loss: 0.5103\n",
      "Epoch 477/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 1.0498 - u_decoder_loss: 0.0753 - f_decoder_loss: 0.0920 - f_decoder_1_loss: 0.2341 - u_decoder_1_loss: 0.3705 - val_loss: 2.6132 - val_u_decoder_loss: 0.0982 - val_f_decoder_loss: 0.3283 - val_f_decoder_1_loss: 1.1210 - val_u_decoder_1_loss: 0.6295\n",
      "Epoch 478/500\n",
      "4798/4798 [==============================] - 1s 182us/sample - loss: 0.8667 - u_decoder_loss: 0.0675 - f_decoder_loss: 0.0824 - f_decoder_1_loss: 0.1497 - u_decoder_1_loss: 0.4059 - val_loss: 1.0102 - val_u_decoder_loss: 0.0884 - val_f_decoder_loss: 0.0580 - val_f_decoder_1_loss: 0.1466 - val_u_decoder_1_loss: 0.5355\n",
      "Epoch 479/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8879 - u_decoder_loss: 0.0938 - f_decoder_loss: 0.0479 - f_decoder_1_loss: 0.1338 - u_decoder_1_loss: 0.4085 - val_loss: 1.2505 - val_u_decoder_loss: 0.1218 - val_f_decoder_loss: 0.0859 - val_f_decoder_1_loss: 0.3722 - val_u_decoder_1_loss: 0.4028\n",
      "Epoch 480/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.9410 - u_decoder_loss: 0.1068 - f_decoder_loss: 0.0656 - f_decoder_1_loss: 0.1912 - u_decoder_1_loss: 0.3963 - val_loss: 0.9270 - val_u_decoder_loss: 0.0881 - val_f_decoder_loss: 0.0378 - val_f_decoder_1_loss: 0.2153 - val_u_decoder_1_loss: 0.4240\n",
      "Epoch 481/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6930 - u_decoder_loss: 0.0592 - f_decoder_loss: 0.0402 - f_decoder_1_loss: 0.0784 - u_decoder_1_loss: 0.3762 - val_loss: 0.9511 - val_u_decoder_loss: 0.0933 - val_f_decoder_loss: 0.0516 - val_f_decoder_1_loss: 0.1155 - val_u_decoder_1_loss: 0.4740\n",
      "Epoch 482/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8453 - u_decoder_loss: 0.0735 - f_decoder_loss: 0.0710 - f_decoder_1_loss: 0.1444 - u_decoder_1_loss: 0.4047 - val_loss: 1.0736 - val_u_decoder_loss: 0.0687 - val_f_decoder_loss: 0.0390 - val_f_decoder_1_loss: 0.1589 - val_u_decoder_1_loss: 0.6349\n",
      "Epoch 483/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7134 - u_decoder_loss: 0.0587 - f_decoder_loss: 0.0373 - f_decoder_1_loss: 0.0917 - u_decoder_1_loss: 0.3890 - val_loss: 0.7672 - val_u_decoder_loss: 0.0602 - val_f_decoder_loss: 0.0277 - val_f_decoder_1_loss: 0.1605 - val_u_decoder_1_loss: 0.3944\n",
      "Epoch 484/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.5349 - u_decoder_loss: 0.0526 - f_decoder_loss: 0.0238 - f_decoder_1_loss: 0.0465 - u_decoder_1_loss: 0.3200 - val_loss: 0.7285 - val_u_decoder_loss: 0.0695 - val_f_decoder_loss: 0.0209 - val_f_decoder_1_loss: 0.1145 - val_u_decoder_1_loss: 0.3886\n",
      "Epoch 485/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8092 - u_decoder_loss: 0.0678 - f_decoder_loss: 0.0387 - f_decoder_1_loss: 0.0739 - u_decoder_1_loss: 0.4897 - val_loss: 0.8852 - val_u_decoder_loss: 0.0770 - val_f_decoder_loss: 0.0370 - val_f_decoder_1_loss: 0.1356 - val_u_decoder_1_loss: 0.4827\n",
      "Epoch 486/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8192 - u_decoder_loss: 0.0596 - f_decoder_loss: 0.0543 - f_decoder_1_loss: 0.1050 - u_decoder_1_loss: 0.4714 - val_loss: 0.9296 - val_u_decoder_loss: 0.0735 - val_f_decoder_loss: 0.0344 - val_f_decoder_1_loss: 0.1432 - val_u_decoder_1_loss: 0.5175\n",
      "Epoch 487/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.9817 - u_decoder_loss: 0.0787 - f_decoder_loss: 0.0473 - f_decoder_1_loss: 0.0876 - u_decoder_1_loss: 0.4739 - val_loss: 1.0822 - val_u_decoder_loss: 0.0753 - val_f_decoder_loss: 0.0405 - val_f_decoder_1_loss: 0.1743 - val_u_decoder_1_loss: 0.6284\n",
      "Epoch 488/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7295 - u_decoder_loss: 0.0625 - f_decoder_loss: 0.0478 - f_decoder_1_loss: 0.1035 - u_decoder_1_loss: 0.3915 - val_loss: 0.8261 - val_u_decoder_loss: 0.0847 - val_f_decoder_loss: 0.0394 - val_f_decoder_1_loss: 0.1616 - val_u_decoder_1_loss: 0.3881\n",
      "Epoch 489/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.7071 - u_decoder_loss: 0.0626 - f_decoder_loss: 0.0471 - f_decoder_1_loss: 0.0808 - u_decoder_1_loss: 0.3901 - val_loss: 0.8837 - val_u_decoder_loss: 0.0676 - val_f_decoder_loss: 0.0622 - val_f_decoder_1_loss: 0.1768 - val_u_decoder_1_loss: 0.4375\n",
      "Epoch 490/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.8424 - u_decoder_loss: 0.0674 - f_decoder_loss: 0.0597 - f_decoder_1_loss: 0.1111 - u_decoder_1_loss: 0.3926 - val_loss: 1.1359 - val_u_decoder_loss: 0.0751 - val_f_decoder_loss: 0.0514 - val_f_decoder_1_loss: 0.1910 - val_u_decoder_1_loss: 0.6486\n",
      "Epoch 491/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.5978 - u_decoder_loss: 0.0479 - f_decoder_loss: 0.0378 - f_decoder_1_loss: 0.0707 - u_decoder_1_loss: 0.3492 - val_loss: 0.9186 - val_u_decoder_loss: 0.0595 - val_f_decoder_loss: 0.0265 - val_f_decoder_1_loss: 0.1233 - val_u_decoder_1_loss: 0.5716\n",
      "Epoch 492/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6432 - u_decoder_loss: 0.0620 - f_decoder_loss: 0.0316 - f_decoder_1_loss: 0.0729 - u_decoder_1_loss: 0.3721 - val_loss: 0.9250 - val_u_decoder_loss: 0.0817 - val_f_decoder_loss: 0.0436 - val_f_decoder_1_loss: 0.1468 - val_u_decoder_1_loss: 0.5162\n",
      "Epoch 493/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.5124 - u_decoder_loss: 0.0456 - f_decoder_loss: 0.0291 - f_decoder_1_loss: 0.0623 - u_decoder_1_loss: 0.2886 - val_loss: 1.1784 - val_u_decoder_loss: 0.0591 - val_f_decoder_loss: 0.0311 - val_f_decoder_1_loss: 0.1416 - val_u_decoder_1_loss: 0.7142\n",
      "Epoch 494/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.7026 - u_decoder_loss: 0.0574 - f_decoder_loss: 0.0499 - f_decoder_1_loss: 0.0931 - u_decoder_1_loss: 0.3726 - val_loss: 0.9479 - val_u_decoder_loss: 0.0897 - val_f_decoder_loss: 0.0492 - val_f_decoder_1_loss: 0.1755 - val_u_decoder_1_loss: 0.4391\n",
      "Epoch 495/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.8090 - u_decoder_loss: 0.0795 - f_decoder_loss: 0.0495 - f_decoder_1_loss: 0.1019 - u_decoder_1_loss: 0.4421 - val_loss: 0.8707 - val_u_decoder_loss: 0.1210 - val_f_decoder_loss: 0.0243 - val_f_decoder_1_loss: 0.1832 - val_u_decoder_1_loss: 0.4257\n",
      "Epoch 496/500\n",
      "4798/4798 [==============================] - 1s 179us/sample - loss: 0.8926 - u_decoder_loss: 0.0680 - f_decoder_loss: 0.0787 - f_decoder_1_loss: 0.2166 - u_decoder_1_loss: 0.3240 - val_loss: 1.5948 - val_u_decoder_loss: 0.1178 - val_f_decoder_loss: 0.0691 - val_f_decoder_1_loss: 0.3180 - val_u_decoder_1_loss: 0.4889\n",
      "Epoch 497/500\n",
      "4798/4798 [==============================] - 1s 178us/sample - loss: 0.6388 - u_decoder_loss: 0.0543 - f_decoder_loss: 0.0391 - f_decoder_1_loss: 0.0929 - u_decoder_1_loss: 0.3283 - val_loss: 0.9322 - val_u_decoder_loss: 0.1137 - val_f_decoder_loss: 0.0333 - val_f_decoder_1_loss: 0.1810 - val_u_decoder_1_loss: 0.4578\n",
      "Epoch 498/500\n",
      "4798/4798 [==============================] - 1s 183us/sample - loss: 1.0451 - u_decoder_loss: 0.1081 - f_decoder_loss: 0.0929 - f_decoder_1_loss: 0.1560 - u_decoder_1_loss: 0.4822 - val_loss: 1.0546 - val_u_decoder_loss: 0.1149 - val_f_decoder_loss: 0.0485 - val_f_decoder_1_loss: 0.2188 - val_u_decoder_1_loss: 0.4879\n",
      "Epoch 499/500\n",
      "4798/4798 [==============================] - 1s 181us/sample - loss: 0.6489 - u_decoder_loss: 0.0615 - f_decoder_loss: 0.0387 - f_decoder_1_loss: 0.0855 - u_decoder_1_loss: 0.3565 - val_loss: 0.7985 - val_u_decoder_loss: 0.0696 - val_f_decoder_loss: 0.0437 - val_f_decoder_1_loss: 0.1566 - val_u_decoder_1_loss: 0.4208\n",
      "Epoch 500/500\n",
      "4798/4798 [==============================] - 1s 180us/sample - loss: 0.7497 - u_decoder_loss: 0.0806 - f_decoder_loss: 0.0514 - f_decoder_1_loss: 0.0928 - u_decoder_1_loss: 0.4018 - val_loss: 1.2994 - val_u_decoder_loss: 0.0617 - val_f_decoder_loss: 0.0943 - val_f_decoder_1_loss: 0.3845 - val_u_decoder_1_loss: 0.4040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 31s, sys: 5min 44s, total: 22min 15s\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = linked_aec.fit(x=[data_train_u, data_train_f], \n",
    "                      y=[data_train_u, data_train_f, data_train_f, data_train_u], \n",
    "                      validation_data=val_data,\n",
    "                      #callbacks=cbs,\n",
    "                      **fit_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.models.save_model(linked_aec, \"dae.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_objects={\"NormalizedMeanSquaredError\": NMSE,\n",
    "#                \"SymmetricOperator\": SymmetricOperator,\n",
    "#                \"Identity\": tf.keras.initializers.Identity}\n",
    "#loaded = keras.models.load_model(\"dae.tf\", custom_objects)\n",
    "#test_aec = keras.models.load_model(\"dae-test\")\n",
    "\n",
    "#tf.saved_model.save(linked_aec, \"dae-test\")\n",
    "#test_aec = tf.saved_model.load(\"dae-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON config (architecture) to disk\n",
    "model_json = linked_aec.to_json()\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the weights to disk\n",
    "linked_aec.save_weights(\"weights.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_aec.layers[1].layers[3].variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_aec, f_aec, f_pred, u_pred = linked_aec.predict(x=[data_train_u, data_train_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ind = 0\n",
    "x_pts = np.linspace(0,2*np.pi,n)\n",
    "\n",
    "plt.figure() \n",
    "\n",
    "plt.plot(x_pts, data_train_f[ind,:], 'C1', linewidth=2, label=\"F true\")\n",
    "plt.plot(x_pts, f_aec[ind,:], '--r', markersize=2, label=\"F -> f -> F\")\n",
    "plt.plot(x_pts, f_pred[ind,:], 'o--k', markersize=5, label=\"Lv -> F\")\n",
    "\n",
    "plt.legend(loc=\"upper right\",fontsize=16)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.figure() \n",
    "\n",
    "plt.plot(x_pts, data_train_u[ind,:], 'C1', linewidth=2, label=\"u true\")\n",
    "plt.plot(x_pts, u_aec[ind,:], '--r', markersize=2, label=\"u -> v -> u\")\n",
    "plt.plot(x_pts, u_pred[ind,:], 'o--k', markersize=5, label=r\"$L^{-1}$f -> u\")\n",
    "\n",
    "plt.legend(loc=\"upper right\",fontsize=16)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
