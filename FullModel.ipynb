{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from OperatorLayer import SymmetricOperator\n",
    "from NormalizedMeanSquaredError import NormalizedMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Duffing_Equation_expt4'  ## FILL IN HERE (from file name)\n",
    "data_folder = '../NODE-Operators/data/'\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_train_u = np.load(data_folder + \"{}_train1_u.npy\".format(data_name))\n",
    "data_train_f = np.load(data_folder + \"{}_train1_f.npy\".format(data_name))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_val_u = np.load(data_folder + \"{}_val_u.npy\".format(data_name))\n",
    "data_val_f = np.load(data_folder + \"{}_val_f.npy\".format(data_name))\n",
    "\n",
    "# data is num_steps x num_examples x n\n",
    "data_test_u = np.load(data_folder + \"{}_test2_u.npy\".format(data_name))\n",
    "data_test_f = np.load(data_folder + \"{}_test2_f.npy\".format(data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "def construct_encoder(n, l, act_layer_config, lin_layer_config):\n",
    "    # First build the encoder\n",
    "    input_ = keras.layers.Input(shape=n)\n",
    "    hidden1 = keras.layers.Dense(n, **act_layer_config)(input_)\n",
    "    hidden2 = keras.layers.Dense(n, **act_layer_config)(hidden1)\n",
    "    hidden3 = keras.layers.Dense(n, **lin_layer_config)(hidden2)\n",
    "    added = keras.layers.Add()([input_, hidden3])\n",
    "    latentspace = keras.layers.Dense(l, **lin_layer_config)(added)\n",
    "    encoder = keras.Model(inputs=[input_], outputs=[latentspace])\n",
    "    return encoder\n",
    "\n",
    "def construct_decoder(n, l, act_layer_config, lin_layer_config):\n",
    "    # Now the decoder\n",
    "    latent_ = keras.layers.Input(shape=l)\n",
    "    hidden4 = keras.layers.Dense(n, **lin_layer_config)(latent_)\n",
    "    hidden5 = keras.layers.Dense(n, **act_layer_config)(hidden4)\n",
    "    hidden6 = keras.layers.Dense(n, **act_layer_config)(hidden5)\n",
    "    hidden7 = keras.layers.Dense(n, **act_layer_config)(hidden6)\n",
    "    added_ = keras.layers.Add()([hidden4, hidden7])\n",
    "    decoder = keras.Model(inputs=[latent_], outputs=[added_])\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training contains: 4798 samples.\n",
      "Validation contains: 1200 samples.\n",
      "Input vector is 128 neurons and latent space is 20 neurons.\n"
     ]
    }
   ],
   "source": [
    "_, n = data_train_u.shape\n",
    "l = 20\n",
    "\n",
    "print(\"Training contains:\", data_train_u.shape[0], \"samples.\")\n",
    "print(\"Validation contains:\", data_val_u.shape[0], \"samples.\")\n",
    "print(\"Input vector is\", n, \"neurons and latent space is\", l, \"neurons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration to be used for layers with activation functions and linear, non-activated functions\n",
    "#act_layer = dict(activation=\"relu\", kernel_initializer='he_normal')\n",
    "act_layer = dict(activation=\"elu\", kernel_initializer='he_normal')\n",
    "lin_layer = dict(activation=None)\n",
    "\n",
    "# Encoder and decoder for u\n",
    "u_enc = construct_encoder(n, l, act_layer, lin_layer)\n",
    "u_dec = construct_decoder(n, l, act_layer, lin_layer)\n",
    "\n",
    "# Encoder and decoder for u\n",
    "f_enc = construct_encoder(n, l, act_layer, lin_layer)\n",
    "f_dec = construct_decoder(n, l, act_layer, lin_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer to be used\n",
    "optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# Specify fit options\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "cbs = [keras.callbacks.ModelCheckpoint(\"dae.h5\", save_best_only=True),\n",
    "       keras.callbacks.EarlyStopping(),\n",
    "       keras.callbacks.TensorBoard(log_dir=logdir)]\n",
    "\n",
    "fit_options = dict(batch_size = 20, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "encoder_loss = NormalizedMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now assemble the COMPLETE, LINKED autoencoder!!\n",
    "u_input = keras.layers.Input(shape=n)\n",
    "u_encoded = u_enc(u_input)\n",
    "\n",
    "f_input = keras.layers.Input(shape=n)\n",
    "f_encoded = f_enc(f_input)\n",
    "\n",
    "Operator = SymmetricOperator()\n",
    "OperatorLayer = Operator(u_encoded)\n",
    "\n",
    "DiffLayer = keras.layers.Subtract()([OperatorLayer, f_encoded])\n",
    "\n",
    "u_decoded = u_dec(u_encoded)\n",
    "f_decoded = f_dec(f_encoded)\n",
    "\n",
    "#Lv_decoded = f_dec(OperatorLayer)\n",
    "#Linvf_decoded = u_dec(HypotheticalInverseOperatorLayer)\n",
    "\n",
    "# Add the Lv=f loss functions\n",
    "#Lv_decoded.add_loss(NormalizedMeanSquaredError(), OperatorLayer, f_encoded)\n",
    "\n",
    "linked_aec = keras.Model(inputs = [u_input, f_input], \n",
    "                         outputs = [u_decoded, f_decoded, DiffLayer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_aec.compile(loss=[\"mse\",\"mse\", \"mse\"], optimizer=optimizer)\n",
    "linked_aec.compile(loss=[encoder_loss, encoder_loss, \"mse\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4798 samples, validate on 1200 samples\n",
      "Epoch 1/5\n",
      "4798/4798 [==============================] - 2s 339us/sample - loss: 32.9213 - model_1_loss: 0.0720 - model_3_loss: 0.2584 - subtract_loss: 32.5776 - val_loss: 1.3524 - val_model_1_loss: 0.0480 - val_model_3_loss: 0.1932 - val_subtract_loss: 1.1111\n",
      "Epoch 2/5\n",
      "4798/4798 [==============================] - 1s 131us/sample - loss: 1.5208 - model_1_loss: 0.0405 - model_3_loss: 0.1727 - subtract_loss: 1.3072 - val_loss: 1.4611 - val_model_1_loss: 0.0368 - val_model_3_loss: 0.1673 - val_subtract_loss: 1.2570\n",
      "CPU times: user 3.9 s, sys: 1.26 s, total: 5.17 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_zeros = np.zeros((data_train_u.shape[0], l))\n",
    "val_zeros = np.zeros((data_val_u.shape[0], l))\n",
    "\n",
    "val_data = [(data_val_u, data_val_f), \n",
    "            (data_val_u, data_val_f, val_zeros)]\n",
    "\n",
    "hist = linked_aec.fit(x=[data_train_u, data_train_f], \n",
    "                      y=[data_train_u, data_train_f, train_zeros], \n",
    "                      validation_data=val_data,\n",
    "                      callbacks=cbs,\n",
    "                      **fit_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "L = Operator.get_operator()\n",
    "\n",
    "# Prove that L = L^T\n",
    "maxval = tf.reduce_max(L - tf.transpose(L))\n",
    "minval = tf.reduce_min(L - tf.transpose(L))\n",
    "\n",
    "print(maxval)\n",
    "print(minval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20), dtype=float32, numpy=\n",
       "array([[ 9.7085786e-01, -5.8497833e-03,  5.0409157e-03, -2.8856765e-03,\n",
       "        -9.4164256e-03, -8.7504694e-03, -5.8301375e-03, -3.1823774e-03,\n",
       "        -2.8548392e-03, -1.4397322e-03, -6.4743902e-03, -8.4049050e-03,\n",
       "        -7.6888292e-03,  8.1949746e-03, -3.5686686e-03, -4.2094789e-03,\n",
       "        -2.2930824e-03, -1.3181175e-03,  2.2913425e-03,  5.2124518e-03],\n",
       "       [-5.8497833e-03,  9.6714008e-01, -6.7858365e-03, -3.5847349e-03,\n",
       "        -8.6577162e-03, -7.8964410e-03, -3.2776727e-03, -5.4884079e-04,\n",
       "        -3.1228128e-03, -1.5713392e-03, -6.5794121e-03, -1.0688985e-03,\n",
       "        -4.1762022e-03, -8.9553927e-05, -1.4480730e-03, -5.5965420e-04,\n",
       "         4.2241453e-03, -1.3726356e-02, -2.1058025e-03,  2.6914442e-03],\n",
       "       [ 5.0409157e-03, -6.7858365e-03,  9.8412400e-01,  8.8865060e-04,\n",
       "         9.5485002e-03,  3.8745902e-03, -7.8534411e-04, -9.6024305e-04,\n",
       "        -3.3684625e-04,  5.3334609e-04,  1.8248372e-03,  2.4453941e-04,\n",
       "         1.0343121e-03, -5.9761056e-03,  2.7064758e-04,  1.3747712e-03,\n",
       "         5.6459391e-03, -9.2714070e-04,  6.3955097e-04, -4.6273917e-03],\n",
       "       [-2.8856765e-03, -3.5847349e-03,  8.8865060e-04,  9.6364838e-01,\n",
       "        -2.5339711e-03, -2.1483675e-03, -1.4831506e-03, -3.3102436e-03,\n",
       "         6.4277989e-03,  5.9188828e-03, -1.8198262e-03, -8.1414729e-04,\n",
       "         6.0580536e-03,  4.3221805e-03,  2.6771674e-04, -1.8887059e-03,\n",
       "         5.1265392e-03,  4.4070400e-04,  4.1971975e-03,  4.0537663e-04],\n",
       "       [-9.4164256e-03, -8.6577162e-03,  9.5485002e-03, -2.5339711e-03,\n",
       "         9.7229952e-01, -1.1127097e-02, -5.6661554e-03, -1.2645966e-04,\n",
       "        -4.0142187e-03, -2.8756682e-03, -8.6528966e-03, -2.9226574e-03,\n",
       "        -7.6579866e-03,  8.4515866e-03, -3.3834246e-03, -3.6184657e-03,\n",
       "        -3.4342401e-04, -5.8089937e-03, -1.9391223e-03,  4.4738804e-03],\n",
       "       [-8.7504694e-03, -7.8964410e-03,  3.8745902e-03, -2.1483675e-03,\n",
       "        -1.1127097e-02,  9.7391295e-01, -7.6914644e-03, -4.3535098e-03,\n",
       "        -1.1264120e-02, -4.8584016e-03, -7.6324223e-03, -4.3669986e-03,\n",
       "        -7.0056939e-03,  6.7397710e-03, -3.5926669e-03, -3.4551211e-03,\n",
       "         4.1075060e-03, -7.1826158e-03, -3.0781259e-04,  4.7136657e-03],\n",
       "       [-5.8301375e-03, -3.2776727e-03, -7.8534411e-04, -1.4831506e-03,\n",
       "        -5.6661554e-03, -7.6914644e-03,  9.7274500e-01,  4.8523844e-04,\n",
       "         1.3387881e-03,  3.7273075e-03, -4.6958607e-03, -8.3026411e-03,\n",
       "        -5.4339287e-03, -4.2993878e-03, -9.0609316e-04, -4.2462898e-03,\n",
       "         3.5999611e-03, -4.7958903e-03, -5.4622552e-04,  1.0497526e-02],\n",
       "       [-3.1823774e-03, -5.4884079e-04, -9.6024305e-04, -3.3102436e-03,\n",
       "        -1.2645966e-04, -4.3535098e-03,  4.8523844e-04,  9.7335386e-01,\n",
       "        -4.9530966e-03,  7.6388489e-03, -1.7262594e-03, -3.4558680e-03,\n",
       "         2.1670449e-03,  4.5847413e-03, -1.3317182e-03,  5.8193365e-03,\n",
       "         3.9301822e-03,  5.5499314e-03, -5.4718764e-03,  4.5998190e-03],\n",
       "       [-2.8548392e-03, -3.1228128e-03, -3.3684625e-04,  6.4277989e-03,\n",
       "        -4.0142187e-03, -1.1264120e-02,  1.3387881e-03, -4.9530966e-03,\n",
       "         9.5056134e-01, -3.7180504e-04,  4.9180147e-04,  5.6677307e-03,\n",
       "        -3.7603225e-03,  5.0002914e-03, -8.9329155e-03, -1.5463388e-02,\n",
       "        -2.2820784e-03, -1.8579413e-03,  6.6018300e-03, -3.2327804e-03],\n",
       "       [-1.4397322e-03, -1.5713392e-03,  5.3334609e-04,  5.9188828e-03,\n",
       "        -2.8756682e-03, -4.8584016e-03,  3.7273075e-03,  7.6388489e-03,\n",
       "        -3.7180504e-04,  9.6637273e-01, -9.7084825e-04, -4.6792962e-03,\n",
       "        -1.3451681e-03, -1.3469966e-03,  5.5530824e-04, -8.1932108e-04,\n",
       "         1.9626627e-03, -4.5247674e-03, -1.2748220e-03,  7.5333577e-04],\n",
       "       [-6.4743902e-03, -6.5794121e-03,  1.8248372e-03, -1.8198262e-03,\n",
       "        -8.6528966e-03, -7.6324223e-03, -4.6958607e-03, -1.7262594e-03,\n",
       "         4.9180147e-04, -9.7084825e-04,  9.7770733e-01, -4.8638266e-03,\n",
       "        -6.8004685e-03, -2.6826304e-04, -5.2054543e-03, -2.6594528e-03,\n",
       "         3.1875253e-03, -5.4284921e-03,  1.9737675e-03,  3.7880202e-03],\n",
       "       [-8.4049050e-03, -1.0688985e-03,  2.4453941e-04, -8.1414729e-04,\n",
       "        -2.9226574e-03, -4.3669986e-03, -8.3026411e-03, -3.4558680e-03,\n",
       "         5.6677307e-03, -4.6792962e-03, -4.8638266e-03,  9.7868651e-01,\n",
       "        -5.4511316e-03,  5.3974343e-03,  2.3604834e-03,  1.4556110e-03,\n",
       "        -3.7552428e-03,  3.6229409e-04, -1.9828985e-03,  4.1969786e-03],\n",
       "       [-7.6888292e-03, -4.1762022e-03,  1.0343121e-03,  6.0580536e-03,\n",
       "        -7.6579866e-03, -7.0056939e-03, -5.4339287e-03,  2.1670449e-03,\n",
       "        -3.7603225e-03, -1.3451681e-03, -6.8004685e-03, -5.4511316e-03,\n",
       "         9.7996408e-01,  1.4098845e-03, -4.3341732e-03, -3.3786127e-03,\n",
       "        -6.7748521e-03, -2.1175300e-03, -1.0544305e-03,  3.9461423e-03],\n",
       "       [ 8.1949746e-03, -8.9553927e-05, -5.9761056e-03,  4.3221805e-03,\n",
       "         8.4515866e-03,  6.7397710e-03, -4.2993878e-03,  4.5847413e-03,\n",
       "         5.0002914e-03, -1.3469966e-03, -2.6826304e-04,  5.3974343e-03,\n",
       "         1.4098845e-03,  9.5975047e-01,  1.9685645e-03, -2.0193546e-03,\n",
       "         3.6768266e-03,  6.2262253e-03, -3.1156417e-03, -1.0125389e-03],\n",
       "       [-3.5686686e-03, -1.4480730e-03,  2.7064758e-04,  2.6771674e-04,\n",
       "        -3.3834246e-03, -3.5926669e-03, -9.0609316e-04, -1.3317182e-03,\n",
       "        -8.9329155e-03,  5.5530824e-04, -5.2054543e-03,  2.3604834e-03,\n",
       "        -4.3341732e-03,  1.9685645e-03,  9.7604680e-01, -8.7651564e-03,\n",
       "        -1.8078822e-03,  3.1371259e-03,  4.0891808e-03, -8.4422197e-04],\n",
       "       [-4.2094789e-03, -5.5965420e-04,  1.3747712e-03, -1.8887059e-03,\n",
       "        -3.6184657e-03, -3.4551211e-03, -4.2462898e-03,  5.8193365e-03,\n",
       "        -1.5463388e-02, -8.1932108e-04, -2.6594528e-03,  1.4556110e-03,\n",
       "        -3.3786127e-03, -2.0193546e-03, -8.7651564e-03,  9.7360742e-01,\n",
       "        -3.7836449e-03, -4.3582753e-04,  2.3679170e-03, -3.9792671e-03],\n",
       "       [-2.2930824e-03,  4.2241453e-03,  5.6459391e-03,  5.1265392e-03,\n",
       "        -3.4342401e-04,  4.1075060e-03,  3.5999611e-03,  3.9301822e-03,\n",
       "        -2.2820784e-03,  1.9626627e-03,  3.1875253e-03, -3.7552428e-03,\n",
       "        -6.7748521e-03,  3.6768266e-03, -1.8078822e-03, -3.7836449e-03,\n",
       "         9.7013921e-01, -6.3845050e-04, -9.7357540e-04, -8.9499488e-04],\n",
       "       [-1.3181175e-03, -1.3726356e-02, -9.2714070e-04,  4.4070400e-04,\n",
       "        -5.8089937e-03, -7.1826158e-03, -4.7958903e-03,  5.5499314e-03,\n",
       "        -1.8579413e-03, -4.5247674e-03, -5.4284921e-03,  3.6229409e-04,\n",
       "        -2.1175300e-03,  6.2262253e-03,  3.1371259e-03, -4.3582753e-04,\n",
       "        -6.3845050e-04,  9.4374710e-01,  5.7593791e-04,  1.7915224e-03],\n",
       "       [ 2.2913425e-03, -2.1058025e-03,  6.3955097e-04,  4.1971975e-03,\n",
       "        -1.9391223e-03, -3.0781259e-04, -5.4622552e-04, -5.4718764e-03,\n",
       "         6.6018300e-03, -1.2748220e-03,  1.9737675e-03, -1.9828985e-03,\n",
       "        -1.0544305e-03, -3.1156417e-03,  4.0891808e-03,  2.3679170e-03,\n",
       "        -9.7357540e-04,  5.7593791e-04,  9.7647297e-01,  7.5721834e-03],\n",
       "       [ 5.2124518e-03,  2.6914442e-03, -4.6273917e-03,  4.0537663e-04,\n",
       "         4.4738804e-03,  4.7136657e-03,  1.0497526e-02,  4.5998190e-03,\n",
       "        -3.2327804e-03,  7.5333577e-04,  3.7880202e-03,  4.1969786e-03,\n",
       "         3.9461423e-03, -1.0125389e-03, -8.4422197e-04, -3.9792671e-03,\n",
       "        -8.9499488e-04,  1.7915224e-03,  7.5721834e-03,  9.6440256e-01]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
