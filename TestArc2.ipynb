{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3.6\n",
    "import random as r\n",
    "import json\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AbstractArchitecture_v2 import AbstractArchitecture\n",
    "from DenseEncoder import DenseEncoder\n",
    "from DenseDecoder import DenseDecoder\n",
    "from NormalizedMeanSquaredError import NormalizedMeanSquaredError as NMSE\n",
    "from plot_model_prediction import plot_model_prediction\n",
    "\n",
    "\n",
    "# Set Experiment Specifics\n",
    "expt_name = \"Experiment_03\"\n",
    "data_file_prefix = './data/NLSL_expt1'  ## FILL IN HERE (from file name)\n",
    "\n",
    "# Network architecture design\n",
    "l = 20  # Latent space size\n",
    "\n",
    "activation = \"relu\"\n",
    "initializer = tf.keras.initializers.VarianceScaling()\n",
    "reg_lambda_l2 = 1e-6\n",
    "regularizer = tf.keras.regularizers.l2(reg_lambda_l2)\n",
    "\n",
    "act_layer = dict(activation=activation,\n",
    "                 kernel_initializer=initializer,\n",
    "                 kernel_regularizer=regularizer)\n",
    "lin_layer = dict(activation=None,\n",
    "                 kernel_initializer=initializer,\n",
    "                 kernel_regularizer=regularizer)\n",
    "latent_config = dict(activation=None, \n",
    "                     kernel_regularizer=regularizer,\n",
    "                     use_bias=False)\n",
    "\n",
    "encoder_layers = 5\n",
    "decoder_layers = 5\n",
    "add_identity = True\n",
    "\n",
    "# Model training settings\n",
    "## Set optimizer\n",
    "optimizer = keras.optimizers.Adam\n",
    "optimizer_opts = {}\n",
    "\n",
    "# Callback function(s) and fit method options\n",
    "cbs = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "\n",
    "# Batch size for model training\n",
    "batch_size = 64\n",
    "\n",
    "# Time to train autoencoders only and full models for initial seeding test\n",
    "aec_only_time = 5  # minutes\n",
    "full_model_time = 5  # minutes \n",
    "\n",
    "# This number is used to compute number of epochs for full-model training\n",
    "final_model_train_hrs = 0.1\n",
    "\n",
    "\n",
    "############################################\n",
    "### Everything below here is automated!! ###\n",
    "############################################\n",
    "\n",
    "# Step 0. Assign a random number generator seed\n",
    "x = r.randint(0, 10**(10))\n",
    "r.seed(x)\n",
    "\n",
    "# Step 1. Load in the data\n",
    "data_train_u = np.load(\"{}_train1_u.npy\".format(data_file_prefix))\n",
    "data_train_f = np.load(\"{}_train1_f.npy\".format(data_file_prefix))\n",
    "data_val_u = np.load(\"{}_val_u.npy\".format(data_file_prefix))\n",
    "data_val_f = np.load(\"{}_val_f.npy\".format(data_file_prefix))\n",
    "data_test_u1 = np.load(\"{}_test1_u.npy\".format(data_file_prefix))\n",
    "data_test_f1 = np.load(\"{}_test1_f.npy\".format(data_file_prefix))\n",
    "data_test_u = np.load(\"{}_test2_u.npy\".format(data_file_prefix))\n",
    "data_test_f = np.load(\"{}_test2_f.npy\".format(data_file_prefix))\n",
    "\n",
    "# Step 2. Set up the model architecture\n",
    "_, n = data_train_u.shape\n",
    "\n",
    "encoder_config = {'units_full': n,\n",
    "                  'num_layers': encoder_layers,\n",
    "                  'actlay_config': act_layer,\n",
    "                  'linlay_config': lin_layer,\n",
    "                  'add_init_fin': add_identity}\n",
    "\n",
    "decoder_config = {'units_full': n,\n",
    "                  'num_layers': decoder_layers,\n",
    "                  'actlay_config': act_layer,\n",
    "                  'linlay_config': lin_layer,\n",
    "                  'add_init_fin': add_identity}\n",
    "\n",
    "# Aggregate settings for model architecture\n",
    "architecture_config = {\"units_latent\": l,\n",
    "                       \"u_encoder_block\": DenseEncoder(**encoder_config),\n",
    "                       \"u_decoder_block\": DenseDecoder(**decoder_config),\n",
    "                       \"F_encoder_block\": DenseEncoder(**encoder_config),\n",
    "                       \"F_decoder_block\": DenseDecoder(**decoder_config),\n",
    "                       \"latent_config\": latent_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model, initially only to train autoencoders!\n",
    "model = AbstractArchitecture(**architecture_config,\n",
    "                             train_autoencoders_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss functions\n",
    "loss_fns = 4*[NMSE()]\n",
    "\n",
    "# Set up validation data for autoencoders-only\n",
    "val_zeros = np.zeros(data_val_u.shape)\n",
    "val_data = [(data_val_u, data_val_f), \n",
    "            (data_val_u, data_val_f, val_zeros, val_zeros)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of epochs to train\n",
    "aec_epochs = int(aec_only_time*60*2)  # about 2 epochs/sec\n",
    "full_epochs = int(full_model_time*60)  # about 1 epoch/sec\n",
    "\n",
    "#aec_epochs = 1\n",
    "#full_epochs = 3\n",
    "\n",
    "# Randomly selected learning rate\n",
    "lr = 10**(-r.uniform(3, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8906 samples, validate on 2227 samples\n",
      "Epoch 1/600\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['abstract_architecture/symmetric_operator/operator:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['abstract_architecture/symmetric_operator/operator:0'] when minimizing the loss.\n",
      "8906/8906 [==============================] - 2s 266us/sample - loss: 1.9263 - output_1_loss: 0.9507 - output_2_loss: 0.9723 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.8429 - val_output_1_loss: 0.8997 - val_output_2_loss: 0.9404 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 2/600\n",
      "8906/8906 [==============================] - 1s 80us/sample - loss: 1.7304 - output_1_loss: 0.8310 - output_2_loss: 0.8960 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.5875 - val_output_1_loss: 0.7480 - val_output_2_loss: 0.8366 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 3/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 1.4827 - output_1_loss: 0.6863 - output_2_loss: 0.7941 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.3745 - val_output_1_loss: 0.6215 - val_output_2_loss: 0.7500 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 4/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 1.3371 - output_1_loss: 0.5963 - output_2_loss: 0.7389 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.2791 - val_output_1_loss: 0.5597 - val_output_2_loss: 0.7165 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 5/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 1.2726 - output_1_loss: 0.5533 - output_2_loss: 0.7166 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.2363 - val_output_1_loss: 0.5307 - val_output_2_loss: 0.7027 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 6/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 1.2429 - output_1_loss: 0.5325 - output_2_loss: 0.7076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.2158 - val_output_1_loss: 0.5160 - val_output_2_loss: 0.6969 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 7/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 1.2275 - output_1_loss: 0.5218 - output_2_loss: 0.7039 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.2039 - val_output_1_loss: 0.5073 - val_output_2_loss: 0.6937 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 8/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 1.2173 - output_1_loss: 0.5143 - output_2_loss: 0.7009 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.1949 - val_output_1_loss: 0.5014 - val_output_2_loss: 0.6907 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 9/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 1.2081 - output_1_loss: 0.5092 - output_2_loss: 0.6975 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.1853 - val_output_1_loss: 0.4964 - val_output_2_loss: 0.6862 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 10/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 1.1950 - output_1_loss: 0.5037 - output_2_loss: 0.6890 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.1661 - val_output_1_loss: 0.4918 - val_output_2_loss: 0.6714 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 11/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 1.1623 - output_1_loss: 0.4992 - output_2_loss: 0.6606 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.1263 - val_output_1_loss: 0.4874 - val_output_2_loss: 0.6361 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 12/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 1.1290 - output_1_loss: 0.4932 - output_2_loss: 0.6312 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.1023 - val_output_1_loss: 0.4830 - val_output_2_loss: 0.6166 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 13/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 1.1060 - output_1_loss: 0.4881 - output_2_loss: 0.6132 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.0808 - val_output_1_loss: 0.4779 - val_output_2_loss: 0.6002 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 14/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 1.0827 - output_1_loss: 0.4825 - output_2_loss: 0.5959 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.0576 - val_output_1_loss: 0.4713 - val_output_2_loss: 0.5836 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 15/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 1.0565 - output_1_loss: 0.4742 - output_2_loss: 0.5791 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 1.0293 - val_output_1_loss: 0.4605 - val_output_2_loss: 0.5661 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 16/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 1.0235 - output_1_loss: 0.4602 - output_2_loss: 0.5610 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.9920 - val_output_1_loss: 0.4415 - val_output_2_loss: 0.5478 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 17/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.9808 - output_1_loss: 0.4377 - output_2_loss: 0.5413 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.9451 - val_output_1_loss: 0.4155 - val_output_2_loss: 0.5269 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 18/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.9337 - output_1_loss: 0.4134 - output_2_loss: 0.5162 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.8976 - val_output_1_loss: 0.3927 - val_output_2_loss: 0.5023 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 19/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.8882 - output_1_loss: 0.3949 - output_2_loss: 0.4914 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.8534 - val_output_1_loss: 0.3744 - val_output_2_loss: 0.4764 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 20/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.8463 - output_1_loss: 0.3779 - output_2_loss: 0.4655 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.8129 - val_output_1_loss: 0.3596 - val_output_2_loss: 0.4507 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 21/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.8074 - output_1_loss: 0.3641 - output_2_loss: 0.4410 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.7754 - val_output_1_loss: 0.3468 - val_output_2_loss: 0.4260 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 22/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.7710 - output_1_loss: 0.3512 - output_2_loss: 0.4152 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.7402 - val_output_1_loss: 0.3346 - val_output_2_loss: 0.4030 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 23/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.7357 - output_1_loss: 0.3398 - output_2_loss: 0.3932 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.7062 - val_output_1_loss: 0.3221 - val_output_2_loss: 0.3815 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 24/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.6988 - output_1_loss: 0.3250 - output_2_loss: 0.3693 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.6691 - val_output_1_loss: 0.3073 - val_output_2_loss: 0.3591 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.6567 - output_1_loss: 0.3082 - output_2_loss: 0.3451 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.6251 - val_output_1_loss: 0.2872 - val_output_2_loss: 0.3352 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 26/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.6071 - output_1_loss: 0.2837 - output_2_loss: 0.3204 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.5750 - val_output_1_loss: 0.2615 - val_output_2_loss: 0.3108 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 27/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.5558 - output_1_loss: 0.2576 - output_2_loss: 0.2944 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.5272 - val_output_1_loss: 0.2369 - val_output_2_loss: 0.2874 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 28/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.5098 - output_1_loss: 0.2356 - output_2_loss: 0.2725 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.4859 - val_output_1_loss: 0.2168 - val_output_2_loss: 0.2663 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 29/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.4694 - output_1_loss: 0.2152 - output_2_loss: 0.2515 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.4489 - val_output_1_loss: 0.1989 - val_output_2_loss: 0.2470 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 30/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.4326 - output_1_loss: 0.1963 - output_2_loss: 0.2327 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.4144 - val_output_1_loss: 0.1816 - val_output_2_loss: 0.2299 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 31/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.3982 - output_1_loss: 0.1786 - output_2_loss: 0.2161 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.3832 - val_output_1_loss: 0.1654 - val_output_2_loss: 0.2148 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 32/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.3674 - output_1_loss: 0.1627 - output_2_loss: 0.2022 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.3550 - val_output_1_loss: 0.1514 - val_output_2_loss: 0.2007 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 33/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.3400 - output_1_loss: 0.1485 - output_2_loss: 0.1887 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.3307 - val_output_1_loss: 0.1393 - val_output_2_loss: 0.1884 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 34/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.3151 - output_1_loss: 0.1359 - output_2_loss: 0.1763 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.3072 - val_output_1_loss: 0.1280 - val_output_2_loss: 0.1762 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 35/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.2919 - output_1_loss: 0.1244 - output_2_loss: 0.1654 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.2851 - val_output_1_loss: 0.1173 - val_output_2_loss: 0.1649 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 36/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.2697 - output_1_loss: 0.1133 - output_2_loss: 0.1539 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.2643 - val_output_1_loss: 0.1071 - val_output_2_loss: 0.1543 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 37/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.2487 - output_1_loss: 0.1031 - output_2_loss: 0.1436 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.2438 - val_output_1_loss: 0.0972 - val_output_2_loss: 0.1438 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 38/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.2278 - output_1_loss: 0.0931 - output_2_loss: 0.1318 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.2238 - val_output_1_loss: 0.0879 - val_output_2_loss: 0.1330 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 39/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.2075 - output_1_loss: 0.0833 - output_2_loss: 0.1210 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.2045 - val_output_1_loss: 0.0789 - val_output_2_loss: 0.1227 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 40/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.1885 - output_1_loss: 0.0745 - output_2_loss: 0.1121 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1867 - val_output_1_loss: 0.0704 - val_output_2_loss: 0.1135 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 41/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.1716 - output_1_loss: 0.0662 - output_2_loss: 0.1024 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1707 - val_output_1_loss: 0.0624 - val_output_2_loss: 0.1055 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 42/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.1565 - output_1_loss: 0.0583 - output_2_loss: 0.0951 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1568 - val_output_1_loss: 0.0552 - val_output_2_loss: 0.0988 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 43/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.1430 - output_1_loss: 0.0513 - output_2_loss: 0.0891 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1439 - val_output_1_loss: 0.0487 - val_output_2_loss: 0.0925 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 44/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.1311 - output_1_loss: 0.0448 - output_2_loss: 0.0831 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1328 - val_output_1_loss: 0.0428 - val_output_2_loss: 0.0872 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 45/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.1207 - output_1_loss: 0.0395 - output_2_loss: 0.0785 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1231 - val_output_1_loss: 0.0378 - val_output_2_loss: 0.0825 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 46/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.1116 - output_1_loss: 0.0347 - output_2_loss: 0.0743 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1149 - val_output_1_loss: 0.0337 - val_output_2_loss: 0.0785 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 47/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.1037 - output_1_loss: 0.0305 - output_2_loss: 0.0703 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1069 - val_output_1_loss: 0.0297 - val_output_2_loss: 0.0745 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 48/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0967 - output_1_loss: 0.0269 - output_2_loss: 0.0671 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.1003 - val_output_1_loss: 0.0265 - val_output_2_loss: 0.0711 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 49/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0907 - output_1_loss: 0.0239 - output_2_loss: 0.0639 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0945 - val_output_1_loss: 0.0237 - val_output_2_loss: 0.0681 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0853 - output_1_loss: 0.0213 - output_2_loss: 0.0614 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0893 - val_output_1_loss: 0.0215 - val_output_2_loss: 0.0652 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 51/600\n",
      "8906/8906 [==============================] - 1s 80us/sample - loss: 0.0807 - output_1_loss: 0.0192 - output_2_loss: 0.0585 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0849 - val_output_1_loss: 0.0195 - val_output_2_loss: 0.0626 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 52/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0765 - output_1_loss: 0.0174 - output_2_loss: 0.0561 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0809 - val_output_1_loss: 0.0179 - val_output_2_loss: 0.0603 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 53/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0729 - output_1_loss: 0.0159 - output_2_loss: 0.0539 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0773 - val_output_1_loss: 0.0165 - val_output_2_loss: 0.0581 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 54/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0696 - output_1_loss: 0.0147 - output_2_loss: 0.0523 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0741 - val_output_1_loss: 0.0154 - val_output_2_loss: 0.0560 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 55/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0665 - output_1_loss: 0.0136 - output_2_loss: 0.0500 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0712 - val_output_1_loss: 0.0144 - val_output_2_loss: 0.0542 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 56/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0638 - output_1_loss: 0.0126 - output_2_loss: 0.0482 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0684 - val_output_1_loss: 0.0135 - val_output_2_loss: 0.0522 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 57/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0613 - output_1_loss: 0.0119 - output_2_loss: 0.0468 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0658 - val_output_1_loss: 0.0126 - val_output_2_loss: 0.0505 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 58/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0590 - output_1_loss: 0.0111 - output_2_loss: 0.0454 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0636 - val_output_1_loss: 0.0119 - val_output_2_loss: 0.0490 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 59/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0569 - output_1_loss: 0.0104 - output_2_loss: 0.0434 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0612 - val_output_1_loss: 0.0113 - val_output_2_loss: 0.0472 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 60/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0548 - output_1_loss: 0.0099 - output_2_loss: 0.0423 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0593 - val_output_1_loss: 0.0107 - val_output_2_loss: 0.0459 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 61/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0530 - output_1_loss: 0.0094 - output_2_loss: 0.0406 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0574 - val_output_1_loss: 0.0103 - val_output_2_loss: 0.0445 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 62/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0513 - output_1_loss: 0.0090 - output_2_loss: 0.0397 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0557 - val_output_1_loss: 0.0098 - val_output_2_loss: 0.0432 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 63/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.0497 - output_1_loss: 0.0086 - output_2_loss: 0.0384 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0541 - val_output_1_loss: 0.0093 - val_output_2_loss: 0.0421 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 64/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0483 - output_1_loss: 0.0081 - output_2_loss: 0.0372 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0525 - val_output_1_loss: 0.0089 - val_output_2_loss: 0.0409 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 65/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0468 - output_1_loss: 0.0078 - output_2_loss: 0.0360 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0511 - val_output_1_loss: 0.0086 - val_output_2_loss: 0.0399 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 66/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0455 - output_1_loss: 0.0075 - output_2_loss: 0.0351 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0498 - val_output_1_loss: 0.0083 - val_output_2_loss: 0.0389 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 67/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0443 - output_1_loss: 0.0072 - output_2_loss: 0.0344 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0487 - val_output_1_loss: 0.0080 - val_output_2_loss: 0.0381 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 68/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0432 - output_1_loss: 0.0069 - output_2_loss: 0.0334 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0474 - val_output_1_loss: 0.0077 - val_output_2_loss: 0.0371 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 69/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0421 - output_1_loss: 0.0067 - output_2_loss: 0.0333 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0464 - val_output_1_loss: 0.0074 - val_output_2_loss: 0.0364 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 70/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0411 - output_1_loss: 0.0063 - output_2_loss: 0.0318 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0452 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0356 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 71/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0402 - output_1_loss: 0.0061 - output_2_loss: 0.0311 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0443 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0349 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 72/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0393 - output_1_loss: 0.0059 - output_2_loss: 0.0307 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0435 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0343 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 73/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0385 - output_1_loss: 0.0056 - output_2_loss: 0.0300 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0426 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0337 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 74/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0377 - output_1_loss: 0.0054 - output_2_loss: 0.0294 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0418 - val_output_1_loss: 0.0060 - val_output_2_loss: 0.0332 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0370 - output_1_loss: 0.0052 - output_2_loss: 0.0293 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0412 - val_output_1_loss: 0.0058 - val_output_2_loss: 0.0327 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 76/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0364 - output_1_loss: 0.0050 - output_2_loss: 0.0285 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0404 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0322 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 77/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0358 - output_1_loss: 0.0049 - output_2_loss: 0.0288 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0399 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0317 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 78/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0352 - output_1_loss: 0.0047 - output_2_loss: 0.0276 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0392 - val_output_1_loss: 0.0053 - val_output_2_loss: 0.0313 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 79/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0346 - output_1_loss: 0.0045 - output_2_loss: 0.0274 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0386 - val_output_1_loss: 0.0051 - val_output_2_loss: 0.0309 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 80/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0341 - output_1_loss: 0.0043 - output_2_loss: 0.0268 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0380 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0305 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 81/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0335 - output_1_loss: 0.0042 - output_2_loss: 0.0265 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0375 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0301 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 82/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0331 - output_1_loss: 0.0041 - output_2_loss: 0.0261 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0370 - val_output_1_loss: 0.0046 - val_output_2_loss: 0.0298 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 83/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0326 - output_1_loss: 0.0039 - output_2_loss: 0.0259 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0366 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0295 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 84/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0322 - output_1_loss: 0.0040 - output_2_loss: 0.0259 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0361 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0291 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 85/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0318 - output_1_loss: 0.0037 - output_2_loss: 0.0252 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0357 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0288 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 86/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0314 - output_1_loss: 0.0036 - output_2_loss: 0.0249 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0354 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0285 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 87/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0310 - output_1_loss: 0.0035 - output_2_loss: 0.0246 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0348 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0282 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 88/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0306 - output_1_loss: 0.0034 - output_2_loss: 0.0244 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0344 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0279 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 89/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0302 - output_1_loss: 0.0033 - output_2_loss: 0.0241 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0341 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0276 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 90/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0299 - output_1_loss: 0.0032 - output_2_loss: 0.0238 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0337 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0273 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 91/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0296 - output_1_loss: 0.0031 - output_2_loss: 0.0238 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0334 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0271 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 92/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0293 - output_1_loss: 0.0031 - output_2_loss: 0.0234 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0330 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0267 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 93/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0290 - output_1_loss: 0.0030 - output_2_loss: 0.0233 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0327 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0266 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 94/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0287 - output_1_loss: 0.0029 - output_2_loss: 0.0234 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0324 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0263 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 95/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0284 - output_1_loss: 0.0029 - output_2_loss: 0.0229 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0322 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0261 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 96/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0281 - output_1_loss: 0.0028 - output_2_loss: 0.0225 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0317 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0258 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 97/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0278 - output_1_loss: 0.0027 - output_2_loss: 0.0222 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0314 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0256 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 98/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0275 - output_1_loss: 0.0027 - output_2_loss: 0.0220 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0311 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0253 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 99/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0273 - output_1_loss: 0.0026 - output_2_loss: 0.0223 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0310 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0252 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0271 - output_1_loss: 0.0026 - output_2_loss: 0.0219 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0306 - val_output_1_loss: 0.0031 - val_output_2_loss: 0.0249 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 101/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0268 - output_1_loss: 0.0025 - output_2_loss: 0.0214 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0303 - val_output_1_loss: 0.0030 - val_output_2_loss: 0.0247 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 102/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0265 - output_1_loss: 0.0024 - output_2_loss: 0.0212 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0300 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0245 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 103/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0263 - output_1_loss: 0.0024 - output_2_loss: 0.0210 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0298 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0242 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 104/600\n",
      "8906/8906 [==============================] - 1s 72us/sample - loss: 0.0261 - output_1_loss: 0.0024 - output_2_loss: 0.0209 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0295 - val_output_1_loss: 0.0028 - val_output_2_loss: 0.0241 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 105/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0259 - output_1_loss: 0.0023 - output_2_loss: 0.0207 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0293 - val_output_1_loss: 0.0028 - val_output_2_loss: 0.0239 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 106/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0257 - output_1_loss: 0.0023 - output_2_loss: 0.0206 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0290 - val_output_1_loss: 0.0027 - val_output_2_loss: 0.0237 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 107/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0254 - output_1_loss: 0.0022 - output_2_loss: 0.0203 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0288 - val_output_1_loss: 0.0027 - val_output_2_loss: 0.0235 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 108/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0252 - output_1_loss: 0.0022 - output_2_loss: 0.0202 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0286 - val_output_1_loss: 0.0027 - val_output_2_loss: 0.0234 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 109/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0250 - output_1_loss: 0.0022 - output_2_loss: 0.0200 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0283 - val_output_1_loss: 0.0026 - val_output_2_loss: 0.0231 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 110/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0248 - output_1_loss: 0.0021 - output_2_loss: 0.0199 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0282 - val_output_1_loss: 0.0026 - val_output_2_loss: 0.0230 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 111/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0246 - output_1_loss: 0.0021 - output_2_loss: 0.0197 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0279 - val_output_1_loss: 0.0025 - val_output_2_loss: 0.0228 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 112/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0244 - output_1_loss: 0.0021 - output_2_loss: 0.0195 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0277 - val_output_1_loss: 0.0025 - val_output_2_loss: 0.0226 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 113/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0243 - output_1_loss: 0.0020 - output_2_loss: 0.0194 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0275 - val_output_1_loss: 0.0025 - val_output_2_loss: 0.0225 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 114/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0241 - output_1_loss: 0.0020 - output_2_loss: 0.0197 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0274 - val_output_1_loss: 0.0024 - val_output_2_loss: 0.0223 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 115/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0239 - output_1_loss: 0.0020 - output_2_loss: 0.0191 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0272 - val_output_1_loss: 0.0024 - val_output_2_loss: 0.0222 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 116/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0237 - output_1_loss: 0.0020 - output_2_loss: 0.0190 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0271 - val_output_1_loss: 0.0024 - val_output_2_loss: 0.0220 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 117/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0236 - output_1_loss: 0.0019 - output_2_loss: 0.0188 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0268 - val_output_1_loss: 0.0023 - val_output_2_loss: 0.0218 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 118/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0234 - output_1_loss: 0.0019 - output_2_loss: 0.0187 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0267 - val_output_1_loss: 0.0024 - val_output_2_loss: 0.0217 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 119/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0233 - output_1_loss: 0.0019 - output_2_loss: 0.0187 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0265 - val_output_1_loss: 0.0023 - val_output_2_loss: 0.0215 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 120/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0231 - output_1_loss: 0.0018 - output_2_loss: 0.0184 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0262 - val_output_1_loss: 0.0023 - val_output_2_loss: 0.0213 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 121/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0229 - output_1_loss: 0.0018 - output_2_loss: 0.0184 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0261 - val_output_1_loss: 0.0023 - val_output_2_loss: 0.0212 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 122/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0228 - output_1_loss: 0.0018 - output_2_loss: 0.0183 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0259 - val_output_1_loss: 0.0022 - val_output_2_loss: 0.0211 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 123/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0226 - output_1_loss: 0.0018 - output_2_loss: 0.0180 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0257 - val_output_1_loss: 0.0022 - val_output_2_loss: 0.0209 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 124/600\n",
      "8906/8906 [==============================] - 1s 82us/sample - loss: 0.0225 - output_1_loss: 0.0017 - output_2_loss: 0.0179 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0256 - val_output_1_loss: 0.0022 - val_output_2_loss: 0.0208 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0224 - output_1_loss: 0.0017 - output_2_loss: 0.0178 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0255 - val_output_1_loss: 0.0022 - val_output_2_loss: 0.0207 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 126/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0222 - output_1_loss: 0.0017 - output_2_loss: 0.0179 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0253 - val_output_1_loss: 0.0021 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 127/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0221 - output_1_loss: 0.0017 - output_2_loss: 0.0176 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0251 - val_output_1_loss: 0.0021 - val_output_2_loss: 0.0204 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 128/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0219 - output_1_loss: 0.0017 - output_2_loss: 0.0183 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0251 - val_output_1_loss: 0.0022 - val_output_2_loss: 0.0203 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 129/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0218 - output_1_loss: 0.0017 - output_2_loss: 0.0177 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0248 - val_output_1_loss: 0.0021 - val_output_2_loss: 0.0202 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 130/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0217 - output_1_loss: 0.0016 - output_2_loss: 0.0177 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0247 - val_output_1_loss: 0.0021 - val_output_2_loss: 0.0200 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 131/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0216 - output_1_loss: 0.0016 - output_2_loss: 0.0171 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0246 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0199 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 132/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0214 - output_1_loss: 0.0016 - output_2_loss: 0.0170 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0244 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0198 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 133/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0213 - output_1_loss: 0.0016 - output_2_loss: 0.0170 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0243 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0197 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 134/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0212 - output_1_loss: 0.0016 - output_2_loss: 0.0168 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0241 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0196 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 135/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0211 - output_1_loss: 0.0015 - output_2_loss: 0.0168 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0241 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0195 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 136/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0210 - output_1_loss: 0.0016 - output_2_loss: 0.0169 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0239 - val_output_1_loss: 0.0019 - val_output_2_loss: 0.0194 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 137/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0209 - output_1_loss: 0.0015 - output_2_loss: 0.0169 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0238 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0193 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 138/600\n",
      "8906/8906 [==============================] - 1s 82us/sample - loss: 0.0208 - output_1_loss: 0.0015 - output_2_loss: 0.0169 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0237 - val_output_1_loss: 0.0020 - val_output_2_loss: 0.0191 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 139/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0207 - output_1_loss: 0.0015 - output_2_loss: 0.0164 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0235 - val_output_1_loss: 0.0019 - val_output_2_loss: 0.0190 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 140/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0205 - output_1_loss: 0.0015 - output_2_loss: 0.0163 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0234 - val_output_1_loss: 0.0019 - val_output_2_loss: 0.0189 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 141/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0204 - output_1_loss: 0.0014 - output_2_loss: 0.0162 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0233 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0188 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 142/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0203 - output_1_loss: 0.0014 - output_2_loss: 0.0161 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0232 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0187 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 143/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0202 - output_1_loss: 0.0014 - output_2_loss: 0.0161 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0231 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0187 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 144/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0201 - output_1_loss: 0.0014 - output_2_loss: 0.0159 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0230 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0185 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 145/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0200 - output_1_loss: 0.0014 - output_2_loss: 0.0158 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0228 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0184 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 146/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0199 - output_1_loss: 0.0014 - output_2_loss: 0.0161 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0227 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0183 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 147/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0198 - output_1_loss: 0.0014 - output_2_loss: 0.0157 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0226 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0182 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 148/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0197 - output_1_loss: 0.0013 - output_2_loss: 0.0156 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0225 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0181 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 149/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0196 - output_1_loss: 0.0013 - output_2_loss: 0.0155 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0224 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0181 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0196 - output_1_loss: 0.0013 - output_2_loss: 0.0157 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0224 - val_output_1_loss: 0.0018 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 151/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0195 - output_1_loss: 0.0013 - output_2_loss: 0.0154 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0222 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0179 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 152/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0194 - output_1_loss: 0.0013 - output_2_loss: 0.0153 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0221 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0178 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 153/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0193 - output_1_loss: 0.0013 - output_2_loss: 0.0156 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0220 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0177 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 154/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0192 - output_1_loss: 0.0013 - output_2_loss: 0.0151 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0219 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0176 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 155/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0191 - output_1_loss: 0.0013 - output_2_loss: 0.0151 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0218 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0175 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 156/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0190 - output_1_loss: 0.0013 - output_2_loss: 0.0152 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0218 - val_output_1_loss: 0.0017 - val_output_2_loss: 0.0175 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 157/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0190 - output_1_loss: 0.0012 - output_2_loss: 0.0149 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0216 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0173 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 158/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0189 - output_1_loss: 0.0013 - output_2_loss: 0.0151 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0215 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0173 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 159/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0188 - output_1_loss: 0.0012 - output_2_loss: 0.0148 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0214 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0172 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 160/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0187 - output_1_loss: 0.0012 - output_2_loss: 0.0148 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0213 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0171 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 161/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0187 - output_1_loss: 0.0012 - output_2_loss: 0.0147 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0212 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0170 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 162/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0186 - output_1_loss: 0.0012 - output_2_loss: 0.0146 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0211 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0170 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 163/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0185 - output_1_loss: 0.0012 - output_2_loss: 0.0145 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0211 - val_output_1_loss: 0.0016 - val_output_2_loss: 0.0169 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 164/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0184 - output_1_loss: 0.0012 - output_2_loss: 0.0145 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0210 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0168 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 165/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0184 - output_1_loss: 0.0012 - output_2_loss: 0.0148 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0209 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0168 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 166/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0183 - output_1_loss: 0.0012 - output_2_loss: 0.0143 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0208 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0166 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 167/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0182 - output_1_loss: 0.0011 - output_2_loss: 0.0143 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0207 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0166 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 168/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0181 - output_1_loss: 0.0011 - output_2_loss: 0.0144 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0206 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 169/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0181 - output_1_loss: 0.0011 - output_2_loss: 0.0142 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0205 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0164 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 170/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0180 - output_1_loss: 0.0011 - output_2_loss: 0.0141 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0204 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0164 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 171/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0179 - output_1_loss: 0.0011 - output_2_loss: 0.0140 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0203 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0163 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 172/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0179 - output_1_loss: 0.0011 - output_2_loss: 0.0140 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0203 - val_output_1_loss: 0.0015 - val_output_2_loss: 0.0162 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 173/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0178 - output_1_loss: 0.0011 - output_2_loss: 0.0139 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0202 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0162 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 174/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0177 - output_1_loss: 0.0011 - output_2_loss: 0.0139 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0201 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0177 - output_1_loss: 0.0011 - output_2_loss: 0.0138 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0201 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 176/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0176 - output_1_loss: 0.0011 - output_2_loss: 0.0141 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0200 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 177/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0175 - output_1_loss: 0.0011 - output_2_loss: 0.0138 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0199 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 178/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0175 - output_1_loss: 0.0011 - output_2_loss: 0.0141 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0199 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 179/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0174 - output_1_loss: 0.0011 - output_2_loss: 0.0136 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0197 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0157 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 180/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0174 - output_1_loss: 0.0010 - output_2_loss: 0.0135 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0196 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0157 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 181/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0173 - output_1_loss: 0.0010 - output_2_loss: 0.0135 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0196 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0156 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 182/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0172 - output_1_loss: 0.0010 - output_2_loss: 0.0137 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0195 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 183/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0172 - output_1_loss: 0.0010 - output_2_loss: 0.0137 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0194 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 184/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0171 - output_1_loss: 0.0010 - output_2_loss: 0.0133 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0194 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0154 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 185/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0171 - output_1_loss: 0.0010 - output_2_loss: 0.0136 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0194 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 186/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0170 - output_1_loss: 0.0010 - output_2_loss: 0.0136 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0193 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 187/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0170 - output_1_loss: 0.0010 - output_2_loss: 0.0132 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0192 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 188/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0169 - output_1_loss: 9.8758e-04 - output_2_loss: 0.0131 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0191 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 189/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0168 - output_1_loss: 9.8500e-04 - output_2_loss: 0.0131 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0190 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 190/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0168 - output_1_loss: 9.8956e-04 - output_2_loss: 0.0134 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0190 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 191/600\n",
      "8906/8906 [==============================] - 1s 80us/sample - loss: 0.0167 - output_1_loss: 9.7424e-04 - output_2_loss: 0.0130 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0189 - val_output_1_loss: 0.0014 - val_output_2_loss: 0.0150 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 192/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0167 - output_1_loss: 9.6631e-04 - output_2_loss: 0.0129 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0188 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 193/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0166 - output_1_loss: 9.5596e-04 - output_2_loss: 0.0129 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0187 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 194/600\n",
      "8906/8906 [==============================] - 1s 80us/sample - loss: 0.0166 - output_1_loss: 9.5157e-04 - output_2_loss: 0.0128 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0187 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0148 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 195/600\n",
      "8906/8906 [==============================] - 1s 81us/sample - loss: 0.0165 - output_1_loss: 9.4744e-04 - output_2_loss: 0.0128 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0186 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0148 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 196/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0165 - output_1_loss: 9.4277e-04 - output_2_loss: 0.0127 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0186 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 197/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0164 - output_1_loss: 9.4784e-04 - output_2_loss: 0.0130 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0185 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 198/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0164 - output_1_loss: 9.3110e-04 - output_2_loss: 0.0127 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0185 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 199/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0163 - output_1_loss: 9.2052e-04 - output_2_loss: 0.0126 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0184 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 200/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0163 - output_1_loss: 9.1854e-04 - output_2_loss: 0.0126 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0183 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0145 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 201/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0162 - output_1_loss: 9.1545e-04 - output_2_loss: 0.0125 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0183 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0144 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 202/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0162 - output_1_loss: 9.0797e-04 - output_2_loss: 0.0125 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0182 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0144 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 203/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0161 - output_1_loss: 8.9844e-04 - output_2_loss: 0.0124 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0181 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0143 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 204/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0161 - output_1_loss: 8.9681e-04 - output_2_loss: 0.0124 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0181 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0143 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 205/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0160 - output_1_loss: 9.0595e-04 - output_2_loss: 0.0127 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0181 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0143 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 206/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0160 - output_1_loss: 9.0020e-04 - output_2_loss: 0.0123 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0180 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0142 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 207/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0159 - output_1_loss: 8.8617e-04 - output_2_loss: 0.0123 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0180 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0142 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 208/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0159 - output_1_loss: 8.8338e-04 - output_2_loss: 0.0123 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0180 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.0141 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 209/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0158 - output_1_loss: 8.7170e-04 - output_2_loss: 0.0122 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0178 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0140 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 210/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0158 - output_1_loss: 8.9179e-04 - output_2_loss: 0.0128 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0178 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0140 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 211/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0158 - output_1_loss: 8.8625e-04 - output_2_loss: 0.0129 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0178 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0140 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 212/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0157 - output_1_loss: 8.5761e-04 - output_2_loss: 0.0121 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0176 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0139 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 213/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0157 - output_1_loss: 8.6205e-04 - output_2_loss: 0.0123 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0177 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0138 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 214/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0156 - output_1_loss: 8.8135e-04 - output_2_loss: 0.0123 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0176 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0138 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 215/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0156 - output_1_loss: 8.4382e-04 - output_2_loss: 0.0120 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0175 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0138 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 216/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0155 - output_1_loss: 8.3866e-04 - output_2_loss: 0.0119 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0175 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0137 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 217/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0155 - output_1_loss: 8.5620e-04 - output_2_loss: 0.0125 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0175 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0137 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 218/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0155 - output_1_loss: 8.2883e-04 - output_2_loss: 0.0119 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0173 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0136 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 219/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0154 - output_1_loss: 8.2680e-04 - output_2_loss: 0.0118 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0174 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0136 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 220/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0154 - output_1_loss: 8.2341e-04 - output_2_loss: 0.0118 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0172 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0135 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 221/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0153 - output_1_loss: 8.1462e-04 - output_2_loss: 0.0117 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0172 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0135 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 222/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0153 - output_1_loss: 8.0613e-04 - output_2_loss: 0.0117 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0171 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0134 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 223/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0152 - output_1_loss: 8.1147e-04 - output_2_loss: 0.0119 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0172 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0134 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 224/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0152 - output_1_loss: 8.0567e-04 - output_2_loss: 0.0117 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0171 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0134 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 225/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0152 - output_1_loss: 8.1491e-04 - output_2_loss: 0.0120 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0171 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0134 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 226/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0151 - output_1_loss: 8.0627e-04 - output_2_loss: 0.0119 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0170 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0133 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 227/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0151 - output_1_loss: 7.9605e-04 - output_2_loss: 0.0119 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0170 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0134 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 228/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0151 - output_1_loss: 7.8123e-04 - output_2_loss: 0.0115 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0169 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0132 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 229/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0150 - output_1_loss: 7.8897e-04 - output_2_loss: 0.0118 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0169 - val_output_1_loss: 0.0012 - val_output_2_loss: 0.0132 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 230/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0150 - output_1_loss: 7.7948e-04 - output_2_loss: 0.0114 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0168 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0132 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 231/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0149 - output_1_loss: 7.7741e-04 - output_2_loss: 0.0115 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0169 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.0132 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 232/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0149 - output_1_loss: 7.7086e-04 - output_2_loss: 0.0114 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0167 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0131 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 233/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0149 - output_1_loss: 7.6052e-04 - output_2_loss: 0.0113 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0167 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0130 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 234/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0148 - output_1_loss: 7.6033e-04 - output_2_loss: 0.0113 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0166 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0130 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 235/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0148 - output_1_loss: 7.5590e-04 - output_2_loss: 0.0113 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0166 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0130 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 236/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0147 - output_1_loss: 7.5211e-04 - output_2_loss: 0.0112 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0166 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0129 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 237/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0147 - output_1_loss: 7.5415e-04 - output_2_loss: 0.0115 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0166 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0130 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 238/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0147 - output_1_loss: 7.4440e-04 - output_2_loss: 0.0112 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0165 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0129 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 239/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0146 - output_1_loss: 7.4111e-04 - output_2_loss: 0.0111 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0164 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0128 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 240/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0146 - output_1_loss: 7.3992e-04 - output_2_loss: 0.0114 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0164 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0128 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 241/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0146 - output_1_loss: 7.3086e-04 - output_2_loss: 0.0111 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0164 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0128 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 242/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0145 - output_1_loss: 7.2692e-04 - output_2_loss: 0.0110 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0163 - val_output_1_loss: 9.9614e-04 - val_output_2_loss: 0.0127 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 243/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0145 - output_1_loss: 7.2340e-04 - output_2_loss: 0.0110 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0163 - val_output_1_loss: 9.9035e-04 - val_output_2_loss: 0.0127 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 244/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0145 - output_1_loss: 7.1881e-04 - output_2_loss: 0.0110 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0163 - val_output_1_loss: 0.0010 - val_output_2_loss: 0.0127 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 245/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0144 - output_1_loss: 7.1619e-04 - output_2_loss: 0.0110 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0162 - val_output_1_loss: 9.8212e-04 - val_output_2_loss: 0.0126 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 246/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0144 - output_1_loss: 7.1375e-04 - output_2_loss: 0.0110 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0162 - val_output_1_loss: 9.8230e-04 - val_output_2_loss: 0.0126 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 247/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0144 - output_1_loss: 7.1267e-04 - output_2_loss: 0.0109 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0162 - val_output_1_loss: 9.9935e-04 - val_output_2_loss: 0.0126 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 248/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0143 - output_1_loss: 7.0774e-04 - output_2_loss: 0.0109 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0161 - val_output_1_loss: 9.8086e-04 - val_output_2_loss: 0.0125 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 249/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0143 - output_1_loss: 6.9845e-04 - output_2_loss: 0.0108 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0161 - val_output_1_loss: 9.7703e-04 - val_output_2_loss: 0.0125 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 250/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0143 - output_1_loss: 7.1948e-04 - output_2_loss: 0.0111 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0160 - val_output_1_loss: 9.6952e-04 - val_output_2_loss: 0.0125 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 251/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0142 - output_1_loss: 7.0832e-04 - output_2_loss: 0.0108 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0160 - val_output_1_loss: 9.5213e-04 - val_output_2_loss: 0.0124 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 252/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0142 - output_1_loss: 7.4953e-04 - output_2_loss: 0.0113 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0160 - val_output_1_loss: 9.6341e-04 - val_output_2_loss: 0.0125 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 253/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0142 - output_1_loss: 6.9084e-04 - output_2_loss: 0.0107 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0159 - val_output_1_loss: 9.5859e-04 - val_output_2_loss: 0.0124 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 254/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0141 - output_1_loss: 6.8708e-04 - output_2_loss: 0.0107 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0159 - val_output_1_loss: 9.5179e-04 - val_output_2_loss: 0.0123 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 255/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0141 - output_1_loss: 6.8024e-04 - output_2_loss: 0.0107 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0158 - val_output_1_loss: 9.3982e-04 - val_output_2_loss: 0.0123 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 256/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0141 - output_1_loss: 6.8173e-04 - output_2_loss: 0.0106 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0158 - val_output_1_loss: 9.3710e-04 - val_output_2_loss: 0.0123 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 257/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0140 - output_1_loss: 6.7672e-04 - output_2_loss: 0.0106 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0158 - val_output_1_loss: 9.3258e-04 - val_output_2_loss: 0.0123 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 258/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0140 - output_1_loss: 6.7182e-04 - output_2_loss: 0.0106 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0157 - val_output_1_loss: 9.2897e-04 - val_output_2_loss: 0.0122 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 259/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0140 - output_1_loss: 6.7473e-04 - output_2_loss: 0.0105 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0157 - val_output_1_loss: 9.5362e-04 - val_output_2_loss: 0.0122 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 260/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0139 - output_1_loss: 6.7644e-04 - output_2_loss: 0.0107 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0157 - val_output_1_loss: 9.3598e-04 - val_output_2_loss: 0.0122 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 261/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0139 - output_1_loss: 6.6545e-04 - output_2_loss: 0.0105 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0157 - val_output_1_loss: 9.3600e-04 - val_output_2_loss: 0.0122 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 262/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0139 - output_1_loss: 6.6468e-04 - output_2_loss: 0.0105 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0156 - val_output_1_loss: 9.1402e-04 - val_output_2_loss: 0.0121 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 263/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0138 - output_1_loss: 6.5933e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0156 - val_output_1_loss: 9.0643e-04 - val_output_2_loss: 0.0121 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 264/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0138 - output_1_loss: 6.5158e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0156 - val_output_1_loss: 9.1885e-04 - val_output_2_loss: 0.0120 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 265/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0138 - output_1_loss: 6.5037e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0155 - val_output_1_loss: 9.0501e-04 - val_output_2_loss: 0.0120 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 266/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0137 - output_1_loss: 6.4659e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0155 - val_output_1_loss: 9.1977e-04 - val_output_2_loss: 0.0120 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 267/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0137 - output_1_loss: 6.4787e-04 - output_2_loss: 0.0103 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0155 - val_output_1_loss: 8.9314e-04 - val_output_2_loss: 0.0120 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 268/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0137 - output_1_loss: 6.4430e-04 - output_2_loss: 0.0103 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0154 - val_output_1_loss: 8.9767e-04 - val_output_2_loss: 0.0119 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 269/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0137 - output_1_loss: 6.4148e-04 - output_2_loss: 0.0103 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0154 - val_output_1_loss: 8.8689e-04 - val_output_2_loss: 0.0119 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 270/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0136 - output_1_loss: 6.3885e-04 - output_2_loss: 0.0102 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0154 - val_output_1_loss: 8.9324e-04 - val_output_2_loss: 0.0119 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 271/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0136 - output_1_loss: 6.3751e-04 - output_2_loss: 0.0102 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0153 - val_output_1_loss: 8.7831e-04 - val_output_2_loss: 0.0118 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 272/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0136 - output_1_loss: 6.3452e-04 - output_2_loss: 0.0102 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0153 - val_output_1_loss: 8.7858e-04 - val_output_2_loss: 0.0118 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 273/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0135 - output_1_loss: 6.4508e-04 - output_2_loss: 0.0105 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0153 - val_output_1_loss: 8.7298e-04 - val_output_2_loss: 0.0118 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 274/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0135 - output_1_loss: 6.2792e-04 - output_2_loss: 0.0102 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0152 - val_output_1_loss: 8.8376e-04 - val_output_2_loss: 0.0118 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 275/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0135 - output_1_loss: 6.2436e-04 - output_2_loss: 0.0101 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0152 - val_output_1_loss: 8.7527e-04 - val_output_2_loss: 0.0118 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 276/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0135 - output_1_loss: 6.2884e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0152 - val_output_1_loss: 8.8905e-04 - val_output_2_loss: 0.0117 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 277/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0134 - output_1_loss: 6.2970e-04 - output_2_loss: 0.0104 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0151 - val_output_1_loss: 8.7365e-04 - val_output_2_loss: 0.0117 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 278/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0134 - output_1_loss: 6.2118e-04 - output_2_loss: 0.0100 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0151 - val_output_1_loss: 8.5686e-04 - val_output_2_loss: 0.0116 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 279/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0134 - output_1_loss: 6.1215e-04 - output_2_loss: 0.0100 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0151 - val_output_1_loss: 8.5698e-04 - val_output_2_loss: 0.0116 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 280/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0133 - output_1_loss: 6.1511e-04 - output_2_loss: 0.0100 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0151 - val_output_1_loss: 8.8718e-04 - val_output_2_loss: 0.0116 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 281/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0133 - output_1_loss: 6.0883e-04 - output_2_loss: 0.0100 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0150 - val_output_1_loss: 8.6232e-04 - val_output_2_loss: 0.0116 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 282/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0133 - output_1_loss: 6.1708e-04 - output_2_loss: 0.0102 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0152 - val_output_1_loss: 8.7873e-04 - val_output_2_loss: 0.0117 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 283/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0133 - output_1_loss: 6.0179e-04 - output_2_loss: 0.0099 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0150 - val_output_1_loss: 8.4031e-04 - val_output_2_loss: 0.0115 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 284/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0132 - output_1_loss: 6.0404e-04 - output_2_loss: 0.0099 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0150 - val_output_1_loss: 8.7212e-04 - val_output_2_loss: 0.0115 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 285/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0132 - output_1_loss: 6.0407e-04 - output_2_loss: 0.0099 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0149 - val_output_1_loss: 8.3340e-04 - val_output_2_loss: 0.0115 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 286/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0132 - output_1_loss: 5.9637e-04 - output_2_loss: 0.0098 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0149 - val_output_1_loss: 8.3365e-04 - val_output_2_loss: 0.0114 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 287/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0131 - output_1_loss: 5.9644e-04 - output_2_loss: 0.0098 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0149 - val_output_1_loss: 8.5539e-04 - val_output_2_loss: 0.0114 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 288/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0131 - output_1_loss: 5.8925e-04 - output_2_loss: 0.0098 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0148 - val_output_1_loss: 8.3771e-04 - val_output_2_loss: 0.0114 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 289/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0131 - output_1_loss: 5.8622e-04 - output_2_loss: 0.0098 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0148 - val_output_1_loss: 8.1964e-04 - val_output_2_loss: 0.0114 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 290/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0131 - output_1_loss: 6.0128e-04 - output_2_loss: 0.0100 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0148 - val_output_1_loss: 8.5752e-04 - val_output_2_loss: 0.0114 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 291/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0131 - output_1_loss: 5.8986e-04 - output_2_loss: 0.0097 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0147 - val_output_1_loss: 8.2456e-04 - val_output_2_loss: 0.0113 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 292/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0130 - output_1_loss: 6.0348e-04 - output_2_loss: 0.0099 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0147 - val_output_1_loss: 8.1075e-04 - val_output_2_loss: 0.0113 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 293/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0130 - output_1_loss: 5.7945e-04 - output_2_loss: 0.0097 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0147 - val_output_1_loss: 8.0967e-04 - val_output_2_loss: 0.0113 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 294/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0130 - output_1_loss: 5.8277e-04 - output_2_loss: 0.0096 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0146 - val_output_1_loss: 8.0510e-04 - val_output_2_loss: 0.0112 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 295/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0129 - output_1_loss: 5.7583e-04 - output_2_loss: 0.0096 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0146 - val_output_1_loss: 8.1906e-04 - val_output_2_loss: 0.0112 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 296/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0129 - output_1_loss: 5.7113e-04 - output_2_loss: 0.0096 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0146 - val_output_1_loss: 8.1741e-04 - val_output_2_loss: 0.0112 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 297/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0129 - output_1_loss: 5.7408e-04 - output_2_loss: 0.0097 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0146 - val_output_1_loss: 7.9790e-04 - val_output_2_loss: 0.0112 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 298/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0129 - output_1_loss: 5.8244e-04 - output_2_loss: 0.0099 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0146 - val_output_1_loss: 8.6522e-04 - val_output_2_loss: 0.0112 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 299/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0128 - output_1_loss: 5.7439e-04 - output_2_loss: 0.0095 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0145 - val_output_1_loss: 7.9217e-04 - val_output_2_loss: 0.0111 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 300/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0128 - output_1_loss: 5.6183e-04 - output_2_loss: 0.0095 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0145 - val_output_1_loss: 8.0705e-04 - val_output_2_loss: 0.0111 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 301/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0128 - output_1_loss: 5.6761e-04 - output_2_loss: 0.0096 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0145 - val_output_1_loss: 7.9783e-04 - val_output_2_loss: 0.0111 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 302/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0128 - output_1_loss: 5.6427e-04 - output_2_loss: 0.0095 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0144 - val_output_1_loss: 7.8710e-04 - val_output_2_loss: 0.0111 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 303/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0127 - output_1_loss: 5.5939e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0144 - val_output_1_loss: 7.9519e-04 - val_output_2_loss: 0.0110 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 304/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0127 - output_1_loss: 5.5352e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0144 - val_output_1_loss: 7.8007e-04 - val_output_2_loss: 0.0110 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 305/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0127 - output_1_loss: 5.5331e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0144 - val_output_1_loss: 7.7828e-04 - val_output_2_loss: 0.0110 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 306/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0127 - output_1_loss: 5.5155e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0143 - val_output_1_loss: 7.7872e-04 - val_output_2_loss: 0.0110 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 307/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0126 - output_1_loss: 5.4858e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0143 - val_output_1_loss: 7.6592e-04 - val_output_2_loss: 0.0110 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 308/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0126 - output_1_loss: 5.4834e-04 - output_2_loss: 0.0093 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0143 - val_output_1_loss: 7.6788e-04 - val_output_2_loss: 0.0109 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 309/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0126 - output_1_loss: 5.4662e-04 - output_2_loss: 0.0093 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0143 - val_output_1_loss: 7.8428e-04 - val_output_2_loss: 0.0109 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 310/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0126 - output_1_loss: 5.4183e-04 - output_2_loss: 0.0093 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0143 - val_output_1_loss: 7.6341e-04 - val_output_2_loss: 0.0109 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 311/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0125 - output_1_loss: 5.4033e-04 - output_2_loss: 0.0093 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0142 - val_output_1_loss: 7.7030e-04 - val_output_2_loss: 0.0109 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 312/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0125 - output_1_loss: 5.3980e-04 - output_2_loss: 0.0092 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0142 - val_output_1_loss: 7.6274e-04 - val_output_2_loss: 0.0109 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 313/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0125 - output_1_loss: 5.3670e-04 - output_2_loss: 0.0092 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0142 - val_output_1_loss: 7.5920e-04 - val_output_2_loss: 0.0108 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 314/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0125 - output_1_loss: 5.3614e-04 - output_2_loss: 0.0092 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0142 - val_output_1_loss: 7.5644e-04 - val_output_2_loss: 0.0108 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 315/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0124 - output_1_loss: 5.4249e-04 - output_2_loss: 0.0094 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0142 - val_output_1_loss: 7.7671e-04 - val_output_2_loss: 0.0108 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 316/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0124 - output_1_loss: 5.3399e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0141 - val_output_1_loss: 7.5241e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 317/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0124 - output_1_loss: 5.3169e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0141 - val_output_1_loss: 7.4220e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 318/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0124 - output_1_loss: 5.2705e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0141 - val_output_1_loss: 7.5080e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 319/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0123 - output_1_loss: 5.2534e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0140 - val_output_1_loss: 7.4337e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 320/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0123 - output_1_loss: 5.2042e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0140 - val_output_1_loss: 7.3695e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 321/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0123 - output_1_loss: 5.2341e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0140 - val_output_1_loss: 7.3705e-04 - val_output_2_loss: 0.0107 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 322/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0123 - output_1_loss: 5.2151e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0140 - val_output_1_loss: 7.3759e-04 - val_output_2_loss: 0.0106 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 323/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0123 - output_1_loss: 5.2224e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0139 - val_output_1_loss: 7.2522e-04 - val_output_2_loss: 0.0106 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 324/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0122 - output_1_loss: 5.1781e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0139 - val_output_1_loss: 7.2983e-04 - val_output_2_loss: 0.0106 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 325/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0122 - output_1_loss: 5.1283e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0139 - val_output_1_loss: 7.4328e-04 - val_output_2_loss: 0.0106 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 326/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0122 - output_1_loss: 5.1680e-04 - output_2_loss: 0.0089 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0139 - val_output_1_loss: 7.3038e-04 - val_output_2_loss: 0.0105 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 327/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0122 - output_1_loss: 5.1195e-04 - output_2_loss: 0.0089 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0138 - val_output_1_loss: 7.2328e-04 - val_output_2_loss: 0.0105 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 328/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0121 - output_1_loss: 5.0988e-04 - output_2_loss: 0.0089 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0138 - val_output_1_loss: 7.1579e-04 - val_output_2_loss: 0.0105 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 329/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0121 - output_1_loss: 5.1195e-04 - output_2_loss: 0.0089 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0138 - val_output_1_loss: 7.1161e-04 - val_output_2_loss: 0.0105 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 330/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0121 - output_1_loss: 5.0664e-04 - output_2_loss: 0.0089 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0138 - val_output_1_loss: 7.1466e-04 - val_output_2_loss: 0.0105 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 331/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0121 - output_1_loss: 5.0292e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0138 - val_output_1_loss: 7.1628e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 332/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0120 - output_1_loss: 4.9968e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 7.1355e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 333/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0120 - output_1_loss: 5.0036e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 7.0143e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 334/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0120 - output_1_loss: 4.9706e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 7.0443e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 335/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0120 - output_1_loss: 5.0216e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 7.1142e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 336/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0120 - output_1_loss: 5.0520e-04 - output_2_loss: 0.0088 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 7.1270e-04 - val_output_2_loss: 0.0104 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 337/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0119 - output_1_loss: 4.9928e-04 - output_2_loss: 0.0087 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0136 - val_output_1_loss: 7.0157e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 338/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0119 - output_1_loss: 4.9339e-04 - output_2_loss: 0.0087 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0136 - val_output_1_loss: 7.1826e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 339/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0119 - output_1_loss: 5.0378e-04 - output_2_loss: 0.0090 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0137 - val_output_1_loss: 8.2186e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 340/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0119 - output_1_loss: 5.0012e-04 - output_2_loss: 0.0087 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0136 - val_output_1_loss: 7.0429e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 341/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0119 - output_1_loss: 5.0489e-04 - output_2_loss: 0.0091 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0136 - val_output_1_loss: 7.3539e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 342/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0118 - output_1_loss: 4.9621e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0135 - val_output_1_loss: 6.9064e-04 - val_output_2_loss: 0.0102 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 343/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0118 - output_1_loss: 4.8812e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0135 - val_output_1_loss: 6.8607e-04 - val_output_2_loss: 0.0102 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 344/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0118 - output_1_loss: 4.8950e-04 - output_2_loss: 0.0087 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0136 - val_output_1_loss: 7.0346e-04 - val_output_2_loss: 0.0103 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 345/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0118 - output_1_loss: 4.8532e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0135 - val_output_1_loss: 6.7948e-04 - val_output_2_loss: 0.0102 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 346/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0117 - output_1_loss: 4.8135e-04 - output_2_loss: 0.0085 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0134 - val_output_1_loss: 6.8412e-04 - val_output_2_loss: 0.0102 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 347/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0117 - output_1_loss: 4.8438e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0134 - val_output_1_loss: 6.7153e-04 - val_output_2_loss: 0.0101 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 348/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0117 - output_1_loss: 4.8256e-04 - output_2_loss: 0.0087 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0135 - val_output_1_loss: 6.9693e-04 - val_output_2_loss: 0.0102 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 349/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0117 - output_1_loss: 4.7542e-04 - output_2_loss: 0.0085 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.6738e-04 - val_output_2_loss: 0.0101 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 350/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0117 - output_1_loss: 4.7399e-04 - output_2_loss: 0.0085 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0134 - val_output_1_loss: 6.6990e-04 - val_output_2_loss: 0.0101 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 351/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0116 - output_1_loss: 4.7639e-04 - output_2_loss: 0.0085 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.7470e-04 - val_output_2_loss: 0.0101 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 352/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0116 - output_1_loss: 4.7408e-04 - output_2_loss: 0.0084 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.7691e-04 - val_output_2_loss: 0.0101 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 353/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0116 - output_1_loss: 4.7269e-04 - output_2_loss: 0.0084 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.5766e-04 - val_output_2_loss: 0.0100 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 354/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0116 - output_1_loss: 4.7532e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.6581e-04 - val_output_2_loss: 0.0100 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 355/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0116 - output_1_loss: 4.7529e-04 - output_2_loss: 0.0084 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0133 - val_output_1_loss: 6.6336e-04 - val_output_2_loss: 0.0100 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 356/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0115 - output_1_loss: 4.6516e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0132 - val_output_1_loss: 6.5357e-04 - val_output_2_loss: 0.0100 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 357/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0115 - output_1_loss: 4.6223e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0132 - val_output_1_loss: 6.6142e-04 - val_output_2_loss: 0.0100 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 358/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0115 - output_1_loss: 4.6230e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0132 - val_output_1_loss: 6.5746e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 359/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0115 - output_1_loss: 4.6140e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0132 - val_output_1_loss: 6.5144e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 360/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0115 - output_1_loss: 4.6370e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0132 - val_output_1_loss: 6.6596e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 361/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0114 - output_1_loss: 4.5752e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0131 - val_output_1_loss: 6.3654e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 362/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0114 - output_1_loss: 4.6087e-04 - output_2_loss: 0.0085 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0131 - val_output_1_loss: 6.3954e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 363/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0114 - output_1_loss: 4.5642e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0131 - val_output_1_loss: 6.5041e-04 - val_output_2_loss: 0.0099 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 364/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0114 - output_1_loss: 4.5249e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0131 - val_output_1_loss: 6.3770e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 365/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0114 - output_1_loss: 4.5392e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0131 - val_output_1_loss: 6.7513e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 366/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0113 - output_1_loss: 4.5673e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 6.4748e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 367/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0113 - output_1_loss: 4.5130e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 6.3264e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 368/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0113 - output_1_loss: 4.5080e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 6.3817e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 369/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0113 - output_1_loss: 4.4788e-04 - output_2_loss: 0.0081 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 6.4560e-04 - val_output_2_loss: 0.0098 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 370/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0113 - output_1_loss: 4.5621e-04 - output_2_loss: 0.0084 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 6.3177e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 371/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0113 - output_1_loss: 4.4654e-04 - output_2_loss: 0.0081 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0129 - val_output_1_loss: 6.3895e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 372/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0112 - output_1_loss: 4.4610e-04 - output_2_loss: 0.0081 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0129 - val_output_1_loss: 6.2480e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 373/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0112 - output_1_loss: 4.5775e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0129 - val_output_1_loss: 6.4884e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 374/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0112 - output_1_loss: 4.5074e-04 - output_2_loss: 0.0083 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0129 - val_output_1_loss: 6.2488e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 375/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0112 - output_1_loss: 4.4770e-04 - output_2_loss: 0.0080 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0129 - val_output_1_loss: 6.5356e-04 - val_output_2_loss: 0.0096 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 376/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0112 - output_1_loss: 4.4059e-04 - output_2_loss: 0.0080 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0128 - val_output_1_loss: 6.1799e-04 - val_output_2_loss: 0.0096 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 377/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0111 - output_1_loss: 4.4005e-04 - output_2_loss: 0.0080 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0128 - val_output_1_loss: 6.0995e-04 - val_output_2_loss: 0.0096 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 378/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0111 - output_1_loss: 4.7875e-04 - output_2_loss: 0.0086 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0130 - val_output_1_loss: 7.0392e-04 - val_output_2_loss: 0.0097 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 379/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0111 - output_1_loss: 4.5260e-04 - output_2_loss: 0.0080 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0128 - val_output_1_loss: 6.0631e-04 - val_output_2_loss: 0.0096 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 380/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0111 - output_1_loss: 4.3521e-04 - output_2_loss: 0.0079 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0128 - val_output_1_loss: 6.0578e-04 - val_output_2_loss: 0.0096 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 381/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0111 - output_1_loss: 4.3246e-04 - output_2_loss: 0.0079 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0261e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 382/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0110 - output_1_loss: 4.2956e-04 - output_2_loss: 0.0079 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0647e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 383/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0110 - output_1_loss: 4.2943e-04 - output_2_loss: 0.0079 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0420e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 384/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0110 - output_1_loss: 4.2802e-04 - output_2_loss: 0.0079 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0547e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 385/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0110 - output_1_loss: 4.3834e-04 - output_2_loss: 0.0081 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0561e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 386/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0110 - output_1_loss: 4.3935e-04 - output_2_loss: 0.0080 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0128 - val_output_1_loss: 6.7209e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 387/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0110 - output_1_loss: 4.3742e-04 - output_2_loss: 0.0078 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.0063e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 388/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0109 - output_1_loss: 4.2806e-04 - output_2_loss: 0.0078 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0126 - val_output_1_loss: 5.9643e-04 - val_output_2_loss: 0.0094 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 389/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0109 - output_1_loss: 4.2144e-04 - output_2_loss: 0.0078 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0126 - val_output_1_loss: 6.0364e-04 - val_output_2_loss: 0.0094 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 390/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0109 - output_1_loss: 4.2409e-04 - output_2_loss: 0.0078 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0126 - val_output_1_loss: 5.9677e-04 - val_output_2_loss: 0.0094 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 391/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0109 - output_1_loss: 4.3387e-04 - output_2_loss: 0.0082 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0127 - val_output_1_loss: 6.1105e-04 - val_output_2_loss: 0.0095 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 392/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0109 - output_1_loss: 4.2042e-04 - output_2_loss: 0.0078 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0126 - val_output_1_loss: 5.9668e-04 - val_output_2_loss: 0.0094 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 393/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0108 - output_1_loss: 4.1756e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 5.8216e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 394/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0108 - output_1_loss: 4.1742e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 5.9248e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 395/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0108 - output_1_loss: 4.1684e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 6.0015e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 396/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0108 - output_1_loss: 4.2058e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 5.9108e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 397/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0108 - output_1_loss: 4.1334e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 5.8392e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 398/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0108 - output_1_loss: 4.1634e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0125 - val_output_1_loss: 5.9564e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 399/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0107 - output_1_loss: 4.1378e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.8737e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 400/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0107 - output_1_loss: 4.1547e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.7780e-04 - val_output_2_loss: 0.0093 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 401/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0107 - output_1_loss: 4.1310e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 6.0051e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 402/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0107 - output_1_loss: 4.1269e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.7511e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 403/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0107 - output_1_loss: 4.1548e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.7532e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 404/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0107 - output_1_loss: 4.0728e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.7166e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 405/600\n",
      "8906/8906 [==============================] - 1s 81us/sample - loss: 0.0106 - output_1_loss: 4.0688e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.7193e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 406/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0106 - output_1_loss: 4.0295e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0124 - val_output_1_loss: 5.8152e-04 - val_output_2_loss: 0.0092 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 407/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0106 - output_1_loss: 4.0542e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0123 - val_output_1_loss: 5.6600e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 408/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0106 - output_1_loss: 4.0163e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0123 - val_output_1_loss: 5.6012e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 409/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0106 - output_1_loss: 4.0057e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0123 - val_output_1_loss: 5.6559e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 410/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0106 - output_1_loss: 4.0345e-04 - output_2_loss: 0.0075 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.6638e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 411/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0105 - output_1_loss: 3.9791e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.6152e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 412/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0105 - output_1_loss: 3.9666e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.5410e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 413/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0105 - output_1_loss: 3.9657e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.5324e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 414/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0105 - output_1_loss: 3.9561e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.6789e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 415/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0105 - output_1_loss: 3.9739e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.6984e-04 - val_output_2_loss: 0.0091 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 416/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0105 - output_1_loss: 4.0146e-04 - output_2_loss: 0.0076 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0122 - val_output_1_loss: 5.5294e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 417/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0105 - output_1_loss: 4.0281e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.6673e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 418/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0104 - output_1_loss: 3.9444e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.5298e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 419/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0104 - output_1_loss: 3.9244e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.5277e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 420/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0104 - output_1_loss: 3.9295e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.4997e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 421/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0104 - output_1_loss: 3.9196e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.4944e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 422/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0104 - output_1_loss: 4.0017e-04 - output_2_loss: 0.0077 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0121 - val_output_1_loss: 5.8121e-04 - val_output_2_loss: 0.0090 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 423/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0103 - output_1_loss: 3.9085e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.3605e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 424/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0103 - output_1_loss: 3.8392e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.5251e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 425/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0103 - output_1_loss: 3.8577e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.4711e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 426/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0103 - output_1_loss: 3.8569e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.3951e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 427/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0103 - output_1_loss: 3.8330e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.5096e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 428/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0103 - output_1_loss: 3.8851e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.4055e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 429/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0102 - output_1_loss: 3.9013e-04 - output_2_loss: 0.0074 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.4876e-04 - val_output_2_loss: 0.0089 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 430/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0102 - output_1_loss: 3.9295e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0120 - val_output_1_loss: 5.3725e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 431/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0102 - output_1_loss: 3.8272e-04 - output_2_loss: 0.0071 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.4021e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 432/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0102 - output_1_loss: 3.7773e-04 - output_2_loss: 0.0071 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.3685e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 433/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0102 - output_1_loss: 3.7792e-04 - output_2_loss: 0.0071 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.3630e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 434/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0102 - output_1_loss: 3.7993e-04 - output_2_loss: 0.0071 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.2224e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 435/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0101 - output_1_loss: 3.7320e-04 - output_2_loss: 0.0071 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.3408e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 436/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0101 - output_1_loss: 3.8192e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.3274e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 437/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0101 - output_1_loss: 3.7700e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.2320e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 438/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0101 - output_1_loss: 3.7362e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.1534e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 439/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0101 - output_1_loss: 3.7505e-04 - output_2_loss: 0.0073 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0119 - val_output_1_loss: 5.2809e-04 - val_output_2_loss: 0.0088 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 440/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0101 - output_1_loss: 3.7428e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.2689e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 441/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0101 - output_1_loss: 3.7371e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.1950e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 442/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0100 - output_1_loss: 3.7360e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.1896e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 443/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0100 - output_1_loss: 3.7004e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.1518e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 444/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0100 - output_1_loss: 3.6767e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0118 - val_output_1_loss: 5.3644e-04 - val_output_2_loss: 0.0087 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 445/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0100 - output_1_loss: 3.6555e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.0899e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 446/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0100 - output_1_loss: 3.8726e-04 - output_2_loss: 0.0072 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.1497e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 447/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0100 - output_1_loss: 3.7021e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.0666e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 448/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0099 - output_1_loss: 3.6450e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.1050e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 449/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0099 - output_1_loss: 3.6611e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.1226e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 450/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0099 - output_1_loss: 3.6516e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.0356e-04 - val_output_2_loss: 0.0086 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 451/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0099 - output_1_loss: 3.6218e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0117 - val_output_1_loss: 5.2253e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 452/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0099 - output_1_loss: 3.6360e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.1246e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 453/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0099 - output_1_loss: 3.6076e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 4.9803e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 454/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0099 - output_1_loss: 3.6234e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.3427e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 455/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0098 - output_1_loss: 3.6959e-04 - output_2_loss: 0.0070 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.1109e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 456/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0098 - output_1_loss: 3.6389e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.1477e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 457/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0098 - output_1_loss: 3.6082e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.1697e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 458/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0098 - output_1_loss: 3.5642e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 4.9548e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 459/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0098 - output_1_loss: 3.5617e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 5.1775e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 460/600\n",
      "8906/8906 [==============================] - 1s 80us/sample - loss: 0.0098 - output_1_loss: 3.6731e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0116 - val_output_1_loss: 5.9242e-04 - val_output_2_loss: 0.0085 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 461/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0098 - output_1_loss: 3.6249e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 4.9338e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 462/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0097 - output_1_loss: 3.6584e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 5.3003e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 463/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0097 - output_1_loss: 3.5776e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0114 - val_output_1_loss: 4.9337e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 464/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0097 - output_1_loss: 3.5139e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 5.0790e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 465/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0097 - output_1_loss: 3.6266e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 5.1414e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 466/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0097 - output_1_loss: 3.5664e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0114 - val_output_1_loss: 5.0141e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 467/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0097 - output_1_loss: 3.5756e-04 - output_2_loss: 0.0069 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 4.9482e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 468/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0097 - output_1_loss: 3.5065e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0114 - val_output_1_loss: 4.9172e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 469/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0096 - output_1_loss: 3.5039e-04 - output_2_loss: 0.0068 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0115 - val_output_1_loss: 4.9283e-04 - val_output_2_loss: 0.0084 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 470/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0096 - output_1_loss: 3.4761e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0114 - val_output_1_loss: 4.9934e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 471/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0096 - output_1_loss: 3.4795e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.8468e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 472/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0096 - output_1_loss: 3.4477e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.8711e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 473/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0096 - output_1_loss: 3.4527e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.8533e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 474/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0095 - output_1_loss: 3.4625e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 5.1066e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 475/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.4640e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.7591e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 476/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.4452e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.9141e-04 - val_output_2_loss: 0.0083 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 477/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.4637e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 4.7250e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 478/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.3938e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.7470e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 479/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.4054e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.8667e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 480/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0095 - output_1_loss: 3.5468e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 5.0348e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 481/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0095 - output_1_loss: 3.4472e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.7110e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 482/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0094 - output_1_loss: 3.4084e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.7996e-04 - val_output_2_loss: 0.0082 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 483/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0094 - output_1_loss: 3.4044e-04 - output_2_loss: 0.0067 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.7437e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 484/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0094 - output_1_loss: 3.3974e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.8747e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 485/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0094 - output_1_loss: 3.4988e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0113 - val_output_1_loss: 5.5546e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 486/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0094 - output_1_loss: 3.4973e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0112 - val_output_1_loss: 4.8422e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 487/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0094 - output_1_loss: 3.4031e-04 - output_2_loss: 0.0066 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.7624e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 488/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0093 - output_1_loss: 3.3171e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.6584e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 489/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0093 - output_1_loss: 3.3548e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.7380e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 490/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0093 - output_1_loss: 3.3455e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.6412e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 491/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0093 - output_1_loss: 3.3431e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.6761e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 492/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0093 - output_1_loss: 3.3740e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.8948e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 493/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0093 - output_1_loss: 3.3921e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.5750e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 494/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0093 - output_1_loss: 3.2956e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 4.6114e-04 - val_output_2_loss: 0.0081 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 495/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0093 - output_1_loss: 3.2768e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.5693e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 496/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0092 - output_1_loss: 3.4244e-04 - output_2_loss: 0.0064 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0111 - val_output_1_loss: 5.0403e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 497/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0092 - output_1_loss: 3.3256e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.5880e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 498/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0092 - output_1_loss: 3.2971e-04 - output_2_loss: 0.0063 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.7646e-04 - val_output_2_loss: 0.0080 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 499/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0092 - output_1_loss: 3.2745e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.6215e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 500/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0092 - output_1_loss: 3.2756e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.5278e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 501/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0092 - output_1_loss: 3.2570e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.6375e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 502/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0092 - output_1_loss: 3.3695e-04 - output_2_loss: 0.0065 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.8731e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 503/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0092 - output_1_loss: 3.2959e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.4923e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 504/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0091 - output_1_loss: 3.2464e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0110 - val_output_1_loss: 4.6155e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 505/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0091 - output_1_loss: 3.2317e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.5520e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 506/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0091 - output_1_loss: 3.2551e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.5340e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 507/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0091 - output_1_loss: 3.2038e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.4893e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 508/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0091 - output_1_loss: 3.2687e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4418e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 509/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0091 - output_1_loss: 3.2011e-04 - output_2_loss: 0.0061 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0109 - val_output_1_loss: 4.5171e-04 - val_output_2_loss: 0.0079 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 510/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.1991e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.5386e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 511/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.1890e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4808e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 512/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0090 - output_1_loss: 3.2258e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.5612e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 513/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.2191e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4970e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 514/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.1609e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4457e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 515/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.2272e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4758e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 516/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.1973e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.5506e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 517/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0090 - output_1_loss: 3.1717e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3534e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 518/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0089 - output_1_loss: 3.1742e-04 - output_2_loss: 0.0059 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.4248e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 519/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0089 - output_1_loss: 3.1755e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0108 - val_output_1_loss: 4.4590e-04 - val_output_2_loss: 0.0078 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 520/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0089 - output_1_loss: 3.1516e-04 - output_2_loss: 0.0059 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3532e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 521/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0089 - output_1_loss: 3.1690e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3505e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 522/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0089 - output_1_loss: 3.2362e-04 - output_2_loss: 0.0062 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3697e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 523/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0089 - output_1_loss: 3.1661e-04 - output_2_loss: 0.0059 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3916e-04 - val_output_2_loss: 0.0077 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 524/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0089 - output_1_loss: 3.0887e-04 - output_2_loss: 0.0059 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.3687e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 525/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0088 - output_1_loss: 3.1330e-04 - output_2_loss: 0.0059 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.2722e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 526/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0088 - output_1_loss: 3.1129e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.2536e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 527/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0088 - output_1_loss: 3.0905e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.3795e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 528/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0088 - output_1_loss: 3.0998e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.6127e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 529/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0088 - output_1_loss: 3.0932e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.2562e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 530/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0088 - output_1_loss: 3.0806e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.3227e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 531/600\n",
      "8906/8906 [==============================] - 1s 79us/sample - loss: 0.0088 - output_1_loss: 3.1081e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.3500e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 532/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0088 - output_1_loss: 3.2125e-04 - output_2_loss: 0.0060 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0107 - val_output_1_loss: 4.9574e-04 - val_output_2_loss: 0.0076 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 533/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0088 - output_1_loss: 3.1076e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.2335e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 534/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0087 - output_1_loss: 3.0611e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.2126e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 535/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0087 - output_1_loss: 3.0884e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.2012e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 536/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0087 - output_1_loss: 3.0455e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0106 - val_output_1_loss: 4.5119e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 537/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0087 - output_1_loss: 3.0661e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.2097e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 538/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0087 - output_1_loss: 3.0359e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.3168e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 539/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0087 - output_1_loss: 3.0319e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.1877e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 540/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0086 - output_1_loss: 3.0395e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0105 - val_output_1_loss: 4.4244e-04 - val_output_2_loss: 0.0075 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 541/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0086 - output_1_loss: 3.0596e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2515e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 542/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0086 - output_1_loss: 3.0732e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2813e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 543/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0086 - output_1_loss: 3.0152e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.1212e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 544/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0086 - output_1_loss: 3.0242e-04 - output_2_loss: 0.0058 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2592e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 545/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0086 - output_1_loss: 3.0229e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.1641e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 546/600\n",
      "8906/8906 [==============================] - 1s 78us/sample - loss: 0.0086 - output_1_loss: 3.0014e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2023e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 547/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0086 - output_1_loss: 3.0253e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.4864e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 548/600\n",
      "8906/8906 [==============================] - 1s 77us/sample - loss: 0.0086 - output_1_loss: 3.0429e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2632e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 549/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0085 - output_1_loss: 3.0324e-04 - output_2_loss: 0.0057 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0104 - val_output_1_loss: 4.2817e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 550/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0085 - output_1_loss: 3.0063e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.1941e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 551/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0085 - output_1_loss: 3.0076e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.1194e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 552/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0085 - output_1_loss: 2.9762e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.1508e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 553/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0085 - output_1_loss: 2.9586e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.0534e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 554/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0085 - output_1_loss: 2.9300e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.0399e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 555/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0085 - output_1_loss: 2.9483e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.0894e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 556/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 2.9531e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.0305e-04 - val_output_2_loss: 0.0074 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 557/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0084 - output_1_loss: 2.9611e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.1450e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 558/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 2.9423e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.0743e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 559/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 2.9429e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.0912e-04 - val_output_2_loss: 0.0073 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 560/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 2.9235e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.0226e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 561/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 2.9201e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.1025e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 562/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0084 - output_1_loss: 2.9362e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.1497e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 563/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0084 - output_1_loss: 3.0188e-04 - output_2_loss: 0.0056 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0103 - val_output_1_loss: 4.6233e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 564/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0084 - output_1_loss: 2.9770e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 3.9803e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 565/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.9159e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.0285e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 566/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.9199e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0102 - val_output_1_loss: 4.0042e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 567/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.8993e-04 - output_2_loss: 0.0054 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0193e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 568/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.9131e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0163e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 569/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0083 - output_1_loss: 2.9151e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0181e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 570/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.8797e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0797e-04 - val_output_2_loss: 0.0072 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 571/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0083 - output_1_loss: 2.8742e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.1800e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 572/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8490e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0147e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 573/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8904e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0338e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 574/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0082 - output_1_loss: 2.8503e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0469e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 575/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8689e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 3.9007e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 576/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8459e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0101 - val_output_1_loss: 4.0009e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 577/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8668e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.9011e-04 - val_output_2_loss: 0.0071 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 578/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8278e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.9297e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 579/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0082 - output_1_loss: 2.8272e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.8835e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 580/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0082 - output_1_loss: 3.0029e-04 - output_2_loss: 0.0055 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.9070e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 581/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0082 - output_1_loss: 2.8339e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.9625e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 582/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0081 - output_1_loss: 2.8539e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 4.0141e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 583/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0081 - output_1_loss: 2.8509e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.8646e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 584/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0081 - output_1_loss: 2.8031e-04 - output_2_loss: 0.0052 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0100 - val_output_1_loss: 3.9691e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 585/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0081 - output_1_loss: 2.8276e-04 - output_2_loss: 0.0053 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.8854e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 586/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0081 - output_1_loss: 2.8088e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.8301e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 587/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0081 - output_1_loss: 2.8118e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.9370e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 588/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0081 - output_1_loss: 2.8003e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.8457e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 589/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.8033e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.8797e-04 - val_output_2_loss: 0.0070 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 590/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.8041e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.9080e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 591/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0080 - output_1_loss: 2.8184e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8246e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 592/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.7812e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.8479e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 593/600\n",
      "8906/8906 [==============================] - 1s 73us/sample - loss: 0.0080 - output_1_loss: 2.7862e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.9434e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 594/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.7824e-04 - output_2_loss: 0.0051 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.7768e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 595/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.7803e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8555e-04 - val_output_2_loss: 0.0068 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 596/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0080 - output_1_loss: 2.8068e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8620e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 597/600\n",
      "8906/8906 [==============================] - 1s 75us/sample - loss: 0.0079 - output_1_loss: 2.7646e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0099 - val_output_1_loss: 3.9497e-04 - val_output_2_loss: 0.0069 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 598/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0079 - output_1_loss: 2.7645e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8843e-04 - val_output_2_loss: 0.0068 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 599/600\n",
      "8906/8906 [==============================] - 1s 74us/sample - loss: 0.0079 - output_1_loss: 2.7583e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8517e-04 - val_output_2_loss: 0.0068 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n",
      "Epoch 600/600\n",
      "8906/8906 [==============================] - 1s 76us/sample - loss: 0.0079 - output_1_loss: 2.7431e-04 - output_2_loss: 0.0050 - output_3_loss: 0.0000e+00 - output_4_loss: 0.0000e+00 - val_loss: 0.0098 - val_output_1_loss: 3.8103e-04 - val_output_2_loss: 0.0068 - val_output_3_loss: 0.0000e+00 - val_output_4_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=loss_fns,\n",
    "              optimizer=optimizer(learning_rate=lr, **optimizer_opts))\n",
    "\n",
    "# Fit the model\n",
    "train_zeros = np.zeros(data_train_u.shape)\n",
    "aec_hist = model.fit(x=[data_train_u, data_train_f],\n",
    "                     y=[data_train_u, data_train_f, train_zeros, train_zeros],\n",
    "                     validation_data=val_data,\n",
    "                     callbacks=cbs,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=aec_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8906 samples, validate on 2227 samples\n",
      "Epoch 1/300\n",
      "8906/8906 [==============================] - 3s 318us/sample - loss: 325.5640 - output_1_loss: 0.0931 - output_2_loss: 0.0287 - output_3_loss: 1.0669 - output_4_loss: 320.8299 - val_loss: 133.1963 - val_output_1_loss: 0.1896 - val_output_2_loss: 0.0375 - val_output_3_loss: 1.0324 - val_output_4_loss: 130.1950\n",
      "Epoch 2/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 83.6514 - output_1_loss: 0.2574 - output_2_loss: 0.0393 - output_3_loss: 1.0120 - output_4_loss: 80.2237 - val_loss: 57.7683 - val_output_1_loss: 0.3209 - val_output_2_loss: 0.0424 - val_output_3_loss: 0.9988 - val_output_4_loss: 54.5074\n",
      "Epoch 3/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 42.2320 - output_1_loss: 0.3597 - output_2_loss: 0.0402 - output_3_loss: 0.9803 - output_4_loss: 38.7225 - val_loss: 33.8931 - val_output_1_loss: 0.4027 - val_output_2_loss: 0.0416 - val_output_3_loss: 0.9658 - val_output_4_loss: 30.5482\n",
      "Epoch 4/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 26.5803 - output_1_loss: 0.4282 - output_2_loss: 0.0398 - output_3_loss: 0.9474 - output_4_loss: 23.1838 - val_loss: 22.9171 - val_output_1_loss: 0.4624 - val_output_2_loss: 0.0434 - val_output_3_loss: 0.9269 - val_output_4_loss: 19.5602\n",
      "Epoch 5/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 18.8282 - output_1_loss: 0.4779 - output_2_loss: 0.0406 - output_3_loss: 0.9027 - output_4_loss: 15.4211 - val_loss: 17.0545 - val_output_1_loss: 0.5000 - val_output_2_loss: 0.0420 - val_output_3_loss: 0.8785 - val_output_4_loss: 13.7464\n",
      "Epoch 6/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 14.4348 - output_1_loss: 0.5056 - output_2_loss: 0.0414 - output_3_loss: 0.8537 - output_4_loss: 11.0943 - val_loss: 13.4748 - val_output_1_loss: 0.5241 - val_output_2_loss: 0.0446 - val_output_3_loss: 0.8277 - val_output_4_loss: 10.2353\n",
      "Epoch 7/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 11.6408 - output_1_loss: 0.5246 - output_2_loss: 0.0444 - output_3_loss: 0.8004 - output_4_loss: 8.4369 - val_loss: 11.0736 - val_output_1_loss: 0.5422 - val_output_2_loss: 0.0484 - val_output_3_loss: 0.7678 - val_output_4_loss: 7.9445\n",
      "Epoch 8/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 9.7053 - output_1_loss: 0.5402 - output_2_loss: 0.0474 - output_3_loss: 0.7417 - output_4_loss: 6.6148 - val_loss: 9.3672 - val_output_1_loss: 0.5498 - val_output_2_loss: 0.0511 - val_output_3_loss: 0.7117 - val_output_4_loss: 6.3742\n",
      "Epoch 9/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 8.2720 - output_1_loss: 0.5478 - output_2_loss: 0.0498 - output_3_loss: 0.6939 - output_4_loss: 5.3164 - val_loss: 8.0579 - val_output_1_loss: 0.5587 - val_output_2_loss: 0.0530 - val_output_3_loss: 0.6718 - val_output_4_loss: 5.1885\n",
      "Epoch 10/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 7.2109 - output_1_loss: 0.5506 - output_2_loss: 0.0512 - output_3_loss: 0.6623 - output_4_loss: 4.3794 - val_loss: 7.0918 - val_output_1_loss: 0.5563 - val_output_2_loss: 0.0560 - val_output_3_loss: 0.6421 - val_output_4_loss: 4.3248\n",
      "Epoch 11/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 6.4099 - output_1_loss: 0.5488 - output_2_loss: 0.0522 - output_3_loss: 0.6351 - output_4_loss: 3.6673 - val_loss: 6.3664 - val_output_1_loss: 0.5545 - val_output_2_loss: 0.0548 - val_output_3_loss: 0.6194 - val_output_4_loss: 3.6752\n",
      "Epoch 12/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 5.7956 - output_1_loss: 0.5445 - output_2_loss: 0.0513 - output_3_loss: 0.6122 - output_4_loss: 3.1221 - val_loss: 5.7951 - val_output_1_loss: 0.5493 - val_output_2_loss: 0.0542 - val_output_3_loss: 0.5994 - val_output_4_loss: 3.1672\n",
      "Epoch 13/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 5.3016 - output_1_loss: 0.5385 - output_2_loss: 0.0499 - output_3_loss: 0.5930 - output_4_loss: 2.6896 - val_loss: 5.3314 - val_output_1_loss: 0.5438 - val_output_2_loss: 0.0546 - val_output_3_loss: 0.5789 - val_output_4_loss: 2.7580\n",
      "Epoch 14/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 4.9040 - output_1_loss: 0.5333 - output_2_loss: 0.0491 - output_3_loss: 0.5748 - output_4_loss: 2.3560 - val_loss: 4.9387 - val_output_1_loss: 0.5355 - val_output_2_loss: 0.0528 - val_output_3_loss: 0.5618 - val_output_4_loss: 2.4215\n",
      "Epoch 15/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 4.5761 - output_1_loss: 0.5263 - output_2_loss: 0.0478 - output_3_loss: 0.5570 - output_4_loss: 2.0796 - val_loss: 4.6100 - val_output_1_loss: 0.5300 - val_output_2_loss: 0.0520 - val_output_3_loss: 0.5455 - val_output_4_loss: 2.1432\n",
      "Epoch 16/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 4.2843 - output_1_loss: 0.5213 - output_2_loss: 0.0467 - output_3_loss: 0.5393 - output_4_loss: 1.8410 - val_loss: 4.3387 - val_output_1_loss: 0.5264 - val_output_2_loss: 0.0515 - val_output_3_loss: 0.5293 - val_output_4_loss: 1.9229\n",
      "Epoch 17/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 4.0403 - output_1_loss: 0.5165 - output_2_loss: 0.0460 - output_3_loss: 0.5246 - output_4_loss: 1.6507 - val_loss: 4.1075 - val_output_1_loss: 0.5193 - val_output_2_loss: 0.0499 - val_output_3_loss: 0.5157 - val_output_4_loss: 1.7437\n",
      "Epoch 18/300\n",
      "8906/8906 [==============================] - 1s 88us/sample - loss: 3.8200 - output_1_loss: 0.5091 - output_2_loss: 0.0460 - output_3_loss: 0.5097 - output_4_loss: 1.4873 - val_loss: 3.8859 - val_output_1_loss: 0.5149 - val_output_2_loss: 0.0509 - val_output_3_loss: 0.4999 - val_output_4_loss: 1.5717\n",
      "Epoch 19/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 3.6315 - output_1_loss: 0.5042 - output_2_loss: 0.0444 - output_3_loss: 0.4951 - output_4_loss: 1.3487 - val_loss: 3.6920 - val_output_1_loss: 0.5110 - val_output_2_loss: 0.0492 - val_output_3_loss: 0.4869 - val_output_4_loss: 1.4302\n",
      "Epoch 20/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 3.4597 - output_1_loss: 0.4989 - output_2_loss: 0.0437 - output_3_loss: 0.4813 - output_4_loss: 1.2312 - val_loss: 3.5174 - val_output_1_loss: 0.5015 - val_output_2_loss: 0.0485 - val_output_3_loss: 0.4738 - val_output_4_loss: 1.3108\n",
      "Epoch 21/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 3.2975 - output_1_loss: 0.4931 - output_2_loss: 0.0430 - output_3_loss: 0.4672 - output_4_loss: 1.1245 - val_loss: 3.3737 - val_output_1_loss: 0.4935 - val_output_2_loss: 0.0478 - val_output_3_loss: 0.4609 - val_output_4_loss: 1.2218\n",
      "Epoch 22/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 3.1640 - output_1_loss: 0.4840 - output_2_loss: 0.0424 - output_3_loss: 0.4537 - output_4_loss: 1.0469 - val_loss: 3.2178 - val_output_1_loss: 0.4864 - val_output_2_loss: 0.0478 - val_output_3_loss: 0.4472 - val_output_4_loss: 1.1197\n",
      "Epoch 23/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 3.0234 - output_1_loss: 0.4758 - output_2_loss: 0.0422 - output_3_loss: 0.4408 - output_4_loss: 0.9634 - val_loss: 3.0931 - val_output_1_loss: 0.4765 - val_output_2_loss: 0.0472 - val_output_3_loss: 0.4351 - val_output_4_loss: 1.0511\n",
      "Epoch 24/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.9013 - output_1_loss: 0.4655 - output_2_loss: 0.0417 - output_3_loss: 0.4291 - output_4_loss: 0.8993 - val_loss: 2.9613 - val_output_1_loss: 0.4711 - val_output_2_loss: 0.0475 - val_output_3_loss: 0.4227 - val_output_4_loss: 0.9719\n",
      "Epoch 25/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.7833 - output_1_loss: 0.4584 - output_2_loss: 0.0417 - output_3_loss: 0.4158 - output_4_loss: 0.8359 - val_loss: 2.8410 - val_output_1_loss: 0.4600 - val_output_2_loss: 0.0465 - val_output_3_loss: 0.4115 - val_output_4_loss: 0.9109\n",
      "Epoch 26/300\n",
      "8906/8906 [==============================] - 1s 88us/sample - loss: 2.6644 - output_1_loss: 0.4486 - output_2_loss: 0.0415 - output_3_loss: 0.4038 - output_4_loss: 0.7796 - val_loss: 2.7291 - val_output_1_loss: 0.4529 - val_output_2_loss: 0.0464 - val_output_3_loss: 0.3993 - val_output_4_loss: 0.8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/300\n",
      "8906/8906 [==============================] - 1s 88us/sample - loss: 2.5611 - output_1_loss: 0.4379 - output_2_loss: 0.0413 - output_3_loss: 0.3927 - output_4_loss: 0.7331 - val_loss: 2.6200 - val_output_1_loss: 0.4417 - val_output_2_loss: 0.0461 - val_output_3_loss: 0.3880 - val_output_4_loss: 0.8054\n",
      "Epoch 28/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.4568 - output_1_loss: 0.4284 - output_2_loss: 0.0411 - output_3_loss: 0.3801 - output_4_loss: 0.6883 - val_loss: 2.5192 - val_output_1_loss: 0.4348 - val_output_2_loss: 0.0465 - val_output_3_loss: 0.3772 - val_output_4_loss: 0.7592\n",
      "Epoch 29/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.3602 - output_1_loss: 0.4188 - output_2_loss: 0.0410 - output_3_loss: 0.3695 - output_4_loss: 0.6495 - val_loss: 2.4132 - val_output_1_loss: 0.4209 - val_output_2_loss: 0.0463 - val_output_3_loss: 0.3661 - val_output_4_loss: 0.7139\n",
      "Epoch 30/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.2621 - output_1_loss: 0.4076 - output_2_loss: 0.0412 - output_3_loss: 0.3590 - output_4_loss: 0.6116 - val_loss: 2.3231 - val_output_1_loss: 0.4132 - val_output_2_loss: 0.0462 - val_output_3_loss: 0.3565 - val_output_4_loss: 0.6785\n",
      "Epoch 31/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 2.1770 - output_1_loss: 0.3990 - output_2_loss: 0.0411 - output_3_loss: 0.3479 - output_4_loss: 0.5811 - val_loss: 2.2329 - val_output_1_loss: 0.4006 - val_output_2_loss: 0.0460 - val_output_3_loss: 0.3464 - val_output_4_loss: 0.6467\n",
      "Epoch 32/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 2.0913 - output_1_loss: 0.3865 - output_2_loss: 0.0408 - output_3_loss: 0.3387 - output_4_loss: 0.5505 - val_loss: 2.1459 - val_output_1_loss: 0.3904 - val_output_2_loss: 0.0457 - val_output_3_loss: 0.3372 - val_output_4_loss: 0.6162\n",
      "Epoch 33/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 2.0043 - output_1_loss: 0.3766 - output_2_loss: 0.0410 - output_3_loss: 0.3298 - output_4_loss: 0.5225 - val_loss: 2.0584 - val_output_1_loss: 0.3806 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.3283 - val_output_4_loss: 0.5807\n",
      "Epoch 34/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.9240 - output_1_loss: 0.3671 - output_2_loss: 0.0408 - output_3_loss: 0.3202 - output_4_loss: 0.4930 - val_loss: 1.9806 - val_output_1_loss: 0.3685 - val_output_2_loss: 0.0457 - val_output_3_loss: 0.3193 - val_output_4_loss: 0.5589\n",
      "Epoch 35/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.8485 - output_1_loss: 0.3561 - output_2_loss: 0.0406 - output_3_loss: 0.3115 - output_4_loss: 0.4719 - val_loss: 1.8950 - val_output_1_loss: 0.3613 - val_output_2_loss: 0.0457 - val_output_3_loss: 0.3104 - val_output_4_loss: 0.5232\n",
      "Epoch 36/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.7751 - output_1_loss: 0.3469 - output_2_loss: 0.0406 - output_3_loss: 0.3027 - output_4_loss: 0.4484 - val_loss: 1.8235 - val_output_1_loss: 0.3513 - val_output_2_loss: 0.0453 - val_output_3_loss: 0.3028 - val_output_4_loss: 0.5023\n",
      "Epoch 37/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.7052 - output_1_loss: 0.3378 - output_2_loss: 0.0406 - output_3_loss: 0.2959 - output_4_loss: 0.4280 - val_loss: 1.7528 - val_output_1_loss: 0.3413 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.2949 - val_output_4_loss: 0.4806\n",
      "Epoch 38/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.6367 - output_1_loss: 0.3283 - output_2_loss: 0.0407 - output_3_loss: 0.2876 - output_4_loss: 0.4096 - val_loss: 1.6836 - val_output_1_loss: 0.3316 - val_output_2_loss: 0.0454 - val_output_3_loss: 0.2873 - val_output_4_loss: 0.4595\n",
      "Epoch 39/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.5710 - output_1_loss: 0.3185 - output_2_loss: 0.0409 - output_3_loss: 0.2801 - output_4_loss: 0.3909 - val_loss: 1.6195 - val_output_1_loss: 0.3239 - val_output_2_loss: 0.0460 - val_output_3_loss: 0.2795 - val_output_4_loss: 0.4398\n",
      "Epoch 40/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.5117 - output_1_loss: 0.3095 - output_2_loss: 0.0411 - output_3_loss: 0.2724 - output_4_loss: 0.3759 - val_loss: 1.5629 - val_output_1_loss: 0.3127 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.2720 - val_output_4_loss: 0.4301\n",
      "Epoch 41/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.4507 - output_1_loss: 0.2990 - output_2_loss: 0.0409 - output_3_loss: 0.2651 - output_4_loss: 0.3586 - val_loss: 1.4967 - val_output_1_loss: 0.3047 - val_output_2_loss: 0.0461 - val_output_3_loss: 0.2657 - val_output_4_loss: 0.4041\n",
      "Epoch 42/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.3974 - output_1_loss: 0.2902 - output_2_loss: 0.0410 - output_3_loss: 0.2587 - output_4_loss: 0.3471 - val_loss: 1.4414 - val_output_1_loss: 0.2944 - val_output_2_loss: 0.0462 - val_output_3_loss: 0.2584 - val_output_4_loss: 0.3917\n",
      "Epoch 43/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 1.3420 - output_1_loss: 0.2814 - output_2_loss: 0.0414 - output_3_loss: 0.2513 - output_4_loss: 0.3342 - val_loss: 1.3835 - val_output_1_loss: 0.2858 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.2522 - val_output_4_loss: 0.3724\n",
      "Epoch 44/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.2889 - output_1_loss: 0.2723 - output_2_loss: 0.0413 - output_3_loss: 0.2458 - output_4_loss: 0.3191 - val_loss: 1.3325 - val_output_1_loss: 0.2773 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.2457 - val_output_4_loss: 0.3595\n",
      "Epoch 45/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.2413 - output_1_loss: 0.2634 - output_2_loss: 0.0409 - output_3_loss: 0.2382 - output_4_loss: 0.3077 - val_loss: 1.2832 - val_output_1_loss: 0.2682 - val_output_2_loss: 0.0458 - val_output_3_loss: 0.2398 - val_output_4_loss: 0.3462\n",
      "Epoch 46/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 1.1944 - output_1_loss: 0.2543 - output_2_loss: 0.0408 - output_3_loss: 0.2323 - output_4_loss: 0.2959 - val_loss: 1.2378 - val_output_1_loss: 0.2610 - val_output_2_loss: 0.0460 - val_output_3_loss: 0.2333 - val_output_4_loss: 0.3338\n",
      "Epoch 47/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 1.1488 - output_1_loss: 0.2464 - output_2_loss: 0.0406 - output_3_loss: 0.2255 - output_4_loss: 0.2841 - val_loss: 1.1880 - val_output_1_loss: 0.2513 - val_output_2_loss: 0.0456 - val_output_3_loss: 0.2275 - val_output_4_loss: 0.3184\n",
      "Epoch 48/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 1.1057 - output_1_loss: 0.2386 - output_2_loss: 0.0404 - output_3_loss: 0.2209 - output_4_loss: 0.2726 - val_loss: 1.1451 - val_output_1_loss: 0.2447 - val_output_2_loss: 0.0453 - val_output_3_loss: 0.2216 - val_output_4_loss: 0.3056\n",
      "Epoch 49/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 1.0634 - output_1_loss: 0.2309 - output_2_loss: 0.0402 - output_3_loss: 0.2147 - output_4_loss: 0.2597 - val_loss: 1.1055 - val_output_1_loss: 0.2343 - val_output_2_loss: 0.0451 - val_output_3_loss: 0.2171 - val_output_4_loss: 0.2972\n",
      "Epoch 50/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 1.0247 - output_1_loss: 0.2225 - output_2_loss: 0.0399 - output_3_loss: 0.2088 - output_4_loss: 0.2509 - val_loss: 1.0662 - val_output_1_loss: 0.2271 - val_output_2_loss: 0.0448 - val_output_3_loss: 0.2113 - val_output_4_loss: 0.2864\n",
      "Epoch 51/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.9882 - output_1_loss: 0.2156 - output_2_loss: 0.0399 - output_3_loss: 0.2040 - output_4_loss: 0.2434 - val_loss: 1.0245 - val_output_1_loss: 0.2193 - val_output_2_loss: 0.0445 - val_output_3_loss: 0.2072 - val_output_4_loss: 0.2711\n",
      "Epoch 52/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.9524 - output_1_loss: 0.2075 - output_2_loss: 0.0393 - output_3_loss: 0.1988 - output_4_loss: 0.2331 - val_loss: 0.9888 - val_output_1_loss: 0.2118 - val_output_2_loss: 0.0442 - val_output_3_loss: 0.2011 - val_output_4_loss: 0.2623\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.9193 - output_1_loss: 0.2001 - output_2_loss: 0.0389 - output_3_loss: 0.1937 - output_4_loss: 0.2258 - val_loss: 0.9550 - val_output_1_loss: 0.2041 - val_output_2_loss: 0.0440 - val_output_3_loss: 0.1962 - val_output_4_loss: 0.2537\n",
      "Epoch 54/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.8865 - output_1_loss: 0.1935 - output_2_loss: 0.0388 - output_3_loss: 0.1897 - output_4_loss: 0.2183 - val_loss: 0.9246 - val_output_1_loss: 0.1969 - val_output_2_loss: 0.0437 - val_output_3_loss: 0.1917 - val_output_4_loss: 0.2467\n",
      "Epoch 55/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.8565 - output_1_loss: 0.1857 - output_2_loss: 0.0382 - output_3_loss: 0.1852 - output_4_loss: 0.2093 - val_loss: 0.8913 - val_output_1_loss: 0.1896 - val_output_2_loss: 0.0431 - val_output_3_loss: 0.1875 - val_output_4_loss: 0.2360\n",
      "Epoch 56/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.8271 - output_1_loss: 0.1786 - output_2_loss: 0.0377 - output_3_loss: 0.1800 - output_4_loss: 0.2019 - val_loss: 0.8727 - val_output_1_loss: 0.1846 - val_output_2_loss: 0.0429 - val_output_3_loss: 0.1837 - val_output_4_loss: 0.2365\n",
      "Epoch 57/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.8005 - output_1_loss: 0.1722 - output_2_loss: 0.0375 - output_3_loss: 0.1767 - output_4_loss: 0.1959 - val_loss: 0.8323 - val_output_1_loss: 0.1751 - val_output_2_loss: 0.0425 - val_output_3_loss: 0.1794 - val_output_4_loss: 0.2192\n",
      "Epoch 58/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.7732 - output_1_loss: 0.1652 - output_2_loss: 0.0370 - output_3_loss: 0.1727 - output_4_loss: 0.1883 - val_loss: 0.8059 - val_output_1_loss: 0.1691 - val_output_2_loss: 0.0421 - val_output_3_loss: 0.1762 - val_output_4_loss: 0.2111\n",
      "Epoch 59/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.7481 - output_1_loss: 0.1589 - output_2_loss: 0.0367 - output_3_loss: 0.1691 - output_4_loss: 0.1823 - val_loss: 0.7823 - val_output_1_loss: 0.1628 - val_output_2_loss: 0.0416 - val_output_3_loss: 0.1723 - val_output_4_loss: 0.2063\n",
      "Epoch 60/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.7227 - output_1_loss: 0.1525 - output_2_loss: 0.0360 - output_3_loss: 0.1651 - output_4_loss: 0.1747 - val_loss: 0.7585 - val_output_1_loss: 0.1560 - val_output_2_loss: 0.0411 - val_output_3_loss: 0.1687 - val_output_4_loss: 0.2007\n",
      "Epoch 61/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.6988 - output_1_loss: 0.1458 - output_2_loss: 0.0354 - output_3_loss: 0.1620 - output_4_loss: 0.1680 - val_loss: 0.7330 - val_output_1_loss: 0.1496 - val_output_2_loss: 0.0407 - val_output_3_loss: 0.1659 - val_output_4_loss: 0.1920\n",
      "Epoch 62/300\n",
      "8906/8906 [==============================] - 1s 94us/sample - loss: 0.6795 - output_1_loss: 0.1415 - output_2_loss: 0.0351 - output_3_loss: 0.1585 - output_4_loss: 0.1647 - val_loss: 0.7119 - val_output_1_loss: 0.1440 - val_output_2_loss: 0.0400 - val_output_3_loss: 0.1620 - val_output_4_loss: 0.1876\n",
      "Epoch 63/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.6568 - output_1_loss: 0.1350 - output_2_loss: 0.0349 - output_3_loss: 0.1557 - output_4_loss: 0.1593 - val_loss: 0.6908 - val_output_1_loss: 0.1384 - val_output_2_loss: 0.0398 - val_output_3_loss: 0.1599 - val_output_4_loss: 0.1806\n",
      "Epoch 64/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.6368 - output_1_loss: 0.1292 - output_2_loss: 0.0341 - output_3_loss: 0.1528 - output_4_loss: 0.1533 - val_loss: 0.6697 - val_output_1_loss: 0.1340 - val_output_2_loss: 0.0394 - val_output_3_loss: 0.1561 - val_output_4_loss: 0.1741\n",
      "Epoch 65/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.6168 - output_1_loss: 0.1239 - output_2_loss: 0.0337 - output_3_loss: 0.1486 - output_4_loss: 0.1480 - val_loss: 0.6559 - val_output_1_loss: 0.1281 - val_output_2_loss: 0.0390 - val_output_3_loss: 0.1527 - val_output_4_loss: 0.1755\n",
      "Epoch 66/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5999 - output_1_loss: 0.1194 - output_2_loss: 0.0332 - output_3_loss: 0.1457 - output_4_loss: 0.1448 - val_loss: 0.6334 - val_output_1_loss: 0.1260 - val_output_2_loss: 0.0385 - val_output_3_loss: 0.1495 - val_output_4_loss: 0.1640\n",
      "Epoch 67/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5822 - output_1_loss: 0.1148 - output_2_loss: 0.0328 - output_3_loss: 0.1430 - output_4_loss: 0.1402 - val_loss: 0.6152 - val_output_1_loss: 0.1191 - val_output_2_loss: 0.0379 - val_output_3_loss: 0.1468 - val_output_4_loss: 0.1608\n",
      "Epoch 68/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5652 - output_1_loss: 0.1100 - output_2_loss: 0.0324 - output_3_loss: 0.1397 - output_4_loss: 0.1359 - val_loss: 0.5952 - val_output_1_loss: 0.1137 - val_output_2_loss: 0.0376 - val_output_3_loss: 0.1434 - val_output_4_loss: 0.1544\n",
      "Epoch 69/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.5488 - output_1_loss: 0.1061 - output_2_loss: 0.0321 - output_3_loss: 0.1361 - output_4_loss: 0.1315 - val_loss: 0.5810 - val_output_1_loss: 0.1096 - val_output_2_loss: 0.0370 - val_output_3_loss: 0.1403 - val_output_4_loss: 0.1521\n",
      "Epoch 70/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5336 - output_1_loss: 0.1021 - output_2_loss: 0.0318 - output_3_loss: 0.1339 - output_4_loss: 0.1281 - val_loss: 0.5639 - val_output_1_loss: 0.1058 - val_output_2_loss: 0.0367 - val_output_3_loss: 0.1372 - val_output_4_loss: 0.1463\n",
      "Epoch 71/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5189 - output_1_loss: 0.0976 - output_2_loss: 0.0314 - output_3_loss: 0.1303 - output_4_loss: 0.1240 - val_loss: 0.5484 - val_output_1_loss: 0.1018 - val_output_2_loss: 0.0362 - val_output_3_loss: 0.1344 - val_output_4_loss: 0.1420\n",
      "Epoch 72/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.5043 - output_1_loss: 0.0940 - output_2_loss: 0.0309 - output_3_loss: 0.1272 - output_4_loss: 0.1202 - val_loss: 0.5343 - val_output_1_loss: 0.0987 - val_output_2_loss: 0.0359 - val_output_3_loss: 0.1312 - val_output_4_loss: 0.1380\n",
      "Epoch 73/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.4919 - output_1_loss: 0.0915 - output_2_loss: 0.0310 - output_3_loss: 0.1249 - output_4_loss: 0.1180 - val_loss: 0.5241 - val_output_1_loss: 0.0958 - val_output_2_loss: 0.0359 - val_output_3_loss: 0.1284 - val_output_4_loss: 0.1371\n",
      "Epoch 74/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.4802 - output_1_loss: 0.0879 - output_2_loss: 0.0304 - output_3_loss: 0.1214 - output_4_loss: 0.1157 - val_loss: 0.5108 - val_output_1_loss: 0.0921 - val_output_2_loss: 0.0353 - val_output_3_loss: 0.1258 - val_output_4_loss: 0.1337\n",
      "Epoch 75/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.4663 - output_1_loss: 0.0858 - output_2_loss: 0.0308 - output_3_loss: 0.1204 - output_4_loss: 0.1140 - val_loss: 0.5014 - val_output_1_loss: 0.0887 - val_output_2_loss: 0.0351 - val_output_3_loss: 0.1225 - val_output_4_loss: 0.1342\n",
      "Epoch 76/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.4549 - output_1_loss: 0.0820 - output_2_loss: 0.0296 - output_3_loss: 0.1157 - output_4_loss: 0.1085 - val_loss: 0.4834 - val_output_1_loss: 0.0864 - val_output_2_loss: 0.0343 - val_output_3_loss: 0.1200 - val_output_4_loss: 0.1246\n",
      "Epoch 77/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.4426 - output_1_loss: 0.0792 - output_2_loss: 0.0292 - output_3_loss: 0.1127 - output_4_loss: 0.1052 - val_loss: 0.4729 - val_output_1_loss: 0.0841 - val_output_2_loss: 0.0337 - val_output_3_loss: 0.1172 - val_output_4_loss: 0.1224\n",
      "Epoch 78/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.4336 - output_1_loss: 0.0771 - output_2_loss: 0.0290 - output_3_loss: 0.1104 - output_4_loss: 0.1043 - val_loss: 0.4618 - val_output_1_loss: 0.0821 - val_output_2_loss: 0.0336 - val_output_3_loss: 0.1143 - val_output_4_loss: 0.1190\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.4223 - output_1_loss: 0.0744 - output_2_loss: 0.0287 - output_3_loss: 0.1070 - output_4_loss: 0.1006 - val_loss: 0.4519 - val_output_1_loss: 0.0799 - val_output_2_loss: 0.0334 - val_output_3_loss: 0.1119 - val_output_4_loss: 0.1162\n",
      "Epoch 80/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.4110 - output_1_loss: 0.0721 - output_2_loss: 0.0284 - output_3_loss: 0.1046 - output_4_loss: 0.0976 - val_loss: 0.4382 - val_output_1_loss: 0.0762 - val_output_2_loss: 0.0328 - val_output_3_loss: 0.1084 - val_output_4_loss: 0.1125\n",
      "Epoch 81/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.4019 - output_1_loss: 0.0698 - output_2_loss: 0.0281 - output_3_loss: 0.1020 - output_4_loss: 0.0953 - val_loss: 0.4302 - val_output_1_loss: 0.0759 - val_output_2_loss: 0.0326 - val_output_3_loss: 0.1058 - val_output_4_loss: 0.1097\n",
      "Epoch 82/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3918 - output_1_loss: 0.0679 - output_2_loss: 0.0277 - output_3_loss: 0.0991 - output_4_loss: 0.0924 - val_loss: 0.4201 - val_output_1_loss: 0.0719 - val_output_2_loss: 0.0325 - val_output_3_loss: 0.1033 - val_output_4_loss: 0.1081\n",
      "Epoch 83/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3830 - output_1_loss: 0.0657 - output_2_loss: 0.0276 - output_3_loss: 0.0967 - output_4_loss: 0.0902 - val_loss: 0.4102 - val_output_1_loss: 0.0698 - val_output_2_loss: 0.0320 - val_output_3_loss: 0.1005 - val_output_4_loss: 0.1056\n",
      "Epoch 84/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3749 - output_1_loss: 0.0640 - output_2_loss: 0.0273 - output_3_loss: 0.0941 - output_4_loss: 0.0886 - val_loss: 0.4033 - val_output_1_loss: 0.0689 - val_output_2_loss: 0.0320 - val_output_3_loss: 0.0981 - val_output_4_loss: 0.1039\n",
      "Epoch 85/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3666 - output_1_loss: 0.0622 - output_2_loss: 0.0274 - output_3_loss: 0.0924 - output_4_loss: 0.0869 - val_loss: 0.3915 - val_output_1_loss: 0.0657 - val_output_2_loss: 0.0315 - val_output_3_loss: 0.0962 - val_output_4_loss: 0.0995\n",
      "Epoch 86/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.3582 - output_1_loss: 0.0604 - output_2_loss: 0.0268 - output_3_loss: 0.0905 - output_4_loss: 0.0845 - val_loss: 0.3907 - val_output_1_loss: 0.0657 - val_output_2_loss: 0.0317 - val_output_3_loss: 0.0965 - val_output_4_loss: 0.0998\n",
      "Epoch 87/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3519 - output_1_loss: 0.0593 - output_2_loss: 0.0266 - output_3_loss: 0.0877 - output_4_loss: 0.0830 - val_loss: 0.3800 - val_output_1_loss: 0.0640 - val_output_2_loss: 0.0314 - val_output_3_loss: 0.0921 - val_output_4_loss: 0.0970\n",
      "Epoch 88/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3440 - output_1_loss: 0.0572 - output_2_loss: 0.0266 - output_3_loss: 0.0861 - output_4_loss: 0.0812 - val_loss: 0.3703 - val_output_1_loss: 0.0608 - val_output_2_loss: 0.0309 - val_output_3_loss: 0.0900 - val_output_4_loss: 0.0946\n",
      "Epoch 89/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.3362 - output_1_loss: 0.0553 - output_2_loss: 0.0261 - output_3_loss: 0.0836 - output_4_loss: 0.0787 - val_loss: 0.3627 - val_output_1_loss: 0.0592 - val_output_2_loss: 0.0306 - val_output_3_loss: 0.0879 - val_output_4_loss: 0.0925\n",
      "Epoch 90/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.3298 - output_1_loss: 0.0538 - output_2_loss: 0.0258 - output_3_loss: 0.0818 - output_4_loss: 0.0771 - val_loss: 0.3571 - val_output_1_loss: 0.0576 - val_output_2_loss: 0.0300 - val_output_3_loss: 0.0865 - val_output_4_loss: 0.0918\n",
      "Epoch 91/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3288 - output_1_loss: 0.0542 - output_2_loss: 0.0258 - output_3_loss: 0.0808 - output_4_loss: 0.0787 - val_loss: 0.3551 - val_output_1_loss: 0.0565 - val_output_2_loss: 0.0306 - val_output_3_loss: 0.0841 - val_output_4_loss: 0.0940\n",
      "Epoch 92/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3178 - output_1_loss: 0.0515 - output_2_loss: 0.0254 - output_3_loss: 0.0791 - output_4_loss: 0.0744 - val_loss: 0.3412 - val_output_1_loss: 0.0556 - val_output_2_loss: 0.0294 - val_output_3_loss: 0.0828 - val_output_4_loss: 0.0846\n",
      "Epoch 93/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.3105 - output_1_loss: 0.0495 - output_2_loss: 0.0250 - output_3_loss: 0.0769 - output_4_loss: 0.0715 - val_loss: 0.3339 - val_output_1_loss: 0.0528 - val_output_2_loss: 0.0291 - val_output_3_loss: 0.0809 - val_output_4_loss: 0.0833\n",
      "Epoch 94/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.3046 - output_1_loss: 0.0486 - output_2_loss: 0.0252 - output_3_loss: 0.0763 - output_4_loss: 0.0712 - val_loss: 0.3424 - val_output_1_loss: 0.0541 - val_output_2_loss: 0.0303 - val_output_3_loss: 0.0796 - val_output_4_loss: 0.0919\n",
      "Epoch 95/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.3018 - output_1_loss: 0.0476 - output_2_loss: 0.0249 - output_3_loss: 0.0744 - output_4_loss: 0.0701 - val_loss: 0.3249 - val_output_1_loss: 0.0509 - val_output_2_loss: 0.0291 - val_output_3_loss: 0.0786 - val_output_4_loss: 0.0808\n",
      "Epoch 96/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2952 - output_1_loss: 0.0461 - output_2_loss: 0.0244 - output_3_loss: 0.0728 - output_4_loss: 0.0676 - val_loss: 0.3201 - val_output_1_loss: 0.0493 - val_output_2_loss: 0.0287 - val_output_3_loss: 0.0771 - val_output_4_loss: 0.0805\n",
      "Epoch 97/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2909 - output_1_loss: 0.0450 - output_2_loss: 0.0241 - output_3_loss: 0.0716 - output_4_loss: 0.0672 - val_loss: 0.3133 - val_output_1_loss: 0.0481 - val_output_2_loss: 0.0283 - val_output_3_loss: 0.0759 - val_output_4_loss: 0.0773\n",
      "Epoch 98/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2850 - output_1_loss: 0.0436 - output_2_loss: 0.0238 - output_3_loss: 0.0706 - output_4_loss: 0.0652 - val_loss: 0.3075 - val_output_1_loss: 0.0473 - val_output_2_loss: 0.0279 - val_output_3_loss: 0.0745 - val_output_4_loss: 0.0752\n",
      "Epoch 99/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2796 - output_1_loss: 0.0425 - output_2_loss: 0.0235 - output_3_loss: 0.0694 - output_4_loss: 0.0633 - val_loss: 0.3089 - val_output_1_loss: 0.0469 - val_output_2_loss: 0.0287 - val_output_3_loss: 0.0734 - val_output_4_loss: 0.0782\n",
      "Epoch 100/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2754 - output_1_loss: 0.0415 - output_2_loss: 0.0234 - output_3_loss: 0.0683 - output_4_loss: 0.0624 - val_loss: 0.2966 - val_output_1_loss: 0.0443 - val_output_2_loss: 0.0274 - val_output_3_loss: 0.0724 - val_output_4_loss: 0.0716\n",
      "Epoch 101/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2713 - output_1_loss: 0.0404 - output_2_loss: 0.0231 - output_3_loss: 0.0670 - output_4_loss: 0.0615 - val_loss: 0.2954 - val_output_1_loss: 0.0447 - val_output_2_loss: 0.0274 - val_output_3_loss: 0.0712 - val_output_4_loss: 0.0721\n",
      "Epoch 102/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2668 - output_1_loss: 0.0395 - output_2_loss: 0.0229 - output_3_loss: 0.0662 - output_4_loss: 0.0600 - val_loss: 0.2923 - val_output_1_loss: 0.0451 - val_output_2_loss: 0.0271 - val_output_3_loss: 0.0705 - val_output_4_loss: 0.0705\n",
      "Epoch 103/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2644 - output_1_loss: 0.0388 - output_2_loss: 0.0229 - output_3_loss: 0.0654 - output_4_loss: 0.0601 - val_loss: 0.2841 - val_output_1_loss: 0.0412 - val_output_2_loss: 0.0269 - val_output_3_loss: 0.0694 - val_output_4_loss: 0.0683\n",
      "Epoch 104/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2603 - output_1_loss: 0.0381 - output_2_loss: 0.0229 - output_3_loss: 0.0648 - output_4_loss: 0.0588 - val_loss: 0.2788 - val_output_1_loss: 0.0402 - val_output_2_loss: 0.0265 - val_output_3_loss: 0.0682 - val_output_4_loss: 0.0664\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.2551 - output_1_loss: 0.0369 - output_2_loss: 0.0224 - output_3_loss: 0.0635 - output_4_loss: 0.0573 - val_loss: 0.2846 - val_output_1_loss: 0.0416 - val_output_2_loss: 0.0274 - val_output_3_loss: 0.0679 - val_output_4_loss: 0.0711\n",
      "Epoch 106/300\n",
      "8906/8906 [==============================] - 1s 95us/sample - loss: 0.2514 - output_1_loss: 0.0355 - output_2_loss: 0.0222 - output_3_loss: 0.0624 - output_4_loss: 0.0563 - val_loss: 0.2716 - val_output_1_loss: 0.0382 - val_output_2_loss: 0.0263 - val_output_3_loss: 0.0668 - val_output_4_loss: 0.0643\n",
      "Epoch 107/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2485 - output_1_loss: 0.0349 - output_2_loss: 0.0221 - output_3_loss: 0.0617 - output_4_loss: 0.0557 - val_loss: 0.2730 - val_output_1_loss: 0.0392 - val_output_2_loss: 0.0261 - val_output_3_loss: 0.0684 - val_output_4_loss: 0.0639\n",
      "Epoch 108/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2448 - output_1_loss: 0.0340 - output_2_loss: 0.0218 - output_3_loss: 0.0608 - output_4_loss: 0.0544 - val_loss: 0.2639 - val_output_1_loss: 0.0364 - val_output_2_loss: 0.0258 - val_output_3_loss: 0.0651 - val_output_4_loss: 0.0620\n",
      "Epoch 109/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2408 - output_1_loss: 0.0328 - output_2_loss: 0.0215 - output_3_loss: 0.0601 - output_4_loss: 0.0532 - val_loss: 0.2669 - val_output_1_loss: 0.0373 - val_output_2_loss: 0.0264 - val_output_3_loss: 0.0654 - val_output_4_loss: 0.0636\n",
      "Epoch 110/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2378 - output_1_loss: 0.0327 - output_2_loss: 0.0214 - output_3_loss: 0.0597 - output_4_loss: 0.0526 - val_loss: 0.2584 - val_output_1_loss: 0.0351 - val_output_2_loss: 0.0255 - val_output_3_loss: 0.0636 - val_output_4_loss: 0.0609\n",
      "Epoch 111/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2344 - output_1_loss: 0.0312 - output_2_loss: 0.0212 - output_3_loss: 0.0585 - output_4_loss: 0.0518 - val_loss: 0.2552 - val_output_1_loss: 0.0343 - val_output_2_loss: 0.0253 - val_output_3_loss: 0.0627 - val_output_4_loss: 0.0601\n",
      "Epoch 112/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.2318 - output_1_loss: 0.0306 - output_2_loss: 0.0210 - output_3_loss: 0.0580 - output_4_loss: 0.0512 - val_loss: 0.2570 - val_output_1_loss: 0.0356 - val_output_2_loss: 0.0253 - val_output_3_loss: 0.0642 - val_output_4_loss: 0.0598\n",
      "Epoch 113/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2309 - output_1_loss: 0.0307 - output_2_loss: 0.0209 - output_3_loss: 0.0575 - output_4_loss: 0.0516 - val_loss: 0.2509 - val_output_1_loss: 0.0326 - val_output_2_loss: 0.0250 - val_output_3_loss: 0.0615 - val_output_4_loss: 0.0602\n",
      "Epoch 114/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2264 - output_1_loss: 0.0295 - output_2_loss: 0.0208 - output_3_loss: 0.0570 - output_4_loss: 0.0501 - val_loss: 0.2468 - val_output_1_loss: 0.0315 - val_output_2_loss: 0.0251 - val_output_3_loss: 0.0617 - val_output_4_loss: 0.0575\n",
      "Epoch 115/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.2237 - output_1_loss: 0.0285 - output_2_loss: 0.0205 - output_3_loss: 0.0562 - output_4_loss: 0.0494 - val_loss: 0.2433 - val_output_1_loss: 0.0308 - val_output_2_loss: 0.0248 - val_output_3_loss: 0.0603 - val_output_4_loss: 0.0571\n",
      "Epoch 116/300\n",
      "8906/8906 [==============================] - 1s 94us/sample - loss: 0.2214 - output_1_loss: 0.0280 - output_2_loss: 0.0204 - output_3_loss: 0.0556 - output_4_loss: 0.0489 - val_loss: 0.2395 - val_output_1_loss: 0.0301 - val_output_2_loss: 0.0245 - val_output_3_loss: 0.0598 - val_output_4_loss: 0.0553\n",
      "Epoch 117/300\n",
      "8906/8906 [==============================] - 1s 94us/sample - loss: 0.2181 - output_1_loss: 0.0273 - output_2_loss: 0.0201 - output_3_loss: 0.0551 - output_4_loss: 0.0480 - val_loss: 0.2560 - val_output_1_loss: 0.0339 - val_output_2_loss: 0.0255 - val_output_3_loss: 0.0601 - val_output_4_loss: 0.0673\n",
      "Epoch 118/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.2160 - output_1_loss: 0.0267 - output_2_loss: 0.0201 - output_3_loss: 0.0545 - output_4_loss: 0.0475 - val_loss: 0.2348 - val_output_1_loss: 0.0290 - val_output_2_loss: 0.0245 - val_output_3_loss: 0.0591 - val_output_4_loss: 0.0536\n",
      "Epoch 119/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2134 - output_1_loss: 0.0260 - output_2_loss: 0.0198 - output_3_loss: 0.0541 - output_4_loss: 0.0471 - val_loss: 0.2412 - val_output_1_loss: 0.0296 - val_output_2_loss: 0.0249 - val_output_3_loss: 0.0600 - val_output_4_loss: 0.0586\n",
      "Epoch 120/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2121 - output_1_loss: 0.0259 - output_2_loss: 0.0198 - output_3_loss: 0.0536 - output_4_loss: 0.0468 - val_loss: 0.2308 - val_output_1_loss: 0.0280 - val_output_2_loss: 0.0240 - val_output_3_loss: 0.0578 - val_output_4_loss: 0.0533\n",
      "Epoch 121/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2094 - output_1_loss: 0.0250 - output_2_loss: 0.0196 - output_3_loss: 0.0530 - output_4_loss: 0.0464 - val_loss: 0.2284 - val_output_1_loss: 0.0270 - val_output_2_loss: 0.0238 - val_output_3_loss: 0.0575 - val_output_4_loss: 0.0529\n",
      "Epoch 122/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2123 - output_1_loss: 0.0255 - output_2_loss: 0.0201 - output_3_loss: 0.0532 - output_4_loss: 0.0491 - val_loss: 0.2300 - val_output_1_loss: 0.0275 - val_output_2_loss: 0.0240 - val_output_3_loss: 0.0574 - val_output_4_loss: 0.0544\n",
      "Epoch 123/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2050 - output_1_loss: 0.0241 - output_2_loss: 0.0196 - output_3_loss: 0.0526 - output_4_loss: 0.0450 - val_loss: 0.2259 - val_output_1_loss: 0.0267 - val_output_2_loss: 0.0238 - val_output_3_loss: 0.0564 - val_output_4_loss: 0.0529\n",
      "Epoch 124/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2027 - output_1_loss: 0.0235 - output_2_loss: 0.0192 - output_3_loss: 0.0520 - output_4_loss: 0.0446 - val_loss: 0.2215 - val_output_1_loss: 0.0253 - val_output_2_loss: 0.0236 - val_output_3_loss: 0.0560 - val_output_4_loss: 0.0509\n",
      "Epoch 125/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.2007 - output_1_loss: 0.0227 - output_2_loss: 0.0189 - output_3_loss: 0.0512 - output_4_loss: 0.0440 - val_loss: 0.2213 - val_output_1_loss: 0.0257 - val_output_2_loss: 0.0234 - val_output_3_loss: 0.0559 - val_output_4_loss: 0.0510\n",
      "Epoch 126/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.2002 - output_1_loss: 0.0226 - output_2_loss: 0.0189 - output_3_loss: 0.0509 - output_4_loss: 0.0442 - val_loss: 0.2160 - val_output_1_loss: 0.0238 - val_output_2_loss: 0.0232 - val_output_3_loss: 0.0549 - val_output_4_loss: 0.0492\n",
      "Epoch 127/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1972 - output_1_loss: 0.0221 - output_2_loss: 0.0192 - output_3_loss: 0.0511 - output_4_loss: 0.0435 - val_loss: 0.2193 - val_output_1_loss: 0.0245 - val_output_2_loss: 0.0237 - val_output_3_loss: 0.0556 - val_output_4_loss: 0.0510\n",
      "Epoch 128/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1950 - output_1_loss: 0.0213 - output_2_loss: 0.0187 - output_3_loss: 0.0503 - output_4_loss: 0.0427 - val_loss: 0.2141 - val_output_1_loss: 0.0236 - val_output_2_loss: 0.0228 - val_output_3_loss: 0.0543 - val_output_4_loss: 0.0492\n",
      "Epoch 129/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1956 - output_1_loss: 0.0218 - output_2_loss: 0.0188 - output_3_loss: 0.0505 - output_4_loss: 0.0436 - val_loss: 0.2268 - val_output_1_loss: 0.0253 - val_output_2_loss: 0.0246 - val_output_3_loss: 0.0541 - val_output_4_loss: 0.0591\n",
      "Epoch 130/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1923 - output_1_loss: 0.0206 - output_2_loss: 0.0183 - output_3_loss: 0.0492 - output_4_loss: 0.0422 - val_loss: 0.2094 - val_output_1_loss: 0.0221 - val_output_2_loss: 0.0226 - val_output_3_loss: 0.0535 - val_output_4_loss: 0.0479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1914 - output_1_loss: 0.0202 - output_2_loss: 0.0183 - output_3_loss: 0.0490 - output_4_loss: 0.0427 - val_loss: 0.2234 - val_output_1_loss: 0.0268 - val_output_2_loss: 0.0235 - val_output_3_loss: 0.0541 - val_output_4_loss: 0.0562\n",
      "Epoch 132/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1919 - output_1_loss: 0.0204 - output_2_loss: 0.0183 - output_3_loss: 0.0487 - output_4_loss: 0.0435 - val_loss: 0.2079 - val_output_1_loss: 0.0216 - val_output_2_loss: 0.0226 - val_output_3_loss: 0.0527 - val_output_4_loss: 0.0484\n",
      "Epoch 133/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1869 - output_1_loss: 0.0192 - output_2_loss: 0.0179 - output_3_loss: 0.0482 - output_4_loss: 0.0409 - val_loss: 0.2073 - val_output_1_loss: 0.0216 - val_output_2_loss: 0.0221 - val_output_3_loss: 0.0530 - val_output_4_loss: 0.0484\n",
      "Epoch 134/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1851 - output_1_loss: 0.0189 - output_2_loss: 0.0177 - output_3_loss: 0.0479 - output_4_loss: 0.0402 - val_loss: 0.2027 - val_output_1_loss: 0.0205 - val_output_2_loss: 0.0220 - val_output_3_loss: 0.0522 - val_output_4_loss: 0.0461\n",
      "Epoch 135/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1841 - output_1_loss: 0.0186 - output_2_loss: 0.0177 - output_3_loss: 0.0476 - output_4_loss: 0.0401 - val_loss: 0.2056 - val_output_1_loss: 0.0208 - val_output_2_loss: 0.0225 - val_output_3_loss: 0.0521 - val_output_4_loss: 0.0487\n",
      "Epoch 136/300\n",
      "8906/8906 [==============================] - 1s 94us/sample - loss: 0.1829 - output_1_loss: 0.0184 - output_2_loss: 0.0178 - output_3_loss: 0.0477 - output_4_loss: 0.0403 - val_loss: 0.2009 - val_output_1_loss: 0.0198 - val_output_2_loss: 0.0217 - val_output_3_loss: 0.0527 - val_output_4_loss: 0.0455\n",
      "Epoch 137/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1818 - output_1_loss: 0.0184 - output_2_loss: 0.0175 - output_3_loss: 0.0473 - output_4_loss: 0.0398 - val_loss: 0.2001 - val_output_1_loss: 0.0198 - val_output_2_loss: 0.0220 - val_output_3_loss: 0.0518 - val_output_4_loss: 0.0457\n",
      "Epoch 138/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1800 - output_1_loss: 0.0178 - output_2_loss: 0.0174 - output_3_loss: 0.0470 - output_4_loss: 0.0395 - val_loss: 0.1984 - val_output_1_loss: 0.0194 - val_output_2_loss: 0.0215 - val_output_3_loss: 0.0513 - val_output_4_loss: 0.0458\n",
      "Epoch 139/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1794 - output_1_loss: 0.0176 - output_2_loss: 0.0184 - output_3_loss: 0.0478 - output_4_loss: 0.0404 - val_loss: 0.2008 - val_output_1_loss: 0.0193 - val_output_2_loss: 0.0218 - val_output_3_loss: 0.0511 - val_output_4_loss: 0.0485\n",
      "Epoch 140/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1780 - output_1_loss: 0.0171 - output_2_loss: 0.0172 - output_3_loss: 0.0464 - output_4_loss: 0.0395 - val_loss: 0.1978 - val_output_1_loss: 0.0195 - val_output_2_loss: 0.0216 - val_output_3_loss: 0.0506 - val_output_4_loss: 0.0464\n",
      "Epoch 141/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1802 - output_1_loss: 0.0177 - output_2_loss: 0.0174 - output_3_loss: 0.0462 - output_4_loss: 0.0413 - val_loss: 0.2018 - val_output_1_loss: 0.0195 - val_output_2_loss: 0.0216 - val_output_3_loss: 0.0518 - val_output_4_loss: 0.0495\n",
      "Epoch 142/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1762 - output_1_loss: 0.0167 - output_2_loss: 0.0171 - output_3_loss: 0.0458 - output_4_loss: 0.0390 - val_loss: 0.1921 - val_output_1_loss: 0.0177 - val_output_2_loss: 0.0211 - val_output_3_loss: 0.0506 - val_output_4_loss: 0.0435\n",
      "Epoch 143/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1740 - output_1_loss: 0.0163 - output_2_loss: 0.0169 - output_3_loss: 0.0455 - output_4_loss: 0.0381 - val_loss: 0.1911 - val_output_1_loss: 0.0176 - val_output_2_loss: 0.0209 - val_output_3_loss: 0.0497 - val_output_4_loss: 0.0440\n",
      "Epoch 144/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1729 - output_1_loss: 0.0159 - output_2_loss: 0.0168 - output_3_loss: 0.0453 - output_4_loss: 0.0383 - val_loss: 0.1966 - val_output_1_loss: 0.0193 - val_output_2_loss: 0.0216 - val_output_3_loss: 0.0514 - val_output_4_loss: 0.0457\n",
      "Epoch 145/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1721 - output_1_loss: 0.0159 - output_2_loss: 0.0167 - output_3_loss: 0.0451 - output_4_loss: 0.0379 - val_loss: 0.1870 - val_output_1_loss: 0.0169 - val_output_2_loss: 0.0207 - val_output_3_loss: 0.0489 - val_output_4_loss: 0.0422\n",
      "Epoch 146/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1706 - output_1_loss: 0.0154 - output_2_loss: 0.0166 - output_3_loss: 0.0447 - output_4_loss: 0.0377 - val_loss: 0.1885 - val_output_1_loss: 0.0183 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0488 - val_output_4_loss: 0.0429\n",
      "Epoch 147/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1708 - output_1_loss: 0.0156 - output_2_loss: 0.0167 - output_3_loss: 0.0449 - output_4_loss: 0.0381 - val_loss: 0.1880 - val_output_1_loss: 0.0167 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0488 - val_output_4_loss: 0.0442\n",
      "Epoch 148/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1685 - output_1_loss: 0.0149 - output_2_loss: 0.0168 - output_3_loss: 0.0448 - output_4_loss: 0.0381 - val_loss: 0.1923 - val_output_1_loss: 0.0177 - val_output_2_loss: 0.0213 - val_output_3_loss: 0.0485 - val_output_4_loss: 0.0474\n",
      "Epoch 149/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1711 - output_1_loss: 0.0154 - output_2_loss: 0.0169 - output_3_loss: 0.0441 - output_4_loss: 0.0393 - val_loss: 0.1848 - val_output_1_loss: 0.0166 - val_output_2_loss: 0.0203 - val_output_3_loss: 0.0483 - val_output_4_loss: 0.0424\n",
      "Epoch 150/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1662 - output_1_loss: 0.0146 - output_2_loss: 0.0165 - output_3_loss: 0.0442 - output_4_loss: 0.0368 - val_loss: 0.1853 - val_output_1_loss: 0.0162 - val_output_2_loss: 0.0202 - val_output_3_loss: 0.0497 - val_output_4_loss: 0.0421\n",
      "Epoch 151/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1651 - output_1_loss: 0.0141 - output_2_loss: 0.0161 - output_3_loss: 0.0435 - output_4_loss: 0.0363 - val_loss: 0.1816 - val_output_1_loss: 0.0156 - val_output_2_loss: 0.0202 - val_output_3_loss: 0.0478 - val_output_4_loss: 0.0413\n",
      "Epoch 152/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1646 - output_1_loss: 0.0142 - output_2_loss: 0.0161 - output_3_loss: 0.0436 - output_4_loss: 0.0364 - val_loss: 0.1826 - val_output_1_loss: 0.0154 - val_output_2_loss: 0.0203 - val_output_3_loss: 0.0477 - val_output_4_loss: 0.0427\n",
      "Epoch 153/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1644 - output_1_loss: 0.0141 - output_2_loss: 0.0162 - output_3_loss: 0.0433 - output_4_loss: 0.0365 - val_loss: 0.1814 - val_output_1_loss: 0.0151 - val_output_2_loss: 0.0201 - val_output_3_loss: 0.0474 - val_output_4_loss: 0.0426\n",
      "Epoch 154/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1644 - output_1_loss: 0.0140 - output_2_loss: 0.0161 - output_3_loss: 0.0433 - output_4_loss: 0.0371 - val_loss: 0.1835 - val_output_1_loss: 0.0151 - val_output_2_loss: 0.0200 - val_output_3_loss: 0.0475 - val_output_4_loss: 0.0449\n",
      "Epoch 155/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1651 - output_1_loss: 0.0141 - output_2_loss: 0.0161 - output_3_loss: 0.0429 - output_4_loss: 0.0381 - val_loss: 0.1821 - val_output_1_loss: 0.0158 - val_output_2_loss: 0.0201 - val_output_3_loss: 0.0472 - val_output_4_loss: 0.0432\n",
      "Epoch 156/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1612 - output_1_loss: 0.0135 - output_2_loss: 0.0158 - output_3_loss: 0.0427 - output_4_loss: 0.0355 - val_loss: 0.1758 - val_output_1_loss: 0.0142 - val_output_2_loss: 0.0198 - val_output_3_loss: 0.0466 - val_output_4_loss: 0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1606 - output_1_loss: 0.0133 - output_2_loss: 0.0157 - output_3_loss: 0.0424 - output_4_loss: 0.0358 - val_loss: 0.1814 - val_output_1_loss: 0.0160 - val_output_2_loss: 0.0197 - val_output_3_loss: 0.0472 - val_output_4_loss: 0.0434\n",
      "Epoch 158/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1602 - output_1_loss: 0.0134 - output_2_loss: 0.0157 - output_3_loss: 0.0425 - output_4_loss: 0.0358 - val_loss: 0.1776 - val_output_1_loss: 0.0149 - val_output_2_loss: 0.0197 - val_output_3_loss: 0.0468 - val_output_4_loss: 0.0412\n",
      "Epoch 159/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1592 - output_1_loss: 0.0132 - output_2_loss: 0.0157 - output_3_loss: 0.0421 - output_4_loss: 0.0352 - val_loss: 0.1762 - val_output_1_loss: 0.0148 - val_output_2_loss: 0.0197 - val_output_3_loss: 0.0463 - val_output_4_loss: 0.0406\n",
      "Epoch 160/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1589 - output_1_loss: 0.0128 - output_2_loss: 0.0156 - output_3_loss: 0.0419 - output_4_loss: 0.0359 - val_loss: 0.1842 - val_output_1_loss: 0.0155 - val_output_2_loss: 0.0204 - val_output_3_loss: 0.0476 - val_output_4_loss: 0.0461\n",
      "Epoch 161/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1593 - output_1_loss: 0.0131 - output_2_loss: 0.0157 - output_3_loss: 0.0419 - output_4_loss: 0.0361 - val_loss: 0.1741 - val_output_1_loss: 0.0144 - val_output_2_loss: 0.0196 - val_output_3_loss: 0.0463 - val_output_4_loss: 0.0394\n",
      "Epoch 162/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1559 - output_1_loss: 0.0125 - output_2_loss: 0.0153 - output_3_loss: 0.0418 - output_4_loss: 0.0343 - val_loss: 0.1734 - val_output_1_loss: 0.0138 - val_output_2_loss: 0.0192 - val_output_3_loss: 0.0471 - val_output_4_loss: 0.0391\n",
      "Epoch 163/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1567 - output_1_loss: 0.0125 - output_2_loss: 0.0154 - output_3_loss: 0.0414 - output_4_loss: 0.0352 - val_loss: 0.1756 - val_output_1_loss: 0.0137 - val_output_2_loss: 0.0196 - val_output_3_loss: 0.0470 - val_output_4_loss: 0.0414\n",
      "Epoch 164/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1570 - output_1_loss: 0.0125 - output_2_loss: 0.0155 - output_3_loss: 0.0414 - output_4_loss: 0.0357 - val_loss: 0.1710 - val_output_1_loss: 0.0130 - val_output_2_loss: 0.0193 - val_output_3_loss: 0.0451 - val_output_4_loss: 0.0398\n",
      "Epoch 165/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1547 - output_1_loss: 0.0121 - output_2_loss: 0.0153 - output_3_loss: 0.0411 - output_4_loss: 0.0348 - val_loss: 0.1726 - val_output_1_loss: 0.0148 - val_output_2_loss: 0.0193 - val_output_3_loss: 0.0454 - val_output_4_loss: 0.0395\n",
      "Epoch 166/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1528 - output_1_loss: 0.0118 - output_2_loss: 0.0151 - output_3_loss: 0.0409 - output_4_loss: 0.0335 - val_loss: 0.1691 - val_output_1_loss: 0.0133 - val_output_2_loss: 0.0191 - val_output_3_loss: 0.0454 - val_output_4_loss: 0.0380\n",
      "Epoch 167/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1523 - output_1_loss: 0.0115 - output_2_loss: 0.0151 - output_3_loss: 0.0408 - output_4_loss: 0.0338 - val_loss: 0.1741 - val_output_1_loss: 0.0144 - val_output_2_loss: 0.0194 - val_output_3_loss: 0.0462 - val_output_4_loss: 0.0410\n",
      "Epoch 168/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1545 - output_1_loss: 0.0121 - output_2_loss: 0.0152 - output_3_loss: 0.0408 - output_4_loss: 0.0354 - val_loss: 0.1706 - val_output_1_loss: 0.0128 - val_output_2_loss: 0.0191 - val_output_3_loss: 0.0461 - val_output_4_loss: 0.0396\n",
      "Epoch 169/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1513 - output_1_loss: 0.0115 - output_2_loss: 0.0149 - output_3_loss: 0.0405 - output_4_loss: 0.0336 - val_loss: 0.1659 - val_output_1_loss: 0.0123 - val_output_2_loss: 0.0189 - val_output_3_loss: 0.0443 - val_output_4_loss: 0.0376\n",
      "Epoch 170/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1500 - output_1_loss: 0.0112 - output_2_loss: 0.0148 - output_3_loss: 0.0403 - output_4_loss: 0.0332 - val_loss: 0.1706 - val_output_1_loss: 0.0133 - val_output_2_loss: 0.0186 - val_output_3_loss: 0.0469 - val_output_4_loss: 0.0391\n",
      "Epoch 171/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1504 - output_1_loss: 0.0113 - output_2_loss: 0.0149 - output_3_loss: 0.0402 - output_4_loss: 0.0337 - val_loss: 0.1666 - val_output_1_loss: 0.0121 - val_output_2_loss: 0.0189 - val_output_3_loss: 0.0441 - val_output_4_loss: 0.0392\n",
      "Epoch 172/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1499 - output_1_loss: 0.0113 - output_2_loss: 0.0148 - output_3_loss: 0.0402 - output_4_loss: 0.0335 - val_loss: 0.1651 - val_output_1_loss: 0.0118 - val_output_2_loss: 0.0187 - val_output_3_loss: 0.0446 - val_output_4_loss: 0.0378\n",
      "Epoch 173/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1492 - output_1_loss: 0.0111 - output_2_loss: 0.0148 - output_3_loss: 0.0401 - output_4_loss: 0.0335 - val_loss: 0.1670 - val_output_1_loss: 0.0123 - val_output_2_loss: 0.0189 - val_output_3_loss: 0.0453 - val_output_4_loss: 0.0385\n",
      "Epoch 174/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1477 - output_1_loss: 0.0108 - output_2_loss: 0.0146 - output_3_loss: 0.0397 - output_4_loss: 0.0327 - val_loss: 0.1632 - val_output_1_loss: 0.0116 - val_output_2_loss: 0.0185 - val_output_3_loss: 0.0437 - val_output_4_loss: 0.0376\n",
      "Epoch 175/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1469 - output_1_loss: 0.0106 - output_2_loss: 0.0145 - output_3_loss: 0.0395 - output_4_loss: 0.0325 - val_loss: 0.1629 - val_output_1_loss: 0.0117 - val_output_2_loss: 0.0184 - val_output_3_loss: 0.0441 - val_output_4_loss: 0.0371\n",
      "Epoch 176/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1463 - output_1_loss: 0.0106 - output_2_loss: 0.0152 - output_3_loss: 0.0402 - output_4_loss: 0.0325 - val_loss: 0.1622 - val_output_1_loss: 0.0115 - val_output_2_loss: 0.0183 - val_output_3_loss: 0.0439 - val_output_4_loss: 0.0370\n",
      "Epoch 177/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1465 - output_1_loss: 0.0106 - output_2_loss: 0.0146 - output_3_loss: 0.0393 - output_4_loss: 0.0328 - val_loss: 0.1630 - val_output_1_loss: 0.0113 - val_output_2_loss: 0.0184 - val_output_3_loss: 0.0433 - val_output_4_loss: 0.0390\n",
      "Epoch 178/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1471 - output_1_loss: 0.0106 - output_2_loss: 0.0146 - output_3_loss: 0.0393 - output_4_loss: 0.0334 - val_loss: 0.1613 - val_output_1_loss: 0.0114 - val_output_2_loss: 0.0184 - val_output_3_loss: 0.0431 - val_output_4_loss: 0.0373\n",
      "Epoch 179/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1444 - output_1_loss: 0.0102 - output_2_loss: 0.0143 - output_3_loss: 0.0390 - output_4_loss: 0.0321 - val_loss: 0.1596 - val_output_1_loss: 0.0112 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0431 - val_output_4_loss: 0.0364\n",
      "Epoch 180/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1453 - output_1_loss: 0.0104 - output_2_loss: 0.0144 - output_3_loss: 0.0390 - output_4_loss: 0.0328 - val_loss: 0.1605 - val_output_1_loss: 0.0111 - val_output_2_loss: 0.0182 - val_output_3_loss: 0.0435 - val_output_4_loss: 0.0370\n",
      "Epoch 181/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1464 - output_1_loss: 0.0106 - output_2_loss: 0.0146 - output_3_loss: 0.0389 - output_4_loss: 0.0337 - val_loss: 0.1594 - val_output_1_loss: 0.0109 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0433 - val_output_4_loss: 0.0367\n",
      "Epoch 182/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1446 - output_1_loss: 0.0106 - output_2_loss: 0.0143 - output_3_loss: 0.0388 - output_4_loss: 0.0323 - val_loss: 0.1588 - val_output_1_loss: 0.0111 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0429 - val_output_4_loss: 0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1422 - output_1_loss: 0.0097 - output_2_loss: 0.0141 - output_3_loss: 0.0383 - output_4_loss: 0.0316 - val_loss: 0.1573 - val_output_1_loss: 0.0108 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0424 - val_output_4_loss: 0.0359\n",
      "Epoch 184/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1417 - output_1_loss: 0.0098 - output_2_loss: 0.0147 - output_3_loss: 0.0392 - output_4_loss: 0.0317 - val_loss: 0.1577 - val_output_1_loss: 0.0106 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0428 - val_output_4_loss: 0.0362\n",
      "Epoch 185/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1433 - output_1_loss: 0.0102 - output_2_loss: 0.0143 - output_3_loss: 0.0386 - output_4_loss: 0.0325 - val_loss: 0.1653 - val_output_1_loss: 0.0130 - val_output_2_loss: 0.0185 - val_output_3_loss: 0.0426 - val_output_4_loss: 0.0413\n",
      "Epoch 186/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1411 - output_1_loss: 0.0097 - output_2_loss: 0.0141 - output_3_loss: 0.0382 - output_4_loss: 0.0315 - val_loss: 0.1572 - val_output_1_loss: 0.0113 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0423 - val_output_4_loss: 0.0360\n",
      "Epoch 187/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1412 - output_1_loss: 0.0096 - output_2_loss: 0.0141 - output_3_loss: 0.0383 - output_4_loss: 0.0320 - val_loss: 0.1571 - val_output_1_loss: 0.0108 - val_output_2_loss: 0.0179 - val_output_3_loss: 0.0420 - val_output_4_loss: 0.0368\n",
      "Epoch 188/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1442 - output_1_loss: 0.0104 - output_2_loss: 0.0144 - output_3_loss: 0.0384 - output_4_loss: 0.0339 - val_loss: 0.1553 - val_output_1_loss: 0.0101 - val_output_2_loss: 0.0177 - val_output_3_loss: 0.0423 - val_output_4_loss: 0.0358\n",
      "Epoch 189/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1401 - output_1_loss: 0.0095 - output_2_loss: 0.0140 - output_3_loss: 0.0378 - output_4_loss: 0.0315 - val_loss: 0.1546 - val_output_1_loss: 0.0101 - val_output_2_loss: 0.0177 - val_output_3_loss: 0.0417 - val_output_4_loss: 0.0358\n",
      "Epoch 190/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1386 - output_1_loss: 0.0092 - output_2_loss: 0.0138 - output_3_loss: 0.0376 - output_4_loss: 0.0307 - val_loss: 0.1529 - val_output_1_loss: 0.0098 - val_output_2_loss: 0.0174 - val_output_3_loss: 0.0415 - val_output_4_loss: 0.0351\n",
      "Epoch 191/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1382 - output_1_loss: 0.0092 - output_2_loss: 0.0137 - output_3_loss: 0.0375 - output_4_loss: 0.0308 - val_loss: 0.1536 - val_output_1_loss: 0.0105 - val_output_2_loss: 0.0178 - val_output_3_loss: 0.0413 - val_output_4_loss: 0.0351\n",
      "Epoch 192/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1380 - output_1_loss: 0.0092 - output_2_loss: 0.0141 - output_3_loss: 0.0378 - output_4_loss: 0.0310 - val_loss: 0.1569 - val_output_1_loss: 0.0111 - val_output_2_loss: 0.0178 - val_output_3_loss: 0.0414 - val_output_4_loss: 0.0378\n",
      "Epoch 193/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1382 - output_1_loss: 0.0091 - output_2_loss: 0.0138 - output_3_loss: 0.0376 - output_4_loss: 0.0315 - val_loss: 0.1606 - val_output_1_loss: 0.0130 - val_output_2_loss: 0.0175 - val_output_3_loss: 0.0444 - val_output_4_loss: 0.0371\n",
      "Epoch 194/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1369 - output_1_loss: 0.0089 - output_2_loss: 0.0136 - output_3_loss: 0.0372 - output_4_loss: 0.0306 - val_loss: 0.1516 - val_output_1_loss: 0.0096 - val_output_2_loss: 0.0174 - val_output_3_loss: 0.0409 - val_output_4_loss: 0.0353\n",
      "Epoch 195/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1374 - output_1_loss: 0.0092 - output_2_loss: 0.0137 - output_3_loss: 0.0370 - output_4_loss: 0.0311 - val_loss: 0.1520 - val_output_1_loss: 0.0099 - val_output_2_loss: 0.0175 - val_output_3_loss: 0.0412 - val_output_4_loss: 0.0350\n",
      "Epoch 196/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1374 - output_1_loss: 0.0092 - output_2_loss: 0.0137 - output_3_loss: 0.0371 - output_4_loss: 0.0311 - val_loss: 0.1511 - val_output_1_loss: 0.0096 - val_output_2_loss: 0.0173 - val_output_3_loss: 0.0410 - val_output_4_loss: 0.0351\n",
      "Epoch 197/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1368 - output_1_loss: 0.0092 - output_2_loss: 0.0137 - output_3_loss: 0.0371 - output_4_loss: 0.0312 - val_loss: 0.1509 - val_output_1_loss: 0.0095 - val_output_2_loss: 0.0172 - val_output_3_loss: 0.0409 - val_output_4_loss: 0.0352\n",
      "Epoch 198/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1352 - output_1_loss: 0.0087 - output_2_loss: 0.0135 - output_3_loss: 0.0369 - output_4_loss: 0.0303 - val_loss: 0.1513 - val_output_1_loss: 0.0095 - val_output_2_loss: 0.0176 - val_output_3_loss: 0.0412 - val_output_4_loss: 0.0351\n",
      "Epoch 199/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1341 - output_1_loss: 0.0086 - output_2_loss: 0.0135 - output_3_loss: 0.0368 - output_4_loss: 0.0300 - val_loss: 0.1497 - val_output_1_loss: 0.0092 - val_output_2_loss: 0.0174 - val_output_3_loss: 0.0408 - val_output_4_loss: 0.0346\n",
      "Epoch 200/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1353 - output_1_loss: 0.0088 - output_2_loss: 0.0138 - output_3_loss: 0.0370 - output_4_loss: 0.0308 - val_loss: 0.1526 - val_output_1_loss: 0.0112 - val_output_2_loss: 0.0174 - val_output_3_loss: 0.0407 - val_output_4_loss: 0.0358\n",
      "Epoch 201/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1337 - output_1_loss: 0.0085 - output_2_loss: 0.0134 - output_3_loss: 0.0364 - output_4_loss: 0.0300 - val_loss: 0.1527 - val_output_1_loss: 0.0100 - val_output_2_loss: 0.0173 - val_output_3_loss: 0.0433 - val_output_4_loss: 0.0349\n",
      "Epoch 202/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1338 - output_1_loss: 0.0085 - output_2_loss: 0.0134 - output_3_loss: 0.0365 - output_4_loss: 0.0303 - val_loss: 0.1586 - val_output_1_loss: 0.0108 - val_output_2_loss: 0.0191 - val_output_3_loss: 0.0406 - val_output_4_loss: 0.0409\n",
      "Epoch 203/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1341 - output_1_loss: 0.0085 - output_2_loss: 0.0135 - output_3_loss: 0.0363 - output_4_loss: 0.0308 - val_loss: 0.1470 - val_output_1_loss: 0.0089 - val_output_2_loss: 0.0171 - val_output_3_loss: 0.0402 - val_output_4_loss: 0.0337\n",
      "Epoch 204/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1325 - output_1_loss: 0.0083 - output_2_loss: 0.0133 - output_3_loss: 0.0363 - output_4_loss: 0.0298 - val_loss: 0.1484 - val_output_1_loss: 0.0093 - val_output_2_loss: 0.0172 - val_output_3_loss: 0.0402 - val_output_4_loss: 0.0347\n",
      "Epoch 205/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1319 - output_1_loss: 0.0084 - output_2_loss: 0.0138 - output_3_loss: 0.0367 - output_4_loss: 0.0299 - val_loss: 0.1492 - val_output_1_loss: 0.0098 - val_output_2_loss: 0.0174 - val_output_3_loss: 0.0403 - val_output_4_loss: 0.0348\n",
      "Epoch 206/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1320 - output_1_loss: 0.0083 - output_2_loss: 0.0139 - output_3_loss: 0.0367 - output_4_loss: 0.0301 - val_loss: 0.1504 - val_output_1_loss: 0.0092 - val_output_2_loss: 0.0176 - val_output_3_loss: 0.0407 - val_output_4_loss: 0.0362\n",
      "Epoch 207/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1323 - output_1_loss: 0.0083 - output_2_loss: 0.0133 - output_3_loss: 0.0359 - output_4_loss: 0.0304 - val_loss: 0.1562 - val_output_1_loss: 0.0104 - val_output_2_loss: 0.0185 - val_output_3_loss: 0.0398 - val_output_4_loss: 0.0409\n",
      "Epoch 208/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1322 - output_1_loss: 0.0084 - output_2_loss: 0.0133 - output_3_loss: 0.0361 - output_4_loss: 0.0303 - val_loss: 0.1459 - val_output_1_loss: 0.0085 - val_output_2_loss: 0.0171 - val_output_3_loss: 0.0396 - val_output_4_loss: 0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1314 - output_1_loss: 0.0082 - output_2_loss: 0.0132 - output_3_loss: 0.0357 - output_4_loss: 0.0300 - val_loss: 0.1498 - val_output_1_loss: 0.0124 - val_output_2_loss: 0.0168 - val_output_3_loss: 0.0410 - val_output_4_loss: 0.0334\n",
      "Epoch 210/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1299 - output_1_loss: 0.0080 - output_2_loss: 0.0130 - output_3_loss: 0.0355 - output_4_loss: 0.0292 - val_loss: 0.1440 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0167 - val_output_3_loss: 0.0396 - val_output_4_loss: 0.0328\n",
      "Epoch 211/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1292 - output_1_loss: 0.0077 - output_2_loss: 0.0130 - output_3_loss: 0.0353 - output_4_loss: 0.0292 - val_loss: 0.1528 - val_output_1_loss: 0.0095 - val_output_2_loss: 0.0176 - val_output_3_loss: 0.0395 - val_output_4_loss: 0.0404\n",
      "Epoch 212/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1299 - output_1_loss: 0.0079 - output_2_loss: 0.0130 - output_3_loss: 0.0354 - output_4_loss: 0.0296 - val_loss: 0.1441 - val_output_1_loss: 0.0086 - val_output_2_loss: 0.0169 - val_output_3_loss: 0.0394 - val_output_4_loss: 0.0334\n",
      "Epoch 213/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1356 - output_1_loss: 0.0092 - output_2_loss: 0.0138 - output_3_loss: 0.0359 - output_4_loss: 0.0332 - val_loss: 0.1479 - val_output_1_loss: 0.0098 - val_output_2_loss: 0.0168 - val_output_3_loss: 0.0415 - val_output_4_loss: 0.0340\n",
      "Epoch 214/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1317 - output_1_loss: 0.0084 - output_2_loss: 0.0132 - output_3_loss: 0.0354 - output_4_loss: 0.0310 - val_loss: 0.1429 - val_output_1_loss: 0.0083 - val_output_2_loss: 0.0166 - val_output_3_loss: 0.0397 - val_output_4_loss: 0.0326\n",
      "Epoch 215/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1283 - output_1_loss: 0.0078 - output_2_loss: 0.0129 - output_3_loss: 0.0350 - output_4_loss: 0.0290 - val_loss: 0.1433 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0389 - val_output_4_loss: 0.0336\n",
      "Epoch 216/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1307 - output_1_loss: 0.0087 - output_2_loss: 0.0131 - output_3_loss: 0.0356 - output_4_loss: 0.0298 - val_loss: 0.1630 - val_output_1_loss: 0.0151 - val_output_2_loss: 0.0186 - val_output_3_loss: 0.0429 - val_output_4_loss: 0.0410\n",
      "Epoch 217/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1315 - output_1_loss: 0.0084 - output_2_loss: 0.0133 - output_3_loss: 0.0351 - output_4_loss: 0.0314 - val_loss: 0.1411 - val_output_1_loss: 0.0084 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0385 - val_output_4_loss: 0.0324\n",
      "Epoch 218/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1264 - output_1_loss: 0.0074 - output_2_loss: 0.0127 - output_3_loss: 0.0346 - output_4_loss: 0.0284 - val_loss: 0.1404 - val_output_1_loss: 0.0080 - val_output_2_loss: 0.0164 - val_output_3_loss: 0.0384 - val_output_4_loss: 0.0323\n",
      "Epoch 219/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1263 - output_1_loss: 0.0075 - output_2_loss: 0.0127 - output_3_loss: 0.0348 - output_4_loss: 0.0286 - val_loss: 0.1416 - val_output_1_loss: 0.0081 - val_output_2_loss: 0.0168 - val_output_3_loss: 0.0384 - val_output_4_loss: 0.0333\n",
      "Epoch 220/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1260 - output_1_loss: 0.0074 - output_2_loss: 0.0127 - output_3_loss: 0.0346 - output_4_loss: 0.0285 - val_loss: 0.1409 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0391 - val_output_4_loss: 0.0322\n",
      "Epoch 221/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1262 - output_1_loss: 0.0074 - output_2_loss: 0.0127 - output_3_loss: 0.0344 - output_4_loss: 0.0287 - val_loss: 0.1410 - val_output_1_loss: 0.0081 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0385 - val_output_4_loss: 0.0331\n",
      "Epoch 222/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1257 - output_1_loss: 0.0073 - output_2_loss: 0.0127 - output_3_loss: 0.0343 - output_4_loss: 0.0286 - val_loss: 0.1413 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0166 - val_output_3_loss: 0.0386 - val_output_4_loss: 0.0328\n",
      "Epoch 223/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1257 - output_1_loss: 0.0074 - output_2_loss: 0.0127 - output_3_loss: 0.0344 - output_4_loss: 0.0288 - val_loss: 0.1398 - val_output_1_loss: 0.0083 - val_output_2_loss: 0.0164 - val_output_3_loss: 0.0383 - val_output_4_loss: 0.0322\n",
      "Epoch 224/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1261 - output_1_loss: 0.0075 - output_2_loss: 0.0127 - output_3_loss: 0.0344 - output_4_loss: 0.0293 - val_loss: 0.1459 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0171 - val_output_3_loss: 0.0380 - val_output_4_loss: 0.0377\n",
      "Epoch 225/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1278 - output_1_loss: 0.0079 - output_2_loss: 0.0132 - output_3_loss: 0.0348 - output_4_loss: 0.0300 - val_loss: 0.1412 - val_output_1_loss: 0.0085 - val_output_2_loss: 0.0164 - val_output_3_loss: 0.0402 - val_output_4_loss: 0.0317\n",
      "Epoch 226/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1255 - output_1_loss: 0.0075 - output_2_loss: 0.0127 - output_3_loss: 0.0341 - output_4_loss: 0.0290 - val_loss: 0.1412 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0166 - val_output_3_loss: 0.0381 - val_output_4_loss: 0.0341\n",
      "Epoch 227/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1246 - output_1_loss: 0.0075 - output_2_loss: 0.0129 - output_3_loss: 0.0346 - output_4_loss: 0.0285 - val_loss: 0.1392 - val_output_1_loss: 0.0079 - val_output_2_loss: 0.0162 - val_output_3_loss: 0.0397 - val_output_4_loss: 0.0313\n",
      "Epoch 228/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1239 - output_1_loss: 0.0072 - output_2_loss: 0.0126 - output_3_loss: 0.0341 - output_4_loss: 0.0282 - val_loss: 0.1400 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0163 - val_output_3_loss: 0.0390 - val_output_4_loss: 0.0326\n",
      "Epoch 229/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1234 - output_1_loss: 0.0070 - output_2_loss: 0.0125 - output_3_loss: 0.0338 - output_4_loss: 0.0282 - val_loss: 0.1371 - val_output_1_loss: 0.0077 - val_output_2_loss: 0.0163 - val_output_3_loss: 0.0376 - val_output_4_loss: 0.0317\n",
      "Epoch 230/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1224 - output_1_loss: 0.0069 - output_2_loss: 0.0125 - output_3_loss: 0.0339 - output_4_loss: 0.0278 - val_loss: 0.1372 - val_output_1_loss: 0.0078 - val_output_2_loss: 0.0162 - val_output_3_loss: 0.0376 - val_output_4_loss: 0.0319\n",
      "Epoch 231/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1229 - output_1_loss: 0.0071 - output_2_loss: 0.0124 - output_3_loss: 0.0337 - output_4_loss: 0.0282 - val_loss: 0.1395 - val_output_1_loss: 0.0089 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0377 - val_output_4_loss: 0.0332\n",
      "Epoch 232/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1250 - output_1_loss: 0.0073 - output_2_loss: 0.0128 - output_3_loss: 0.0336 - output_4_loss: 0.0299 - val_loss: 0.1381 - val_output_1_loss: 0.0076 - val_output_2_loss: 0.0163 - val_output_3_loss: 0.0376 - val_output_4_loss: 0.0332\n",
      "Epoch 233/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1229 - output_1_loss: 0.0071 - output_2_loss: 0.0124 - output_3_loss: 0.0336 - output_4_loss: 0.0285 - val_loss: 0.1402 - val_output_1_loss: 0.0080 - val_output_2_loss: 0.0167 - val_output_3_loss: 0.0382 - val_output_4_loss: 0.0339\n",
      "Epoch 234/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1219 - output_1_loss: 0.0068 - output_2_loss: 0.0123 - output_3_loss: 0.0333 - output_4_loss: 0.0281 - val_loss: 0.1352 - val_output_1_loss: 0.0077 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0369 - val_output_4_loss: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1211 - output_1_loss: 0.0067 - output_2_loss: 0.0123 - output_3_loss: 0.0332 - output_4_loss: 0.0278 - val_loss: 0.1354 - val_output_1_loss: 0.0073 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0381 - val_output_4_loss: 0.0308\n",
      "Epoch 236/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1208 - output_1_loss: 0.0067 - output_2_loss: 0.0122 - output_3_loss: 0.0332 - output_4_loss: 0.0277 - val_loss: 0.1363 - val_output_1_loss: 0.0078 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0368 - val_output_4_loss: 0.0328\n",
      "Epoch 237/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1221 - output_1_loss: 0.0071 - output_2_loss: 0.0126 - output_3_loss: 0.0336 - output_4_loss: 0.0285 - val_loss: 0.1395 - val_output_1_loss: 0.0096 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0380 - val_output_4_loss: 0.0330\n",
      "Epoch 238/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1205 - output_1_loss: 0.0067 - output_2_loss: 0.0122 - output_3_loss: 0.0330 - output_4_loss: 0.0277 - val_loss: 0.1356 - val_output_1_loss: 0.0077 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0377 - val_output_4_loss: 0.0314\n",
      "Epoch 239/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1202 - output_1_loss: 0.0067 - output_2_loss: 0.0122 - output_3_loss: 0.0330 - output_4_loss: 0.0275 - val_loss: 0.1367 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0393 - val_output_4_loss: 0.0304\n",
      "Epoch 240/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1198 - output_1_loss: 0.0066 - output_2_loss: 0.0122 - output_3_loss: 0.0329 - output_4_loss: 0.0274 - val_loss: 0.1347 - val_output_1_loss: 0.0075 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0367 - val_output_4_loss: 0.0317\n",
      "Epoch 241/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1220 - output_1_loss: 0.0072 - output_2_loss: 0.0124 - output_3_loss: 0.0330 - output_4_loss: 0.0288 - val_loss: 0.1335 - val_output_1_loss: 0.0073 - val_output_2_loss: 0.0157 - val_output_3_loss: 0.0369 - val_output_4_loss: 0.0311\n",
      "Epoch 242/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1194 - output_1_loss: 0.0065 - output_2_loss: 0.0122 - output_3_loss: 0.0327 - output_4_loss: 0.0276 - val_loss: 0.1322 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0158 - val_output_3_loss: 0.0364 - val_output_4_loss: 0.0307\n",
      "Epoch 243/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1192 - output_1_loss: 0.0066 - output_2_loss: 0.0122 - output_3_loss: 0.0326 - output_4_loss: 0.0276 - val_loss: 0.1451 - val_output_1_loss: 0.0097 - val_output_2_loss: 0.0178 - val_output_3_loss: 0.0371 - val_output_4_loss: 0.0383\n",
      "Epoch 244/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1229 - output_1_loss: 0.0074 - output_2_loss: 0.0125 - output_3_loss: 0.0327 - output_4_loss: 0.0299 - val_loss: 0.1358 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0381 - val_output_4_loss: 0.0315\n",
      "Epoch 245/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1184 - output_1_loss: 0.0064 - output_2_loss: 0.0121 - output_3_loss: 0.0328 - output_4_loss: 0.0276 - val_loss: 0.1336 - val_output_1_loss: 0.0073 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0365 - val_output_4_loss: 0.0317\n",
      "Epoch 246/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1197 - output_1_loss: 0.0068 - output_2_loss: 0.0122 - output_3_loss: 0.0325 - output_4_loss: 0.0283 - val_loss: 0.1314 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0156 - val_output_3_loss: 0.0367 - val_output_4_loss: 0.0303\n",
      "Epoch 247/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1183 - output_1_loss: 0.0066 - output_2_loss: 0.0122 - output_3_loss: 0.0329 - output_4_loss: 0.0274 - val_loss: 0.1302 - val_output_1_loss: 0.0067 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0363 - val_output_4_loss: 0.0299\n",
      "Epoch 248/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1170 - output_1_loss: 0.0063 - output_2_loss: 0.0119 - output_3_loss: 0.0323 - output_4_loss: 0.0267 - val_loss: 0.1320 - val_output_1_loss: 0.0071 - val_output_2_loss: 0.0158 - val_output_3_loss: 0.0360 - val_output_4_loss: 0.0314\n",
      "Epoch 249/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1183 - output_1_loss: 0.0066 - output_2_loss: 0.0124 - output_3_loss: 0.0328 - output_4_loss: 0.0280 - val_loss: 0.1332 - val_output_1_loss: 0.0073 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0360 - val_output_4_loss: 0.0324\n",
      "Epoch 250/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1199 - output_1_loss: 0.0070 - output_2_loss: 0.0122 - output_3_loss: 0.0325 - output_4_loss: 0.0287 - val_loss: 0.1328 - val_output_1_loss: 0.0086 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0361 - val_output_4_loss: 0.0312\n",
      "Epoch 251/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1203 - output_1_loss: 0.0070 - output_2_loss: 0.0123 - output_3_loss: 0.0324 - output_4_loss: 0.0292 - val_loss: 0.1330 - val_output_1_loss: 0.0076 - val_output_2_loss: 0.0156 - val_output_3_loss: 0.0367 - val_output_4_loss: 0.0317\n",
      "Epoch 252/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1172 - output_1_loss: 0.0064 - output_2_loss: 0.0120 - output_3_loss: 0.0324 - output_4_loss: 0.0275 - val_loss: 0.1306 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0362 - val_output_4_loss: 0.0307\n",
      "Epoch 253/300\n",
      "8906/8906 [==============================] - 1s 89us/sample - loss: 0.1166 - output_1_loss: 0.0063 - output_2_loss: 0.0119 - output_3_loss: 0.0322 - output_4_loss: 0.0272 - val_loss: 0.1353 - val_output_1_loss: 0.0089 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0364 - val_output_4_loss: 0.0327\n",
      "Epoch 254/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1171 - output_1_loss: 0.0066 - output_2_loss: 0.0120 - output_3_loss: 0.0323 - output_4_loss: 0.0273 - val_loss: 0.1322 - val_output_1_loss: 0.0079 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0370 - val_output_4_loss: 0.0307\n",
      "Epoch 255/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1155 - output_1_loss: 0.0062 - output_2_loss: 0.0118 - output_3_loss: 0.0318 - output_4_loss: 0.0267 - val_loss: 0.1312 - val_output_1_loss: 0.0080 - val_output_2_loss: 0.0157 - val_output_3_loss: 0.0357 - val_output_4_loss: 0.0308\n",
      "Epoch 256/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1149 - output_1_loss: 0.0060 - output_2_loss: 0.0118 - output_3_loss: 0.0317 - output_4_loss: 0.0266 - val_loss: 0.1280 - val_output_1_loss: 0.0067 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0354 - val_output_4_loss: 0.0298\n",
      "Epoch 257/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1145 - output_1_loss: 0.0060 - output_2_loss: 0.0118 - output_3_loss: 0.0320 - output_4_loss: 0.0265 - val_loss: 0.1321 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0165 - val_output_3_loss: 0.0358 - val_output_4_loss: 0.0320\n",
      "Epoch 258/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1174 - output_1_loss: 0.0067 - output_2_loss: 0.0120 - output_3_loss: 0.0318 - output_4_loss: 0.0282 - val_loss: 0.1417 - val_output_1_loss: 0.0108 - val_output_2_loss: 0.0158 - val_output_3_loss: 0.0357 - val_output_4_loss: 0.0390\n",
      "Epoch 259/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1158 - output_1_loss: 0.0064 - output_2_loss: 0.0118 - output_3_loss: 0.0315 - output_4_loss: 0.0275 - val_loss: 0.1347 - val_output_1_loss: 0.0086 - val_output_2_loss: 0.0160 - val_output_3_loss: 0.0364 - val_output_4_loss: 0.0331\n",
      "Epoch 260/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1158 - output_1_loss: 0.0063 - output_2_loss: 0.0119 - output_3_loss: 0.0316 - output_4_loss: 0.0274 - val_loss: 0.1312 - val_output_1_loss: 0.0074 - val_output_2_loss: 0.0157 - val_output_3_loss: 0.0351 - val_output_4_loss: 0.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1187 - output_1_loss: 0.0072 - output_2_loss: 0.0122 - output_3_loss: 0.0322 - output_4_loss: 0.0287 - val_loss: 0.1277 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0350 - val_output_4_loss: 0.0302\n",
      "Epoch 262/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1134 - output_1_loss: 0.0058 - output_2_loss: 0.0116 - output_3_loss: 0.0313 - output_4_loss: 0.0262 - val_loss: 0.1263 - val_output_1_loss: 0.0064 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0350 - val_output_4_loss: 0.0295\n",
      "Epoch 263/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1142 - output_1_loss: 0.0060 - output_2_loss: 0.0120 - output_3_loss: 0.0316 - output_4_loss: 0.0270 - val_loss: 0.1260 - val_output_1_loss: 0.0064 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0294\n",
      "Epoch 264/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1125 - output_1_loss: 0.0057 - output_2_loss: 0.0115 - output_3_loss: 0.0311 - output_4_loss: 0.0260 - val_loss: 0.1276 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0304\n",
      "Epoch 265/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1144 - output_1_loss: 0.0063 - output_2_loss: 0.0117 - output_3_loss: 0.0313 - output_4_loss: 0.0271 - val_loss: 0.1266 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0150 - val_output_3_loss: 0.0352 - val_output_4_loss: 0.0293\n",
      "Epoch 266/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1133 - output_1_loss: 0.0060 - output_2_loss: 0.0116 - output_3_loss: 0.0312 - output_4_loss: 0.0266 - val_loss: 0.1271 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0303\n",
      "Epoch 267/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1152 - output_1_loss: 0.0063 - output_2_loss: 0.0119 - output_3_loss: 0.0312 - output_4_loss: 0.0281 - val_loss: 0.1298 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0331\n",
      "Epoch 268/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1179 - output_1_loss: 0.0068 - output_2_loss: 0.0121 - output_3_loss: 0.0313 - output_4_loss: 0.0300 - val_loss: 0.1289 - val_output_1_loss: 0.0072 - val_output_2_loss: 0.0153 - val_output_3_loss: 0.0353 - val_output_4_loss: 0.0313\n",
      "Epoch 269/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1125 - output_1_loss: 0.0059 - output_2_loss: 0.0115 - output_3_loss: 0.0310 - output_4_loss: 0.0263 - val_loss: 0.1247 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0345 - val_output_4_loss: 0.0292\n",
      "Epoch 270/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1114 - output_1_loss: 0.0057 - output_2_loss: 0.0114 - output_3_loss: 0.0309 - output_4_loss: 0.0260 - val_loss: 0.1258 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0343 - val_output_4_loss: 0.0299\n",
      "Epoch 271/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1112 - output_1_loss: 0.0057 - output_2_loss: 0.0114 - output_3_loss: 0.0306 - output_4_loss: 0.0260 - val_loss: 0.1247 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0344 - val_output_4_loss: 0.0294\n",
      "Epoch 272/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1123 - output_1_loss: 0.0060 - output_2_loss: 0.0115 - output_3_loss: 0.0308 - output_4_loss: 0.0267 - val_loss: 0.1284 - val_output_1_loss: 0.0091 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0300\n",
      "Epoch 273/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1147 - output_1_loss: 0.0065 - output_2_loss: 0.0118 - output_3_loss: 0.0308 - output_4_loss: 0.0282 - val_loss: 0.1264 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0152 - val_output_3_loss: 0.0345 - val_output_4_loss: 0.0305\n",
      "Epoch 274/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1121 - output_1_loss: 0.0059 - output_2_loss: 0.0116 - output_3_loss: 0.0307 - output_4_loss: 0.0269 - val_loss: 0.1286 - val_output_1_loss: 0.0075 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0343 - val_output_4_loss: 0.0329\n",
      "Epoch 275/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1149 - output_1_loss: 0.0065 - output_2_loss: 0.0117 - output_3_loss: 0.0308 - output_4_loss: 0.0286 - val_loss: 0.1312 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0360 - val_output_4_loss: 0.0319\n",
      "Epoch 276/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1111 - output_1_loss: 0.0058 - output_2_loss: 0.0114 - output_3_loss: 0.0306 - output_4_loss: 0.0263 - val_loss: 0.1230 - val_output_1_loss: 0.0060 - val_output_2_loss: 0.0148 - val_output_3_loss: 0.0342 - val_output_4_loss: 0.0290\n",
      "Epoch 277/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1111 - output_1_loss: 0.0058 - output_2_loss: 0.0115 - output_3_loss: 0.0305 - output_4_loss: 0.0266 - val_loss: 0.1253 - val_output_1_loss: 0.0067 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0348 - val_output_4_loss: 0.0301\n",
      "Epoch 278/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1101 - output_1_loss: 0.0056 - output_2_loss: 0.0114 - output_3_loss: 0.0305 - output_4_loss: 0.0260 - val_loss: 0.1265 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0151 - val_output_3_loss: 0.0360 - val_output_4_loss: 0.0298\n",
      "Epoch 279/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1105 - output_1_loss: 0.0058 - output_2_loss: 0.0113 - output_3_loss: 0.0306 - output_4_loss: 0.0261 - val_loss: 0.1242 - val_output_1_loss: 0.0064 - val_output_2_loss: 0.0150 - val_output_3_loss: 0.0351 - val_output_4_loss: 0.0289\n",
      "Epoch 280/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1099 - output_1_loss: 0.0056 - output_2_loss: 0.0113 - output_3_loss: 0.0304 - output_4_loss: 0.0260 - val_loss: 0.1235 - val_output_1_loss: 0.0061 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0342 - val_output_4_loss: 0.0297\n",
      "Epoch 281/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1100 - output_1_loss: 0.0057 - output_2_loss: 0.0113 - output_3_loss: 0.0303 - output_4_loss: 0.0261 - val_loss: 0.1265 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0356 - val_output_4_loss: 0.0291\n",
      "Epoch 282/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1092 - output_1_loss: 0.0057 - output_2_loss: 0.0115 - output_3_loss: 0.0307 - output_4_loss: 0.0256 - val_loss: 0.1225 - val_output_1_loss: 0.0062 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0337 - val_output_4_loss: 0.0295\n",
      "Epoch 283/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1090 - output_1_loss: 0.0055 - output_2_loss: 0.0119 - output_3_loss: 0.0308 - output_4_loss: 0.0259 - val_loss: 0.1214 - val_output_1_loss: 0.0058 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0338 - val_output_4_loss: 0.0288\n",
      "Epoch 284/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1099 - output_1_loss: 0.0057 - output_2_loss: 0.0117 - output_3_loss: 0.0305 - output_4_loss: 0.0267 - val_loss: 0.1274 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0159 - val_output_3_loss: 0.0353 - val_output_4_loss: 0.0313\n",
      "Epoch 285/300\n",
      "8906/8906 [==============================] - 1s 93us/sample - loss: 0.1103 - output_1_loss: 0.0058 - output_2_loss: 0.0118 - output_3_loss: 0.0307 - output_4_loss: 0.0266 - val_loss: 0.1270 - val_output_1_loss: 0.0071 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0359 - val_output_4_loss: 0.0302\n",
      "Epoch 286/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1116 - output_1_loss: 0.0063 - output_2_loss: 0.0116 - output_3_loss: 0.0305 - output_4_loss: 0.0273 - val_loss: 0.1223 - val_output_1_loss: 0.0064 - val_output_2_loss: 0.0148 - val_output_3_loss: 0.0337 - val_output_4_loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/300\n",
      "8906/8906 [==============================] - 1s 90us/sample - loss: 0.1082 - output_1_loss: 0.0055 - output_2_loss: 0.0111 - output_3_loss: 0.0299 - output_4_loss: 0.0256 - val_loss: 0.1377 - val_output_1_loss: 0.0091 - val_output_2_loss: 0.0163 - val_output_3_loss: 0.0335 - val_output_4_loss: 0.0407\n",
      "Epoch 288/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1106 - output_1_loss: 0.0061 - output_2_loss: 0.0116 - output_3_loss: 0.0305 - output_4_loss: 0.0276 - val_loss: 0.1225 - val_output_1_loss: 0.0064 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0339 - val_output_4_loss: 0.0296\n",
      "Epoch 289/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1108 - output_1_loss: 0.0062 - output_2_loss: 0.0114 - output_3_loss: 0.0302 - output_4_loss: 0.0273 - val_loss: 0.1226 - val_output_1_loss: 0.0067 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0337 - val_output_4_loss: 0.0298\n",
      "Epoch 290/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1114 - output_1_loss: 0.0062 - output_2_loss: 0.0115 - output_3_loss: 0.0302 - output_4_loss: 0.0277 - val_loss: 0.1212 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0335 - val_output_4_loss: 0.0288\n",
      "Epoch 291/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1072 - output_1_loss: 0.0054 - output_2_loss: 0.0110 - output_3_loss: 0.0296 - output_4_loss: 0.0254 - val_loss: 0.1202 - val_output_1_loss: 0.0060 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0334 - val_output_4_loss: 0.0286\n",
      "Epoch 292/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1076 - output_1_loss: 0.0055 - output_2_loss: 0.0111 - output_3_loss: 0.0296 - output_4_loss: 0.0258 - val_loss: 0.1243 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0150 - val_output_3_loss: 0.0331 - val_output_4_loss: 0.0318\n",
      "Epoch 293/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1075 - output_1_loss: 0.0055 - output_2_loss: 0.0111 - output_3_loss: 0.0296 - output_4_loss: 0.0257 - val_loss: 0.1196 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0144 - val_output_3_loss: 0.0332 - val_output_4_loss: 0.0287\n",
      "Epoch 294/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1068 - output_1_loss: 0.0053 - output_2_loss: 0.0111 - output_3_loss: 0.0295 - output_4_loss: 0.0255 - val_loss: 0.1187 - val_output_1_loss: 0.0057 - val_output_2_loss: 0.0145 - val_output_3_loss: 0.0331 - val_output_4_loss: 0.0281\n",
      "Epoch 295/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1063 - output_1_loss: 0.0053 - output_2_loss: 0.0110 - output_3_loss: 0.0294 - output_4_loss: 0.0253 - val_loss: 0.1203 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0144 - val_output_3_loss: 0.0334 - val_output_4_loss: 0.0287\n",
      "Epoch 296/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1059 - output_1_loss: 0.0052 - output_2_loss: 0.0110 - output_3_loss: 0.0294 - output_4_loss: 0.0251 - val_loss: 0.1204 - val_output_1_loss: 0.0066 - val_output_2_loss: 0.0145 - val_output_3_loss: 0.0332 - val_output_4_loss: 0.0289\n",
      "Epoch 297/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1078 - output_1_loss: 0.0056 - output_2_loss: 0.0112 - output_3_loss: 0.0295 - output_4_loss: 0.0263 - val_loss: 0.1249 - val_output_1_loss: 0.0074 - val_output_2_loss: 0.0149 - val_output_3_loss: 0.0331 - val_output_4_loss: 0.0324\n",
      "Epoch 298/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1074 - output_1_loss: 0.0055 - output_2_loss: 0.0112 - output_3_loss: 0.0294 - output_4_loss: 0.0262 - val_loss: 0.1197 - val_output_1_loss: 0.0066 - val_output_2_loss: 0.0145 - val_output_3_loss: 0.0332 - val_output_4_loss: 0.0284\n",
      "Epoch 299/300\n",
      "8906/8906 [==============================] - 1s 91us/sample - loss: 0.1056 - output_1_loss: 0.0052 - output_2_loss: 0.0110 - output_3_loss: 0.0292 - output_4_loss: 0.0252 - val_loss: 0.1187 - val_output_1_loss: 0.0061 - val_output_2_loss: 0.0147 - val_output_3_loss: 0.0328 - val_output_4_loss: 0.0281\n",
      "Epoch 300/300\n",
      "8906/8906 [==============================] - 1s 92us/sample - loss: 0.1052 - output_1_loss: 0.0052 - output_2_loss: 0.0109 - output_3_loss: 0.0291 - output_4_loss: 0.0251 - val_loss: 0.1186 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0144 - val_output_3_loss: 0.0327 - val_output_4_loss: 0.0293\n"
     ]
    }
   ],
   "source": [
    "# Set up validation data for full model\n",
    "val_zeros = np.zeros(data_val_u.shape)\n",
    "val_data = [(data_val_u, data_val_f), \n",
    "            (data_val_u, data_val_f, data_val_f, data_val_u)]\n",
    "\n",
    "# Now set the model to train all aspects (including operator L)\n",
    "model.train_autoencoders_only=False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=loss_fns,\n",
    "              optimizer=optimizer(learning_rate=lr, **optimizer_opts))\n",
    "\n",
    "hist = model.fit(x=[data_train_u, data_train_f],\n",
    "                 y=[data_train_u, data_train_f, data_train_f, data_train_u],\n",
    "                 validation_data=val_data,\n",
    "                 #callbacks=cbs,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=full_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3. Train 20 initial models, autoencoders-only then full model\n",
    "## create a variety of different models with randomized learning rates\n",
    "#num_init_models = 3\n",
    "#models = []\n",
    "#\n",
    "## Set the loss functions\n",
    "#loss_fns = 4*[NMSE()]\n",
    "#\n",
    "## Set up validation data for autoencoders-only\n",
    "#val_zeros = np.zeros(data_val_u.shape)\n",
    "#val_data = [(data_val_u, data_val_f), \n",
    "#            (data_val_u, data_val_f, val_zeros, val_zeros)]\n",
    "#\n",
    "## Compute number of epochs to train\n",
    "#aec_epochs = int(aec_only_time*60*2)  # about 2 epochs/sec\n",
    "#full_epochs = int(full_model_time*60)  # about 1 epoch/sec\n",
    "#\n",
    "#aec_epochs = 1\n",
    "#full_epochs = 3\n",
    "#\n",
    "## For loop for generating the different models\n",
    "#for i in range(num_init_models):\n",
    "#    # Randomly selected learning rate\n",
    "#    lr = 10**(-r.uniform(3, 6))\n",
    "#    \n",
    "#    # Create a model, initially only to train autoencoders!\n",
    "#    model = AbstractArchitecture(**architecture_config,\n",
    "#                                 train_autoencoders_only=True)\n",
    "#    # Compile the model\n",
    "#    model.compile(loss=loss_fns,\n",
    "#                  optimizer=optimizer(learning_rate=lr, **optimizer_opts))\n",
    "#\n",
    "#    # Fit the model\n",
    "#    train_zeros = np.zeros(data_train_u.shape)\n",
    "#    aec_hist = model.fit(x=[data_train_u, data_train_f],\n",
    "#                         y=[data_train_u, data_train_f, train_zeros, train_zeros],\n",
    "#                         validation_data=val_data,\n",
    "#                         callbacks=cbs,\n",
    "#                         batch_size=batch_size,\n",
    "#                         epochs=aec_epochs)\n",
    "#    \n",
    "#    # Now set the model to train all aspects (including operator L)\n",
    "#    model.train_autoencoders_only=False\n",
    "#    \n",
    "#    hist = model.fit(x=[data_train_u, data_train_f],\n",
    "#                     y=[data_train_u, data_train_f, data_train_f, data_train_u],\n",
    "#                     validation_data=val_data,\n",
    "#                     callbacks=cbs,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=full_epochs)\n",
    "#    \n",
    "#    # Append the results to the model list\n",
    "#    models.append((model, hist, lr, aec_hist))\n",
    "#\n",
    "#\n",
    "### Step 4. Select the best model from the 20 autoencoder-only results\n",
    "#\n",
    "## List of learning rates and final losses, losses averaged over final 5 epochs\n",
    "#lrs = []\n",
    "#final_losses = []\n",
    "#\n",
    "#for i in range(num_init_models):\n",
    "#    _, hist, lr, _ = models[i]\n",
    "#    final_losses.append(np.mean(hist.history['loss'][-5:]))\n",
    "#    lrs.append(lr)\n",
    "#\n",
    "#\n",
    "## Select the best model, based on the minimum in the final losses\n",
    "#best_model_idc = np.argmin(final_losses)\n",
    "#best_model = models[best_model_idc][0]\n",
    "#best_lr = lrs[best_model_idc]\n",
    "#\n",
    "## Save weights for the best model\n",
    "#model_weight_path = \"./data/{}_best_aec_model_weights.tf\".format(expt_name)\n",
    "#best_model.save_weights(model_weight_path)\n",
    "#\n",
    "#\n",
    "### Optional Step: Plot learning rates vs autoencoder-only losses\n",
    "##plt.figure()\n",
    "##plt.loglog(lrs, final_losses, 'o')\n",
    "##plt.ylabel(\"Final Loss\")\n",
    "##plt.xlabel(\"Adam Learning Rate\")\n",
    "##plt.show()\n",
    "#\n",
    "#\n",
    "#\n",
    "### Step 5. Set up the full architecture run!!\n",
    "#\n",
    "## Set up validation data, loss functions, and number of epochs\n",
    "#val_data = [(data_val_u, data_val_f), \n",
    "#            (data_val_u, data_val_f, data_val_f, data_val_u)]\n",
    "#loss_fns = 4*[NMSE()]\n",
    "#\n",
    "## Compute number of epochs to fit full model\n",
    "## about 1 epoch/sec in this step\n",
    "#final_epochs = int(final_model_train_hrs*60*60) # 1 epoch/sec\n",
    "#final_epochs = 3\n",
    "#\n",
    "## Instantiate the new model\n",
    "#full_model = AbstractArchitecture(**architecture_config,\n",
    "#                                  train_autoencoders_only=False)\n",
    "#\n",
    "## Load the weights\n",
    "#full_model.load_weights(model_weight_path)\n",
    "#full_model.compile(loss=loss_fns,\n",
    "#                   optimizer=optimizer(learning_rate=best_lr))\n",
    "#\n",
    "## Continue training the (now full) model\n",
    "#hist = full_model.fit(x=[data_train_u, data_train_f],\n",
    "#                      y=[data_train_u, data_train_f, data_train_f, data_train_u],\n",
    "#                      validation_data=val_data,\n",
    "#                      callbacks=cbs,\n",
    "#                      batch_size=batch_size,\n",
    "#                      epochs=full_epochs)\n",
    "#\n",
    "## And save the final results!\n",
    "#full_model_weights_path = \"./data/{}_final_model_weights.tf\".format(expt_name)\n",
    "#full_model.save_weights(full_model_weights_path)\n",
    "#\n",
    "## Look at learning rates vs AEC-only and full-model losses\n",
    "#lrs = []\n",
    "#full_losses = []\n",
    "#aec_losses = []\n",
    "#for i in range(num_init_models):\n",
    "#    _, full_hist, lr, aec_hist = models[i]\n",
    "#    full_losses.append(np.mean(full_hist.history['loss'][-3:]))\n",
    "#    aec_losses.append(np.mean(aec_hist.history['loss'][-3:]))\n",
    "#    lrs.append(lr)\n",
    "#    \n",
    "### Optional Step: Plot learning rates vs autoencoder-only losses\n",
    "##plt.figure()\n",
    "##plt.loglog(lrs, full_losses, 'o', label=\"Full Models\")\n",
    "##plt.loglog(lrs, aec_losses, 'o', label=\"AEC Only\")\n",
    "##plt.ylabel(\"Final Loss\")\n",
    "##plt.xlabel(\"Adam Learning Rate\")\n",
    "##plt.legend()\n",
    "##plt.show()\n",
    "#\n",
    "##min(aec_losses), min(full_losses)\n",
    "#\n",
    "##\n",
    "#\n",
    "### Doubled down on JSON for saving the data, since it is a uniform format!!\n",
    "#\n",
    "## Get the dictionary containing each metric and the loss for each epoch\n",
    "#history_dict = hist.history.copy()\n",
    "#\n",
    "#for key in history_dict:\n",
    "#    history_dict[key] = [val.astype(np.float64) for val in history_dict[key]]\n",
    "#    \n",
    "## And now dump it\n",
    "#hist_filepath = \"./data/{}_model_history.json\".format(expt_name)\n",
    "#json.dump(history_dict, open(hist_filepath, 'w'))\n",
    "#\n",
    "## Also dump the full_losses, aec_losses, and learning rates\n",
    "#initial_training = {'aec_only_loss': aec_losses,\n",
    "#                    'full_init_loss': full_losses,\n",
    "#                    'learn_rates': lrs}\n",
    "#init_train_filepath = \"./data/{}_initial_train.json\".format(expt_name)\n",
    "#json.dump(initial_training, open(init_train_filepath, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_prediction(model, 144, data_val_u, data_val_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeVyU1f7A8c/DsA8uKIor4oa7AmKQWpqahhdz10xN22zX9m5dTcuyvF1t0/ZSE5fSMi9cJ6zc+rmgIrhlmLiGiqKCMMAwy/n98bAIDIvIMAOc9+s1r+BZzyTwneec7/keRQiBJEmSJDkaJ3s3QJIkSZKskQFKkiRJckgyQEmSJEkOSQYoSZIkySHJACVJkiQ5JGd7N6A0Pj4+wt/f397NkCRJkmwsLi4uVQjRpPh2hw1Q/v7+7N+/397NkCRJkmxMUZQz1rbLLj5JkiTJIckAJUmSJDkkGaAkSZIkhyQDlCRJkuSQbBqgFEVprSjKekVR0hVFua4oyo+KovjZ8p6SJElS7WCzAKUoiiewBegMTAOmAh2BrYqiaG11X0mSJKl2sGWa+aNAO6CTEOIEgKIoh4C/gMeAxTa8tyRJVSA9PZ3U1FRyc3Pt3RSphtFoNNSrV49GjRrh5uZWqWvYMkDdC+zJD04AQohTiqLsBEYiA5QkObScnBxSUlJo1aoVHh4eKIpi7yZJNYQQAqPRyPXr1zl79ix+fn6VClK2HIPqBhyxsv0o0NWG94Wc6xD7OWxbaNPbSFJtdvnyZZo0aYKnp6cMTlJJ2emQcQFMhhK7FEXB1dUVHx8fvL29uXr1aqVuYcsA1Qi4ZmX7VcDbhvfFbDYR/eYs5s+cS/TGjZjNZlveTpJqpZycHLy8vOzdDMlR6S9DxkUwZJR5WP369cnIKPuY0ti61JG15XpL/SimKMoMYAaAn1/lkv3MZjPDRk4gdqsBvQW0k+8nNOx2YmJi0Gg0lbqmJNVFJpMJZ2eHrYYm2ZM5FzKvg6sTeDQs81AXF5dKPyTY8gnqGupTVHHeWH+yQgjxhRAiRAgR0qRJibqBFaLT6YiNjSXTokbHTH0WsbGx6HS6Sl1Pkuoy2bUnWSPSLpOWauF8mkLa9UyEsPYsorqVnyFbBqijqONQxXUF/rDVTePj49Hr9UW26fV6EhISbHVLSZKkOkMIwfFzFzkJnM8ycvLkSY4fP15mkKosWwao/wJhiqK0y9+gKIo/0C9vn00EBQWh1RadZqXVagkMDLTVLSVJkuqM9KuX0ZsElrzvLRYLer2e9PT0Kr+XLQPUl8BpYKOiKCMVRbkX2AicAz631U3Dw8MJDQ3F08MdADcg9LbbCA8Pt9UtJUmq5U6fPs28efM4efKkvZtid1lXUwuCUz6LxUJWVlaV38tmAUoIoQcGAceBlcAq4BQwSAiRaav7ajQaYmJiWLNmLW4auKuthpgfI2WChCRJlXb69GneeOONOh+ghMWCyMkpsd3JyQlPT88qv59NU3SEEGeBsba8hzUajYZ7R47kjk6NUXLT0Vz+Axo0r+5mSJJUB+VPUnV1dbV3U6qUEILjx/9Ebyj6/OTk5IRWq6VBgwZVfs9aXc086u2pbApwhvfet3dTJEmys+nTp+Pv719i+8CBAxk4cGCp523bto277roLgLvvvhtFUVAUhW3btgHq6t9Tpkzhm2++oXPnzri6uvK///2Pbdu2FTku3/Lly1EUhdOnTxfZ/uWXX9KrVy/c3d3x8fHh4YcfrvQEV1tIT09Hr88u0r2nKAq+vr4EBATYJOOzVk9ycG8dCGdNsHsrfCZApsxK0q2ZV/WfkitlXtUPyJcmODiYpUuX8tRTT/HRRx/Rp08fALp2LSyIs3XrVhISEpg7dy5NmzbF39+fc+fOVfge//znP1m0aBEzZ87kvffeIzk5mdmzZ3PkyBF27drlEEMUWXo9lmKZekKIgoBtC7U6QBkbd+a+VAv3XMvi0RMnoGNHezdJkqQapn79+gXBqEuXLoSFhZU45tq1a8TFxdGsWbOCbRUNUKdPn+a9995j7ty5vP766wXbAwIC6N+/P1FRUYwaNeoW38Wt89SYUShafcFWY0/5anWAcmnZk4QsgQI8uuVXGaAk6VZV45NLTRIWFlYkON2MX375BYvFwuTJkzGZTAXbQ0NDqV+/Pjt27HCIANUgJwMvQK8oWISw6dhTvlodoHDxoE+Hhvxy4BrzP3yfoJatCQ8Pd4jHZUmSao/mzSufhHXp0iUAOnToYHX/lStXKn3tqiCEIP1qKlnXsvF1AvzbkpWTg6enJw0aNLBptZFaHaDMZjMHLpi5Csw99hfaSZMIDQ2VdfkkqQ5yd3e3uq7VlStXaNy48S1d29ofaXd3dS5m8XsWDzj59968eTPe3iXraN9q226Fmrl3HH1mJhahZtVpL1+2WVJEcbU6i0+n0/H31Wwgry5fZqasyydJdVSbNm1ISUkhNTW1YFtSUhKJiYnlnpu/llF2dvZN3Q/gyJGiqw5t2rSpyPd33303Tk5OnD17lpCQkBKvtm3bVvieVU3N3CtMjrCAzapGWFOrn6Di4+PJyTUV2ZZfly8iIsJOrZIkyR7Gjx/PnDlzmDx5Ms8//zypqam88847+Pj4lHtuQEAAzs7OfPPNNwUrxHbq1Il69eqVek7z5s0ZMGBAwT2aNm1KZGQkSUlJRY5r3749r7zyCk8//TSJiYkMGDAAd3d3zp07xy+//MIjjzxSkOZe3bKysrBYis57yq8a0bBh2VXMq0KtfoIKCgpCWyzDRNblk6S6qUOHDqxfv57k5GRGjRrFv//9bxYvXkxAQEC55zZu3JglS5Zw8OBBBgwYQJ8+fYiLiyv3vMjISMLCwpg5cybTp0/Hz8+P2bNnlzhuwYIFfPHFF+zYsYMJEyYwcuRIFi5ciLe3Nx3tmNylLlZZdJutM/dupNiiAm1VCAkJEfv377+la5jNZoYNG0bs71vQ5wq0QOigQcRs3izHoCSpHMeOHaNLly72boZkR8Jk4NDBwxjzwkR+5t7NjkGV97OkKEqcECKk+PZa3cWXX5dvSv92/BJ3luVGCF+4UAYnSZKkClAyU2kn4JqrBmcf32rJ3LtRre7iAzVI9ejWmStGuAvQbN9u7yZJkiQ5PiEg9TL1AD+/VrRo0YKGDRtW6yKWtT5AAbTvFgTAycYesGWLnVsjSZJUA+Skcz3DRIazAg3KTySxhboRoIIGAJDUwQlGjrRzayRJkhybEIK0lPOcMsMZnLBXpkLdCFA9QwFIqm+C8UPt3BpJkiTHJYTgeOKfnLyShREwmC02W9K9PHUiQHk3asSDd7YhoJETHPgVUlLs3SRJkiSHpE7OzcKSF4+EENU6OfdGdSJAAXzz+kOMaO8Md8+Azz6zd3MkSZIcihCCtLQ0UlIullhWw1ZLupenVqeZF9E8kOsWqN/YAypQ2kSSJKmuKKi5p9eXqBwB1Ts5t8h9q/2OdjJvxRYa/zsDk7cF/vzT3s2RJElyGAU190oJTrZeVqM0deYJqlWHbpgscM7TTNvjiWqOv1xhV5IkyWrNPYB69erh6+tbrZNzb1RnnqDa5621kuQG6LMgOdm+DZIkSXIQnp6eODkVDQdOioKvr2+1T84t0ga73NUO2rdvD8BJrRP8azzUr2/nFkmSJDmGBg0aoPX0KPjeCdB6eNilW+9GdSZAtWzZElcXZ5IMAjqZZICSJOmWZWdnk+ygvTE30zYlJwe/hq4ANNS60a5DBwK6dLHbk1O+OhOgNBoN8//1EkPaOUPsbtizx95NkiSpGk2fPh1/f/8S2wcOHMjAgQMrdc2UlBT8/PwYMmQI3377LZmZmZW6zpNPPomvry8mU9H16wwGA97e3jz77LO2a5vFAn/9Rebf1wBo1bJViW49f39/pk+fXuJURVGYN2/eTbetoupMgDKbzXQNvp09l9yJXp2C+dWX7N0kSaqZBg4s+frkE3VfVpb1/cuXq/tTU63v/+47df+5c9b3R0Wp+x1sikjr1q1Zt24dDRo0YMaMGfj6+jJlyhRiYmIwm80Vvs4DDzzApUuX2Lx5c5Ht0dHRpKWlMXXqVNu1zckJfOsjFPAE3I4nOUwxgzoRoPLXhbpv0iTmbr7KpDTBsF2xN/UDJEmSVJxGo2HMmDH88MMPXLx4kQ8++IC///6b8PBwWrduzYsvvsjBgwfLvU5YWBgdO3Zk5cqVRbavXLmSLl260Lt3b9u1zWIGy3WaNnWiq6cHCoAd5jxZJYRwyFfv3r1FVYmKihJeXl4CKHh5gYhav77K7iFJtc0ff/xh7yZUqWnTpok2bdqU2D5gwAAxYMCAMs81mUzCaDQWvCwWS5nHnz17Vrz77ruie/fuAhCDBg0qt31vvPGG8PDwENevXxdCCHHlyhXh6uoq3nnnHdu27fYwYTm8T1guJQphNguRkVHinDZt2ohp06aV2A6IuXPnlvveyvtZAvYLK3GgTjxBxcfHo9fri2zTAwlbt9qnQZIk1Sjt27fHxcWl4LVixYoyj79+/Trp6elkZGSgKAr1K5CUNXXqVHJycli/fj0Aa9euxWg0MnnyZNu2zd2dv42QcC6T1KtXEVptuW2tLnViom5QUBBarbbIIKEWCLwhrVKSpNrN3d2d3NzcEtuvXLlC48aNyzw3KioKg8FQ8H3btm1LHHP+/HlWr17NqlWrSEhIoGPHjjz88MNMmTLF6vHFtW3bln79+hEZGcmDDz5IZGQkAwcOpHXr1jZr2+RRwzAanLhkBoGFs2fPcuXKlRJLulv7f3f16tVy39OtqhMBKjw8nNDQUGJjY8nMzESjQGgzJ8IfvNfeTZMkqZq0adOGlJQUUlNT8fFRF+BLSkoiMTGRvn37lnlujx49rG43Go1ERkayatUqtm7dire3NxMnTuTTTz8lLCzspts4depUnnjiCbZt28bu3btZtmxZuedUum3CQtqJw5w0GAvWe7JYLAWVyxs2bFhwrTZt2nDkyJEi14+Ojr7p93ez6kQXn0ajISYmhjVr1qhPU+7O/PywJ5qsJHs3TZKkajJ+/HgURWHy5MnExMSwatUqRo4cWRCsKiM5OZknnniCBg0a8OOPP3LhwgWWLl1aqeAEMGHCBFxcXJgyZQoeHh6MHTvWJm0TQpB2KZkUvZHiBY6sVS6/7777OHz4MM899xy//fYbixcv5j//+U+l21ZRdeIJCtQgFRERQYsWLbi2czlO+7+CZd9C7+n2bpokSdWgQ4cOrF+/ntmzZzNq1CgCAgJYvHgxCxYsqPQ1mzdvzoULF/D29q6SNjZs2JARI0awfv16Jk2aRL169aq8bSK/cnlmRsGaTzeyVrl82rRpnDt3jq+//prPP/+cO+64gw0bNtAhr4ScrSjCDqskVkRISIjYv3+/bS5+dg9MGAAHTJBlAOc6E6clqcKOHTtGly5d7N0MqYqlpaVx8mQSFivRKb9yefExqFtV3s+SoihxQoiQEu2pshbUIFuOXWWTRgGjBRJsFAQlSZIciChYkDDFanCqV68e7dq1q/LgdCvq5KPD/HffQ39Gw3CAXzZASOX6iyVJkmqCgm69MtZ8yq9c7kjq5BNUWFgY8RdzyHYHdm6zd3MkSZJsylEXJCxPnXyCCgsLw2S2EN9MQ99EmcknSVLtVuqChIBvu3Z2W5CwPHXyCSokRB2Lm+8K0X01mItVEJYkSapNrC5ICPhqtXZdkLA8dS5Amc1mpk2bhqIo/HzKzKS1lxg26E5ZOFaSpFqrQYMGaN1dyI9DToDW1ZUGHTvatV3lqXMBSqfTERsbS356fWYuxMbuQ6fT2bllkiRJtqFYTAQ0sNC+oRMtfH3UBQl79EBx8Ck2dS5AWS0cm2siISHBTi2SJEmyLcv1C1y4YsTjuqBF85ILEjoqmwUoRVGeVxQlSlGUC4qiCEVR5tnqXjcjv3DsjbRAYGCgfRokSZJkQ8KYzYWLlzmfC1dcXBEajb2bVGG2fIJ6FGgK/GTDe9y0/MKx+aU83BQIBcK72LZkhyRJUnVT5z8lckGvDmlczDVy/PhxHLWCUHG2DFDdhBChwDM2vMdNyy8cu3btWjw8PBjQph4xgOa3H+zdNEmSapAFCxbQqVMnnJyc+Oknh/ocXiA99QL6nMIs5RurldcENgtQQoiSSfcOQqPRMGLECMLCwkh31aJp7ATJf9i7WZIk1SCDBw9m06ZN3HnnnfZuinXCQlba5RIFYa1VK3dUdS5J4kY9e/bk8NlrmJ/UQkdD+SdIklTjffrppyiKwsGDB2/pOqGhobRv377MY7755hs6duyIq6tr9ZcRyryMp8ZM8VQIa9XKHZVDBShFUWYoirJfUZT9ly9ftvn9evbsiY+PD5f0As7EwtIlUEM+WUiSVDkJCQm4uLjYvFL7+fPnmTFjBn379mXLli38+uuvNr1fEeZcyLxIAzfw0hZO0nXkskbWVChAKYoyJC8Tr7zXtltpjBDiCyFEiBAipEmTJrdyqQp58MEHOXPub5q38oeTV+HpZ+Dll21+X0mS7CchIYGuXbvi6upa6jHBwcH4+PhYfZ07d65C9/nrr78KCgP079+/oIJNRV29epUrV67c1DkF0v8GYYEsVwI8PGnXrh0tWrRwuGrl5anoE9QuoEsFXg/YoI02U/CP1OZ2aO0M9w2GpUthzx77NkySJJuwWCwcOXKk3GklBw4cIDU11eqrdevW5d5n+vTpDBw4EFDHqhRFYfr06TfV1kOHDtG8eXNGjRrFDz/8gMFQwWGInHT1hROXM3I5lpbGrFmz6Nu3b4n5TwMHDixopyOq0DRiIUQW8KeN22IXzz77LLnJJ/ikGzDMB753gp9/hkou2SxJknVmsxmdTkd8fDxBQUGEh4ejqeY5OYmJiWRlZdl83uOcOXPo3bs3M2fOZOnSpQQHB3OzvUJhYWF8/fXXREZGMnHiROrXr8+ECROYOnUq/fr1s36Sxaw+PQE4NSTdchmzRlNjnpiKc6gxKHu4ePEiP+/7S/3mchz06AE7d9q3UZJUy5jNZoYNG8akSZOYO3cukyZNYtiwYdVeAzO/YkxVBKi33nqLVq1asXv3bh555BFatWrFxYsXAWjfvn3BGFfXrl0JCwsrN6GiOHd3d6ZOnUpMTAzJycm8/vrr7N+/n/79+9O+fXvmzp3LiRMnip6UcVEdf3L2wKI3kQE0cLA1nm6GzQoxKYoSAvhTGAS7KooyLu/rTXlPZXbXs2dPvvvuO65r2lJffwn6j4dztk/QkKSaylqX0IQJE3jyySfJyspi+PDhJfYHBgYSGxtLZmYmAJmZmWzdupXAwEAaN27ME088wcSJEzl37hxTp04tcf4LL7zAiBEjSExMpFOnTpVue1UGqNmzZzN79uxbuoYQokSQdrZSH8/X15dnn32WZ599lsTERCIjI1m5ciVvvvkmDz30EF9//TXk6kF/Sb2uqw8p105jATQOXm+vLLZ8gnoaWAd8l/f9+Lzv16FWmHAI3bt3B+CFrU5EHzdifqAfbNxo51ZJUu1y9uzZEjUwLRZLQcCqLgkJCbRp08ZhVo7dvn07Li4uRV7lSU9PL1iAUKPRqKXbLBbEtTOk5QjO53jwR3IK5/OOT0lJqTETc4uzWWgVQkwHptvq+lXBbDbz73//G4Cvtiax1hVCj8wmJv4BNE5OUEP7bSXJlrZt21bqPk9PT6v7o6Oj+eWXX4oEJC8vLz7++GMiIiIKtrVu3brM69/K0xPAwYMHCXOg8eXevXuzb9++co87ceIEq1atYtWqVfz1118EBgbyyiuvcP/999PM1xdx5RzHU7LQG8EiigZ9i8WCRqOxmmRx5coVGjduXGXvp6rV3Ge/KqDT6YpM1svMhdjEC+hCQ4no3h2WL7df4ySpFsmvgRkbG4ter0er1RIaGkp4eHi1teHixYukpKQ4VGHoevXqlZp+npmZyfLly4mMjCQ2NpaWLVsyefJkpk6dWtDzA8CVFNJPX0IPlFa+x9fXl0uXLpGamoqPjw8ASUlJJCYm0rdv36p9U1WoTgco60tvCBL014nYvt1OrZKk2ie/BqZOpyMhIYHAwMBqz+KLj48H1D/8xWvnubm5VWuwrIj9+/fz6quvMmbMGN566y0GDRpUYlVcLGa4dpEsSg9OAEOHDuXzzz9n8uTJPP/886SmpvLOO+8UBCtHVacDVP7SGzd2O2hdIbBLa9iwBc6fhxYt7NhCSao9NBoNERERRbr0qlN+b8miRYtYtGhRkX29e/d2uAAVHBxMSkpK2WWJrieDqxnP+i4oGSarVcqdnJzo3Lkz69atY86cOYwaNYqAgAAWL17MggULbPgObp3iqGXXQ0JCxP79+216j/zU1927d5OVlYWbqzP9WwpiHhuF5p8/wLp1MG5c+ReSpFro2LFjNi8HJN2C7DS4dgpQED4BHPzjOCaTWrncyckJNzc3vL298fT0pEGDBnadC1Xez5KiKHFCiBJ9nXV6HlR+t8Pq1atxc3Nj4O0hxEzxROOcCO7usGuXvZsoSZJUkikX0s6qXyveGHNMmEwmvL29C0oade3alRYtWtSY1XOtqdNdfKAGqZEjRzJ06FASExPReDSEjLPwzAwIcZxsH0mSJECtsXftNAgzwrUe6WdS0Xtm0bRpU3x9fXFzc7N3C6tMnX6CutHAgQM5fvw45xsEqxvuC4EJE+zbKEmSpOKunwejHuHkwvHLRk4KwQW9ntTUVE6fPl1jVsutCBmg8uTPjt9+JS+r5eQ2NUmiWJafJEmS3WSngf4yAjif60VmVlZB9l5NWy23ImSAytOrVy/mzZtHmltL5m83EL3iv5hbtoTffrN30yRJksCYA2lnEEJwPM2Fi5evlHhaqkmr5VZEnR+DutHvv/+uTiTMNKB1MRAKxBw/TvXWW5YkSSrGbIKrJ0FYSBda9Dn6UlPKa8pquRUhn6Dy6HQ69uzZQ2ZmJgLINEIsoNuyxd5NkyS7qU3jGTWWEGpShNkAzh5kOXlhsZSclqsoikOulnsrP0MyQOWJj48v8WisBxISE+3TIEmyMxcXF7Kzs+3dDOl6MuRmgJMzNGqHp6e2RNq4oig0a9bMIVfLzc7OrnRmoQxQefKrStxI6wSBGRl2apEk2VfTpk1JTk4mKytLPknZS+Yl0F8GFPBuC86uNGjQAC8vr4KyR05OTnh5edGiRQuHCU5CCIxGI1evXuXvv/+udEFaOQaVJ7+Y5datW7FYLHi5OhHaCML/+bS9myZJdlG/fn0Azp8/j9FotHNr6iBjFuhT1a89G0P6ObBYMJpMOGk0IASm1FRcPT0xu7vz55+Otei5s7Mz7u7u+Pn54e7uXrlrVHGbaqz8qhKjR49Gp9MR+eI9RGi2own0sHfTJMlu6tevXxCopGq0LxrGj4EIV5j4JvR6Xt3u78+Q1FQu+vtzRKeDkBD47DN47DH7ttdGZBffDTQaDffddx8mkwn/kKFoBLB5PZw7Z++mSZJUV1w4CLMnwxkjuPaD/s8BYD58mJVnzrBFr6d7p06Y85d7b9vWjo21LRmgigkPDychIYFud08GkwYW7IVVy+3dLEmS6oLLx2HlGPhTD34NMS+MIvp//+ONN96g9+DBPAIIIOrnnxn21FOYoVYHKNnFV4y3tzfe3t7qNwF9wUMHB/7Pvo2SJKn2u3oKVo6Cy5fgnBnzPx9n2NBhxO7dS2axDOOsrCxik5LQARF+fvZpbzWQT1BWbNmyhXfeeQc6DIZGTvDnUXs3SZKk2uzqSVgeoaaUp7YBATrfZsTu2FEiOOXTG40kvPQS1KLisMXJJygrtmzZwrvvvsusxJ14NnaCsynqZDkHSeGUJKkWuXoSlo+A639D61C4bxEEbiE+PR29lQm5+bQaDYF33lmNDa1+8gnKittuuw2z2Uz8BSM0qwdpJjhzwN7NkiSptrn0Jyz7R15wCoMpP0DnHjBrFkHBwXhYSc9WFAUvZ2dCTSbCa3kxaxmgrAgOVpfceHvBAqLbd8c81QPObLdzqyRJqlWSD8CycMg4D359Ycp6SPgD1q8Ho5Hw8HC88lL8FUDr7l5Q1HrNnDnEAJpvv7XrW7A12cVXjNlsZvr06SiKgk6n43dPd0J9jcTctQXNgOft3TxJkmqDk9th7WS1hFHHYTBhBbh4wEcfwebNmEeM4PMvv+TSpUv069WLoQ0bEvzCC4QPH45GowGzGbKyYNo0e78Tm1IctYRJSEiI2L9/f7XfNzo6mkmTJpGZmVmwzUsDawZ7ELHxIrjLSYuSJN2Cg9/BxqfAYoTu42D0Z6BxgbQ08PPDPGYMw/7+m+3bt2MymdBqtYSFhRETE6MGp1pIUZQ4IURI8e2yi6+Y+Ph49MX6dfVmSDhsgCS5NpQkSZUkBOx4DzbMAEMuMBRGf6EGJ8D80UdEZ2Qw7dIldu7ciclkAkCv1xMbG4tOp7Nj4+1DBqhirBeNVQi8boG4n+zUKkmSajRjDmx4DLa8BSjgNBreWA9LlgBgTk9n2Pz53KfRsEqnIycnp8jper2ehIQEOzTcvuQYVDH5RWNjY2PR69VFwQL8/Qg/dQbmfQdjl4C2nr2bKUlSTXH9Anw3GZLjwMUTxnwJnf8BW5Mwv/IKOmdn1up0/G4ykVvKJbRaLYGBgdXabEcgx6CsMJvN6HQ69u3bx5IlS2jcuDFTtJcJTkgjfMwwND/8bJd2SZJUw5z6HX54BDIvQgM/mLQafLuDomA+f55h/v7sMZnQl/F32MvLi9DQUDkGJak0Gg0RERG8/vrr+Pr68tdffzEvIY1JGhh2+BBms9neTZQkyZFZzLBtIXx7rxqc/O+AGVuhWQ9YuhTuvBPdzp3EajSlBid3d3emTJnCmjVranVwKovs4iuDTqfjXF4lcwFkmiH2TAq6TZuIGDHCvo2TJMkxZaTAj4/Cqe2AAne+BAP+CZq8P7fr1sHVq8T/+Sd6g8HqJfKfmpYvX14nA1M+GaDKYDWjL9dCwqsvE5GYCC++aKeWSZLkkE5ugx8eBf0l0DaBMV9A+0FA3tDB6tXE7diB+Y47OHHsGG5ubkUSItzd3Rk3bhwTJ04kPDy8TgcnkAGqTPkZfTfOidK6QmBuBrz7Ljz+OHh52bGFkiQ5BGM2bAAEb4oAACAASURBVF0Auz4GhNqlN/YrqNcMUIPTsGHD2L1jB1kAv/8OqMMJGo0Gi8WCVquVT03FyDGoMuRn9Hl5ean1rzzdCW2pIXxUE7hyBT75xN5NlCTJ3s7thc/ugF0fqQWlB/wTHthYEJxAHS7YvXs3WUZjkVPNZjMuLi5Mnjy5To81lUY+QZUhfxl4nU7HypUr8fFuwEcto9CYT8LgAfDee/DUU1Bs3pQkSXVAbhZsfRt2LwUE+HSCez6ADn2LHjd/PvH79pFVyrIZBoOBTp06ERERYfs21zDyCaoc+Rl9ANG6GDRdwtUd93aD1FTYvNmOrZMkyS7O7IbP+sPuJepTU//nMDd4iuguA5g/eTLR0dFqtu++ffD66wRpNHh6elq9VF2d41QRMkBVUFhYGGfPnuW8zx3qBpfD8Pbb0LOnfRsmSVLVWLwY2rdXSxKVJvMSbHgclt0DV5OgSWd45FfMbacy7MGHmWQy8frq1YwfN46Ajh3Z+OCDmJs0IXzZMm6//faSVWryxp3Cw8Nt/OZqJtnFV0G33347AHsuuTPGRQspB2HWt+Dtb9+GSZJUNV54Qf3v0aPQvXvRfWYT7PtK7dIzXAeNK/SbpaaQO7uh27iRWI2GzLw5kjkGAydPnWIi0KlFC+qPGMHo0aN55plnOHjwICaTCWdnZ4KDg2W2XhlkgKqgoKAgXF1d2b3vAGNCw+HIeoj7HrI6w223QbNm5V9EkiTHdeYMtGkDv/xSNECd2QWbXoKUI+r3He6G8IXQuL36fXo68YcOkZlbslCRATh0/jycP8++ffvo37+/TIS4CbKLr4Lc3Nzo3bs3ycnJ0G2UunHXehg5Ev77X/s2TpKkW+fnB506FY4rp56AbyfBqIFw9CA09IP71sDkdYXBadUq6NgR3wqUjDMYDHW2KnllyQB1E3777Tfuv/9+5n+3j+iTzpiNx6BFc5koIUk13cGDMHEitG0LF5Ih6llYehv88BMkGOFsN3hqL3QeriZFACQmYp4xgygfHxauWIGTkxNubm5l3qauViWvLJt08SmKEgA8BdwFtAMygH3AHCHEQVvc09bMZjMjRowoqHKuddMQ2lwQ06sLmi1b1BUu5WO7JNVMe/fC99/Dt8/B2YMQtwwUJzhWH8iBXUkU+XOZnY153DiGGY3sPHmSHIMBV1dXOnXqREZGBhcuXCixZAbIjL2bZasxqKGowWkFcABoCLwMxCqK0k8IEWej+9qMTqdjz549BaWPMnNMxCaDrt05Iq5dg7g4dSxKkqSaxZAJm1eCqwInvlKfkDoNh7CXYPdrENwQAgMhNxdc1MUFeflldEeOEOvuXhCIcnNzOXnyJJGRkWg0Gg4cOMCPP/7IiRMnyMrKkhl7lWCrALUWWCpuWMtDUZQtwGlgFvCAje5rM/Hx8SUm2ulzIcFwlQhFge3bZYCSpJrEkAn7voSdH0HcOWjiBH5hcMQPvjoFk4Lh55/VtPP8bj0AiwUuXiQ+NBT93r1FLqnX6zl8+DCzZ88mIiKCf/3rX+h0OhISEggMDJQZezfJJmNQQohUUWyhKSFEOnAcaGmLe9qa1ZV23V0IbK2BLx6RhWMlyVGcOaMGlE2bSu7LzYWcdPh9MXzQA36dB9lXIdUJ+g6Fh2KgSTvYsgUOHFDPURTIyoLvvoPsbHBygnXrCHr1Vdzd3YtcvngXXv5E//yAJYPTzam2JAlFURoB3YFj1XXPqpRfl8/ZWX3o9PLyIrR3IOEdnOHaFrCY7NxCSZIAaJn3GXjBgqLbr1+Avl2gly98OQeyrkCr22DsaujYA+4aoQaju+9Wj+/dG44fV7/evRvuuw/eeQcSEwFoHxBAdnY2rq6uaq3OvCUyZBdeFRJCVMsLWAVkAR0qcnzv3r2FozGZTOKxxx4TgFi+fLkwGY1CfBwixOv1hJg8QojXXrN3EyVJEkKI558XwsVFiNRUIS79KcRPTwoxt5EQd7kJoVWEACFefFgIi6XkuSaTuh8K95tMQjRrJgQIk5+fiPrpJ9GvXz+hKIpYtmyZmD9/voiKihImk6l632ctAewX1uKGtY0lDoIhqGv2lffaVsr5r+btf6ic+8wA9gP7/fz8quv/zU3ZuXOnuOOOO8SxY8fUDdvfE2JufSH6txOiXj0h0tPt20BJqsuOHBFi2jQhNm5U/7w92Fv9/RzgJsQ/3IX4bqoQf+0UYtgwIRo1EiIz0/p1duwQ4ujRgm9NJpOIGjFCzAPRq1UrodVqBSA0Go0YPHiwDEy3qLQApYgKTDBTFMUT8KvAA1mWEOJssXMfBz4FZgsh3q7ANQAICQkR+/fvr+jh9pN2Vu3LvqiBz6/Bhx/CzJn2bpUk1U2vvgrv/RveuwPe/V3NzJvaEBalw8Sx8O1a9bhdu6BfP/j4Yzh1CpKS4KefrF4yfy2n2N27ybRSkdzLy4s1a9bIauS3QFGUOCFESPHtFcriE0JkAX9W4qZTgU+ARTcTnGoCIQSKoqizy/3vAH6Hnu3ho4/UJTjkYKgk2V5SEly+DD06qnOXvlwE/gqkx8OQRtDyDvDuDbmzYdZLhef17Qtr10JEBAwZAh4epd5Cp9MRGxtrNThB4eRbGaCqns2SJBRFGQ0sA74SQtSqFLdHHnmEIUOGFG7oPV39bx+N+gvzv//ZpV2SVGdcvQrPPgudO0O/vvCvAFg5D64YIbQVhL8H35yChT/A8tXQp4+a9HCjiRPVwHTkSMnisDeIj48vmP9ojZx8azu2qiRxJ7AGOAQsVxQl7IbdBiFEvC3uW11cXV2Ji4srfIrqMgI8G0OLC/Dco9Cunb2bKEm11769MGQwZGRCoAsEuENDEyS2AOeT8PEBaNRIPfbXX+GPP+Crr6xf6+OPITMTunUr2GQ2m9HpdMTHxxMUFETPnj1xcXEht1gxWEVR5ORbG7PVRN1BgBsQBOwstu8M4G+j+1aLbt26kZ6ezoULF2jRogU4u0Hg/bDrYxjgWuanMUmSKun6eYhbATPeAks2PKaF1g0haDLcNgOa/wraXwqDE6iTau+4Q00RtyZv2gjBwcAN4015Jc08PT1p06YNRqMRJycnhBB4enrSoUMHxowZI5fLsLEKJUnYgyMnSWzdupVBgwaxefNm7s6fM5F6Apb0BicP6PMF+LUv8qlMkqQKSk1Va+MNH64GmJNbYP8ySNSBMEOGBcwtYNLz0GsSuNdXzzt5Ery91dfNyF9mA4iOjmbSpElkZmaWOMzNzY2WLVuyePFiOem2it1SkoRUVLe8wHP06NHCAOXTQU2WOLEDxk6ABx+GpUvt2EpJqqHeeAOWLIGlT4NxB1w7rW63aKD7KOjzsPq7dmP5Iah813pecIKyx5sMBgOXLl1Co9HI4FRN5HIbldC0aVMefvhhOnbsWHRH7+ngrECAFqKjy146WpKkooSAk7/Dqq/V7xd8AldPQQM/GDQHLo2Bz85B674lg1MVCQoKKjP4yOUyqpcMUJVgNpsZNWoUBw4cIDo6GnPeMs90GQHaJuCXBWfPqtlBkiSVLTsN9nwGS0Ph0+HQIBc6OsNlBfr8B2YlwNlm8MU30KVL4bjRLTKbzURHRzN//vyC3+PbbrsNs9mMS37V8mJkxl71kl18N6n4IGp+Fk9MTAwaZzfo8whczJvyFR0NPXrYt8GS5IiEgOQDsP8bOPIDmLLV7b7N4esHoNcUMLhCixbqqrXTpsFdd8F771XqdsUz84YOHcrw4cOLJEN06NCBZs2aIYRg0aJFXLt2TS6XYWcySeImWRtELTKTPPMSvN8NPrsGnfvBb9vt2FpJcjCGTDiyXg1MFw7C/xmgmQaGDoHeD0KTMGjarPD4o0fVD3kDB6of+Dw9b/qW1j5Utm/fnqSkpBLJEIqi4ObmRr9+/YiJiQGQy2VUg9KSJGQX302yNohapF/aqyn0GA8TPeC5UDu0UJIcUMpR+N8LsKgzRM1Sg1O6Fn4zQPCr8MBGyG4FLVqBTld4XkyMWu0hKqpSwQluqASRmYkQgszMTI4dO2Y1GUIIQU5ODrGxseh0Orlchp3JAHWTrK4LVbxfOvRxqO8Eh1ZDzvVqbqEkOQhjDhz6Hr4eBh/fDms+A8N1aB0Ko78Aw73g6gpTH1O7/L77Tj3vxoU/n38e/vtfKPY7dzOsfajMzc0tWDrHGpkM4RhkgLpJ+etCeXl5AWqXwG233Va0X7p5TzUNdkcqjBhkp5ZKkp1cSYLNc2BxF/jxUTi3B+IUWJUFDV6EhzdD+39A5GoYPx4aN4bJk+E//1HHmRo3rtLmWPtQ6erqSqNGjUosOJhPJkM4BhmgbpJGoyEmJoY1a9Zw7733IoTgo48+KvnoH/Yk5AK/xsGJRLu0VZKqjdkEx6Jg5Wj4OBh2faSuVNusB0R8AOtPg4sLLPhILe66ejVkZMATT6gr1Pr7q9cZN+7Wm1IsO2/o0KFotdoiv6O5ubmkpKQA0LZtW3r27IlWq5ULDzoYmcVXCfn90sHBwYwdO5ZWrVqVPCjgHrirG2w9AItehU9/rP6GSpKt5ZcfOrACMi6o25zdodsYdUJty96Fc5bi4yEoCF54Abp2hdtvV6uKA7z5JgQGwsiRt9QcawkRISEhXL9+nSFDhtCkSRO+++47jEYjADk5OVy+fJn3338fjUYjkyEcjMzis6XD6+He+yBTAxcywdn63ApJqlEsFji5Vc3Eyy8/BNC4A4Q8pJYf8ryhHt6330JcnNqF9+ab8NZb8MsvMHhwlU+4jY6OZuLEiWTdsDSGm5sbBoOBbdu2sWPHDubOncuNf/cUReHNN99k9uzZVdoWqeJkqSMbSU5OZsOGDTz66KO4ubkV3dltNPRtCavPwqp3YNrr9mmkJFUF/RVIiFTr4l07pW5zcoYuo9TA1PZO6wHnyy8hPV3t4vvXv9Tq4d2733JwKj63KTw8nPj4+CLBCdQSRR4eHvTt25eMjAy0Wm2R9HI53uS4ZIC6RXv37uWZZ57hwIEDjBkzpmjXgJMGnpgDR5+ExO/BMlvtb5ekmuTvONj7BRzdAGaDuq1+K7W0V/BUqNes9HPPn4edO9X6egDu7vD++7fcpNImzN97771Wj8/NzSU8PJxNmzYRGhpa4jw53uSYZIC6BWazmQ8//BCAZcuWsW7dusKqEvlB6vZpMO1DSD8Lf2yA7mPt2GJJqiCTQQ1Ie7+A5Li8jQr43AEpfpCkQEho2cEJ4Mcf1RTyKkh+uNGNc5sAMjMz2blzJ2azuaAnw2AwFBxvNpuJjY1l8+bNxMTEyMm3NYT8OH8LdDodcXFxBd9nZmYWTPAroHGBvs/CRTP8dx6YjdXfUEmqqOvnYctbajWUDY+pwcm9IXiPgR09YZYO3vpUzcL76y/1nF9/hchI9etjx9TMvO15FVTWr1eXnenSpUqbaW1uU05ODtu2bcPZ2RlvK0tu5M9tkpNvaw75BHULrP2SZGZm8n5eF0bBJ7OG/eBzPYw4AfEr1f56SXIUQsDZPbD3czVV3GJSt/t2VxcC7DYWegSpY0evvabOWercufD8Tz6BDRvU1Wn37gU3N5g5U73usGFQbCXaqhAUFIS7uzvZ2dkl9un1esxmM+7u7uTk5BRsl2NNNY8MULcgfwJg8XpeW7duZe/evYXdfR0DwMsTLhhh20LoeR+4Vq5siyRVyvnz4OOjVm7IZ8yGw+vUbryLh9Vtiga6joTbHoM2Nyxr8euvcP269eLHa9eqAem//1XHmp54Apo0UfeNHg1+fpVqsrUkCCjsuQgICOD48eNWg1ROTg7t2rXj0qVLcqypBpNp5rfgxoFaaytwFikiO2AAnIuHBxQYMg/6P1ft7ZXqqLQ0dZXZWbPggw/g2hnY/zV88QlsvQYNFWiqhXFj4eH50KBl4blmM9ihCyz/d2vPnj0FlcRvyyuBtHfv3iIVyLt168aPP/5Y5GnJy8uLyMhIObephpDFYm3gxqoSgwYNQimWNluknldwMFzIBYuA/3tfTdmVpOqQX+NuSBB8/wB8FAjbP4CfrwIu4OoHh8zQ/O6iwQng7bfVbrobEg6qQ34ShF6vLyjwumvXLnbt2lVQ9FWv15OUlMSECRPo168fXl5eRSpBREREyLGmGk528d2i/AFXUD/ZlTq/IjgYcgzg0Rdy4mDLfBjxgT2aLNUlFjN8+j600MK+Z9RtGldw6w+Gn+HHKLj7bnWcKL/7b+VKOHQImjVTJ9cOGaKOK1Wj0pIgitPr9Rw+fFhm5tVSsouviuR3SezYsQOj0YhWqyUsLKww5TwlRS310qkprLxb/cPx2HZo3sveTZdqo9wsOLgGfloEC47B3W6g9YRDrrBvHzRqDRcvgq9v0QmzRiP066cGKINBnVwbH69m4lWj6OhoRo8ejclkKvO4It3oUo0lu/hsLL+77+mnnwbgvffeKzofytcX7rkH2garA9AI2PSymul0I5NJHYyWpMrIvAxbF8AH3eF/z8OOJPW3fNY8mLQETqZA1Bb12GbNSlZzcHFRM/Gys+HaNUhOrpbgVLzAa1hYGBaLpdSl1wHc3d1l4kMtJ7v4qpBGo2HKlCm8//77NGnSpGQXw549cOIEjHsFDn+vLkNweB30nFB4zIQJasquxVLldcqkWigmRs2S8zJBwleQsKaw2kOLIFg0A9J8YOhQNeGh7WyYPh22boXly0u/rqJAw4bV8Q5KJBu5u7vTokULvvrqKzQaDStWrGDr1q0U7+0ZN24cy5cvl115tZh8gqpinTt3xsnJiTNnzpTc+e238NRT4FoPBs9Vt8X8C7Kuql8bjWpwAnUpAkkqS1qa+lTetSu07QlrvlSDU0A4TN8Ej26F2+5XgxOo2XgPP6x+bS1d3E50Oh27d+8uGL/Nycnh5MmTPPnkk3z77bfMnDmzxHpOXl5eTJw4UQanWk4GqCrm6elJeno6L7zwQsmdQUFq992pUxA4Gfz6gv6SGqRAnWsCapCqX7/6Gi3VHAYDLFwI8d/BmlHwoCeM9gBvDWxzhUd3wv1r1TlMM2fC558XPf/FF2HZMnWfg7BW4BUoWHodKFgkVK7XVLfILj4byF9tt4TgYPW/8fHQvj3c+zF82hcOroYeY2HVKnW+ivzFk6wxZMIjYyFyMyR4QCcXNenmtkdhsj+Mmwwbd8CT3dWn9SVL4N//LnoNNze1i8+B5FeFkFl6UnEyi88GNm/ezGeffcbatWtxvXHmvsEAXl7w0kuwYIE6GJ3yM8Qtggat4cxd4K6FXbugTx9YtMh+b0JyHBkXIfZzdXLtf5LBW4FnesDtT0Gv+9WqJEKoT0v33acubdGjh7oA4NatdploezPyx6B27txZIkjJLL26QWbxVaNLly6xYcMG/sovppnPzU0tmplfBiYmBp5fCZ5dIP0cDALefVedkxIfX+3tlhxMyh/w01Pwfnf4v8WQcg2uWGDsdHh6P/R5pLBklqLA44+rXcPTp6sBa8UKhwhOxTP0zGZzwfaffvqJiIgIpk+fzqpVq2jXrh3u7u6yK08CZBefTXTLS8s9evRowdcF5swprOw8YIA6nrBMgX5OIFZAhyHq/p9/ruZWSw5BCDi1HXZ9DCfyxiRRoMu9cLYN8DZMfU5da8ya7dth2zb46ito27aaGl260tZt2rRpE8OHDy94atq2bRv9+vXj2LFjbN68WXblSYAMUDaRn8l39OjRkjvHjy/8+s47YeNGdab+n8BgN/CYCW2nqJMo09KqLdVXsjOzEY78CLs/Lizc6uwBQVMg7Alo3F4dTwoIULP2ShMUpCbZjBxZPe0uR2nrNg0dOpQ9e/YUrNmUnxCxefPmghJFkiS7+GzAw8ODdu3aWQ9QxQ0erFaB7tEDhg+CnDRIjVH3/fmnbRsq2V9OOuz8CD7sBRtmqMFJ2wQG/gsMD0KrqWpwAnj5ZfVnoqz5cQ0bwqhRDjOHrrSSRdu3by+yoCAUq10pScgnKJu5/fbbyy3TUmDECPWlT1Wz+tISYVAP8PCwbSMl+3lrDvwYCb0zgWxoqQGfALj9aeg5EU6cgre6wopVcPas2vWnKA4TeEpz4xIZPXv2xGAw4OTkVDDuVBa5XpNUnAxQNrJs2TJ0Oh3z588vWMum3L50rQ+M+wZW3At3nAFNEiBr9dUqFw7CriXw9XLIssBpAS4e8PMK6HUvOOV1asTkPUVv26b+d+FCdd2lPXvA3d0eLS9X8YoQGo0Gi8VSogKENTIhQrJGBigbKG1guEhtvtL494dhC0D3Mnz3BDTpBL7VW6hTqmJCqAkPuz6CUzsgV8BZE0R0hwdmwfgZ8Okm+GJU4TkxMdCpE7Rrp9bEW7NGfXqqpuBkbbHA4j+7xY8xm81FxpuKPzU5OzujKApGo7Fgm7u7O+PGjWPixIkyIUIqSQjhkK/evXuLmioqKkpotVoBFLy8vLxEVFRUxS5gsQgxMEAIb0WI97sLcf2ibRss2YYxR4gDK4VYEirE3Prq6+0WQrw5XggQYvNm9bgXXlC/P3pU/T47WwgPDyFmzhQiK0uIhg3V/S++WC3NNplMYvDgwcLLy0soiiK8vLzE4MGDhclkKvOYdu3aCUVRivzcF3+1a9euzOtKdROwX1iJAzJJwgaslW65qQFgRYF+YyFNQOoZWD1BrSIg1QxZV+H3RfBBD9j4FFw+BvWaw5A34LmjkNZanRPXv796/Msvq2sxffaZ+n1uLrz+OkyapI5D3nuvun3IkGpp/o2ZdyJvscCdO3cybdq0gnlM1o5JTk4u87peXl4sXryYNWvW8Oabb7JmzZqK9SpIdZbs4rOBoKAgtFptkcULXVxcyMnJYePGjRw6dKj8canuPdXPnMbmcCEB1k2DSWtBU/ryA5KdXT0Jez6D+Egw5mWu+XZXEx+6jwXnvKoi3bvD008XJsE0baoux94ybzXb+vXhn/8svO4XX6hp4/lFX22stMy7VatWsXHjRkJDQ7njjjtKHJOflefm5obBYCj42bZYLAXd3Pkr28o0cqkiZKkjG8gfg9qzZ0+RX2Jrv7ClfoI8eFAtVfPVh3DlA8i6Aj3Gw+jPS5+kKVU/IeDsHti9BP78H+qnCqD9IOj7DLS7S11i5a+/YPjwil1z82YIDYUGDWzW7LJER0czadKkIh+wbuTl5cXTTz/NwoULrSZA9OzZk7Fjx9Krl5rgc/jwYTnpVipTaaWO7D7WVNqrJo9BCaH20c+ZM0e4urqW2h9f5rhUVpYQiiLEvHlCnNuvjl3MrS/EDzOEMMs+e7sz5QpxaJ0Qnw8sHF96o7EQPz4uxIVDRY+NixOidWshXnlFiHPnhEhPt35Ng0GIzz9Xx5sWLrT9eyiFyWQSffr0KXMsyd/fXwBWf75varxVkoQcg6p2Go0GFxeXIhlLxZU5LuXhAW+/DQMHQqveMHkduGjh0Fp1XMNS/rwSyQay02Dnh+rE2h8ehvMHwKMR3PkSPHcERn8KzYqttdSzp/r0tHCh2r3XsWPJlZQBIiPhscfUr4cNs/17KYVGo6FPnz44OzszYcIE3K1kDp4+fRqNRkOjRo1K7JMTbqWqIsegbMjaWNSNyp2Y+OqrhV+36asGqVXj4OAaMGbBmC/B2a2KWy2V8Omn4GGBJmcg4YbxJZ8AtQxRz/sKi7YWt2aNuoTKp59Cmzbw2mtquStrE24nTixcULBnT9u8lwowGAysXbuWsWPHsmrVqiJzm25kNptJS0srsVSGnHArVRlrj1W3+gLqAd8DJwA9kAbEAlMqeo2a3sUnRNFUXEBoNBrh5ORU0DVSboqtxSLE3r1CHDtWuO3U/wmxoJXapbTsH0Jkp9n+jdRVFosQS+epXW4gRHMnISZ7CrF8hBCJMUKYzSXPOXhQCL1e/dpkEqJFCyH+8Y/C/Tt3CnH+fOn3XLVKiMjIqn0fN8FkMolXX31VAGLevHnCZDIJk8kkoqKixKBBg6ymkcvUcelWUUoXn02SJBRFaQx8DPwGnAbcgInAA8DzQoj3y7tGTU6SuFF+Sm5CQgI98pbZfuyxx2jWrBlxcXFlDxrn5KhLc9x/f9GVUS8ehsixkJmiZolNWgMN/Wz8TuqQnOtwcC3s+wo2HIJEI9zmCTsVuJQBu3dDWFjJ8/74A7p1U1+HDqmTbYcPhx9+gDFjqv99VFD+z2hcXBwbNmzgyJEjmM3mguoO+Yk81pInvLy8iIyMRKPRyArkUqU5RJIEsBs4XJFja8MTVGlmzZolPDw8hMFgKP/g8eOFaNas5Kf1q6eF+ChYfZJa2FaIk9tt09i6JOWYENHPFyakzK0vxHsBQmx+S50sbTAIsXFj4fEXi02gfvxx9Ulr6VL1+3HjhPDxUc9zMPlPRfPmzRO9evUqeMov/rox4aEiE3glqTIo5QmqugNUNHCgIsfW5gCVnJwsUlJSKnbwqlXqP9Pu3SX3nT8lxMox6h/Sed5C/N+H1rud6rK//xZi2DA1e84ao0GIoz+p3aX5QWlufSGe6S3EN2+q2XrWHDwoRP36hdUfrl4VwtNTiIceUr+/fFn9d3v22ap/T7eoeNdzWS9FUcT8+fOLnBsVFSXmz58voqKiZHCSqkRpAcqmWXyKyllRlMaKoswAhgEf2PKeNUGLFi1o2rRpxQ4ePhycneGnn4pu37wZugRCq6eh//MgzPDLHIgcoy4RLqk8PNSutk8/Lbr9ciLE/AsWd4HvH4DTv6tZkiEPwRO7YIcJPt4ATqXkEfn6qv8ujz4KFgt88w1kZcEzz6j7T59W7/3IIzZ9e5VRfI2mshRPeMifZDt79uyCSbeSZCu2TjN/CjACqcASYJYQ4tvSDlYUZYaiKPsVRdl/+fJlGzfNvlavXs1rr71W/oENG6qp5r/8Urht1y4YPRr8/aFXIAyZq1aZ8GwMJ7fCJ7fD4fXWU5nrmkaNoF8/iI4GQwbErYCvhsDS29TJtVmp4NMJ7nkXXjgGEe+rP60HD8KDD5a+vIWvL7z/vvpv8emnq/N5pwAAHKxJREFUcM898O676uRqgJAQuHxZHY9yMNYqRRQnl1yXHEGFkiQURRkC/FLugbBdCDHwhvOaAG0AH+Be4DHgSSHE59ZPL1RbkiRK89xzz7FkyRJee+01+vTpU/bA8tmzajmcY8fUpbxXrVL/QO7YAR9/rCZSzJqlPjn99AQkbVHP6zAE/rEIvP2r7X05lG3b4PvvwcUAH30Ds3ygYa66z7UedB8DQVOhVUjRQDR7NrzzDpw/r/5/Lo0QamDatUtNkGjd2qZvp6qUVilCURQ8PT3p0KEDY8aMITg4WCY8SNXilpIkAE+gcwVefuVcZzmQAbiUd8/aPAZlMplEz549C/r4KzzYHBUlRKNGQvTvL8SZM+q2wYOF6Nq18BizWYj9y4V4p7U6ljLfV4hf3xQi57rt3pCjsViEuHBYiIHdhfDUCDHTSx0PustNiK/vESJ+lRCGzMLjs7OF+OuvwnPbthVi6NCK3evkSXXs6euvq/592EjxZAetVit69eol3njjDTmuJNkFpYxBVWiirhAiC6iK9cf3A9MAX+DvKrhejaTT6UhKSgLUDwiZmZnExsai0+nKLqIZEQFXrpTc9txzcOoUtG2rLnjXexoE3AMxr8GR9fD7f+DACrjzZQieqi6QV9OZzVD8k/2VJDjyo/qezx2D3zMg2AX8WkL3bGjYAx6KLnmtCRPUJ6CEBEhLA6NRTe2viLZt1e5DB11EEKyv7fTUU0/x/+3dfXTU5bXo8e/OJJO3QbQoaLHW8iKICgLXwK2oFSwg2lIBi6HceupynVNt6/FqOfh2LxCLniMIHunpOVq7wFYJHBF5ieQCLYI2EKgQARHRBLGF8FYF2iSQZCbP/ePJL8xrSGAmv5lhf9b6LZKZYeb5JVmz53me/dv7gQceYPfu3ZoarpJXtKiVqAN4AzuD8p7psek8gyoqKoq44DE8W6rNPvnEzg7mzYt+/583G/PKt09npz3Xy5j35hpzMkY9uFTw+efG9O5tL2D+8xZj1k4zZt4NoVl43/uK/bmseMXOKmtqQp+jqcmYV16xF9W++66te3j//fa+QMCYhhjZeykmWmp4QUGBAcy8WH8zSnUwOjKLT0T+SUTmi8gPROQWERknIouACcAvjDENiXjdVOGUQAp21uVheveGq66yn+Kj+VoB3LcaJr4Gl/aH2iPw+2nwfF9Y+bC96DeV1H0JL/5fWx381dvhN7fBH+fCX/dATmdbdqjwv+GTbnDddXDnfXZW6fy8jYG9e20Ppvvvh9/8Bm66yX7/yivw1lv28Vnp0daktLSU8vLykL5N77//PhkZGXz/+993e3hKtSpRtfh2AmOB2cBXsHlRu4E7jTFvJ+g1U8btt9/OkCFDWlJ9c3Jy6Nq1K4FAgEAg0P6llkmT7JuuMdGzzkTg6u9A3zuh8g9Q9oJNq9463x7drrX9iq4dl3wJFaUl0KkWTu2Gveuh+gNY+HfongEZX4Dva3DNndBnDHQvgOzm5cuh/xNGjAj9eRQVwbRpp7//wQ/gJz85fd9//qet+LBjhw1uKaK19uzRMvaampoQESZNmqQNA1VyizatSoYjnZf4jLFLL8uWLTM9evQw2dnZLVftd9iV+Yd3G/P2lNPJFM7xywJjVj9pzKdrz7wMGAjYduUffBCfMQUCdlzbfmfMin825j++aUyuGDMgy5if5NvxPXSRXbobPsCYnBxjVq8+/f/Hj7etLYyxS3jh3n7bmDFjjJk715jKysj7P/nEmEceScrKD7GEX3Sbk5NjevToYZYtW2b8fr9ZsmTJ2bV7UaoDcS5JEir+PB4PHo+HI0eOtHQibXOyRCwLFthrfnr3hqoquOIKu1QVPLMKBGDWLNtOfMxzMPJpO6v6cAl8uhaOfmyPjfNAMuzs6rIBtoVE137wlW9Ap6/aZbDycnj+eZuOvXBh28ZoDNT/DU4cgC8+hb9+An8N+rchKPW5OgAnDXzSBFUB2LgI3twMMhP+6w0YMABWrrSdZnftsjXvBg2yR7SZ5JgxrTcN7N3bnk8KKS0tZdOmTdTV1QG28+3evXuZOHEiffv2pXtzl97MzEz8fn/I/3XaYmh3W5WsNEC5KNryy1m/aZw4AVOn2gDw3HPw6KMweTJ06mQz/F5/3T7u17+2bTw+/tgGtMxs6DvGHoFG2x22ci3sK7Ot5g/tsEcwjxcu+CqsOmG/f+sNWNIFOl1g+1Q1+UOPk8ft3lfNUVvgNlAf+zwu6A7dB9trk1bsBl6C3y6yLSrKD8IXx2H4cBtMRo6E5cvhxRdh9mzIyzvdT+k8UVFR0RKcgtXX17N9+3a2b9+OiHD55ZdTXV1NQ8Pp7V9ti6GSnQYoF0XrF5Wbm3t2bxqdO9sLd0eOtBUQrrzSXrz729/a2c2//Av06WP3YDIyYNEi+6Z+8cWnn8OTBd+4yR4ADXVQXQGHP7TJFEf3wLF9Ntgc2wcN9XBZBviAsgXQuY05N1n50KkbdOkNF/e2fZWcI7/L6cdNu83uBY0fbys0zJtnKzw0Ndn7v/tdG6DeftsG4B//GLp0if6aaWrgwIH4fL5WyxYZYzh69ChXX301VVVV1NbWkp+fr1UiVNJLSLuNeEj3ShJgN7edZnC1tbUYY7jyyiuprKw8+43rAwfghRfgoYdsZYNjx2ywuu02uwS2c6fNgBs/3pbqefjh9r9GfY2tWlF71B71f7cNFBvrbO268t3w2lrI8ECmBwrvhO99D3xd7eHNb8Nr1NsyTw8+aJfd5s+H++6Dd96xpZ8AjhyBSy+1s0aPByor7bmeR/x+P6NHj6asrCykaWA4EWH69OkMGjRI22KopBOrkoQGKJcF94tauXIlF154IcOGDYvIxjon06bZLLUPPrD7NmDLAA0bZguehvvwQ/vGHzy7CnfwoC0DlNE8azpwwNa9y82Fv//dzmb+8hcbNDweuyfm9bZv3IcO2T2z7t1tb6zcXPjOd2DFitOPefll2L/fPm7mzPY9fwoLBAIsW7aMBx98kB/96EcUFBQwZcoUqqurowYqn89HcXGx7jeppJQU/aDac6R7Fl84v99vhg8fnpheO19+aTPfbryxbY+fNMmYbt2M+eij2I/p39+Yu+6yX2/dap9/4UJjTp0KfdyqVfa+V1+N/jwrVhgzf37bxrVnjzEHD7btsWkovIeT1+s1gMnNzTUjRoww9fX1ZuXKlWbGjBlmwIABJj8/X/s2qZRAMvSDas9xvgWolStXRvTniWsacHm5MTt3ht42b54xP/xh5GO3bjWmUydb92/jRmMaG0Pvr6qyfzpz5tjv/X5jLrvMNue7+mpjgntdNTUZM3t29MBy6pR9nptvjrzvoYeMWbq0feeY4pwAVFRU1FITLzwo5efntyllXPs2qVQSK0BpkkSSiGtGXzRDhkTedvy4TaLYuRPuuMMmWcyfb9O0P/jAJlzcfLNN2a6psUt0r756ujfVXXfZfz0emDDBJjEMHmyrqztEbEZhNM7zOG1Hdu+2S45VVTYzr2vX06+R5sL3I/Pz8ykoKABgy5YtZ+zdFP634vRt0iU9lco0QCWJaBl9Xq+Xjz/+mJKSksRsaE+ZAtnZNlDMnGmTEpz9ix49oKzMpqzn5dmkBa8Xli61e0CDBoUmJPz4x7YCw8svR78G6Q9/sOWY5s49fdtLL9nn+Pa3bUuRG26A4CB9xx3xPd8kFt5EsKamho0bNwK0mvzg0JRxlZaiTauS4TjflvhiteHusD2EI0fatr/T1GTMtm3G7NvXvuefM8cu561da7/fs8d+P3Pm6eddutTuR/3+9+1//hQXrYBwWw7dY1LpgBhLfJrFl0ScjL7FixezaNGikCv/Uz4Lq6bGdpk9dAg2bLDp7w88AOvWwWWXuT0615WUlHDXXXdFVHuIRhsLqnQTK4tPl/iSiLNvUFFRQSAQCLmvpqaGuc3LYyn5ZuTzwZo18M1v2i60ZWW2B1OslurnCedDyZtvvonf7ycrK4vGxsaoj83OzqZv374alNR5QwNUEoq2HwXwzjvvsGXLFoYMGZKaVaivuMIGqWHDbOXwWbPcHpGrghMjnN91nz59uOSSS1i/fj3hqxt33303CxYsSL3fu1JnKSH9oNS5cdpx+Hy+kNuNCe2+m5L69YM//Qn+7d/cHonrwhMjAPbt28ewYcMi+oX5fD4mTpyowUmdVzRAJSGPx8Pq1aspLi5m+PDhEfc7KcUpq2fP0xUoziOBQICSkhKefvppSkpK2Lp1a9RLCzIzM1s+oIgIPp9P6+ap85Iu8SUpZz8KIq+D0ZTi1BPtOqeePXuSm5sbUo08Pz+fQYMG8eSTT7aUwNK6eep8pVl8Sc55Y3v33XdpbGwkPz+foUOHpuYe1HmspKSEwsLCiA8aPp+Pw4cPIyItFcb1d6vON7Gy+M6/dZYU4yz3PfbYYwA88cQT+gaW5MKX8gKBQNRKIXV1dTQ2NnLttddSVFREcXGx/m6VCqJLfCnA4/Hw85//nJqaGsaNG6dvYEks2lLekCFD+NnPfkZ2dnZIVYisrCy+/PJLJk2axOOPP66/V6XC6AwqRVxwwQXMmTOHvn37uj0U1YrgzLzgrEuAG2+8kby8vJbHOt1t58+fz6hRoyKufVPqfKcBKoU0NjZSVlZ2xsKhyj2xiv7u3LmT1atXs3jxYiZOnIg3qDdWbW1tal86oFSCaIBKIX/84x8ZNmwY69evd3soKopAIEBjYyMSVh0jLy+P48ePc88993DzzTdzzTXXRFSLSPlLB5RKAN2DSiEFBQVkZWXxzDPPACla8ijNOKWKtm7dyltvvUVlZSVNTU0t9+fm5tKrVy9WrFjBiRMnyMvLi1opRC8dUCqSBqgUEQgEGDt2LE1NTWzatInCwkJNSXZZtFJFwbKysujWrRuVlZXU1taSlZXF6NGjWbVqFUOGDIlIpNALcZUKpQEqRTib785GenDJo5StcJ7iopUqCtbY2Eh1dXVLMkRjYyObN29mzZo1rF69Wi/EVeoMNECliLZ23HWWnCoqKhg4cKC+8SVQtN9JMK/XG3Ovyel2qx8ulIpNA1SKiLZvkZ2dHdJxF4h6DY4uAybG9ddfT0ZGRkR6uFMVomfPnlRVVelek1JnSbP4UkR4hXOPx0NDQwMLFy6ksLCQUaNGUVJSEvUaHE1fji+nUsTq1atpamrC6/W2BKUBAwYwffp0iouLW1qjaNFXpc6OzqBShFPyyOm4u2TJkpaqBE4guvTSS9u0DKjOXniliJycHHr37s348eOjNhHUvSalzp4GqBQS3HG3vr4+5L7a2tqWT/G6pJQYgUCAGTNmtBTuBTh58iR79+5l0KBBUT8EOL8z/YCgVPvpEl8KcvajguXn5zN69GgGDBhAdnY2ADk5ObqkFCfOzOnZZ5/Vi2yV6iAaoFJQ+H6UiFBQUMD+/fspKyvjV7/6FZ07d+biiy/mpptuorS0VOu8naPS0lI2btyI3++PuE9nqUolhgaoFBTccffuu+/GGMP06dP53e9+x9ChQ7n33nvp1q0b+/fvZ8aMGS1JFBqkIkVrjRFNRUUFJ0+ejLjd6/XqLFWpBNEAlaKcvY3XXnuNiooKtm3bxq5duxg4cCAlJSUcOHAAQLP5WuEs2xUWFjJt2rRWA3nv3r0jbvN6vUydOlXT+JVKEO2om+Kiddzt1q0bn332GcG/WxGhqKiIp556ysXRJgfnYuZFixbxxhtvtFR6ABt0pkyZwg033MCOHTtaLnYGuPXWW9m2bRt1dXV6jZlScRSro65m8aU4p9yOs3FfW1tLdXV1RHM8r9cbclHv+famGq2oa7QqEA0NDTzzzDNkZGTQ1NREXl4ePXv2ZNy4cTz66KMA7Ny5U1PGleoAGqBSXLRyO6dOnaJHjx4cOXKkJeW8vr6ehQsXsnz58rT/5B9e7mnkyJGMGTOm1bp5wYwxLct8tbW17Nixgx07dpCfn8/QoUPT+menVDLRAJXiopVA8vl8zJkzB4/Hw+LFi1m0aBF+vz9iPyodr80JrzCek5ND586dOXHiRMiM8mwENxZMx5+dUslGkyRSXHDKeXA5Hefi0Kuuuipi0z+dr9sJrzB+6tQpDh8+3GpwysrKIjOzbZ/V0vlnp1Sy0RlUigsugRStnE5bisymw3KVs6w3e/bsNi3jwemirgUFBQBs2bKFmpqalp9HtGw+veZJqY6jWXxpLnzJy3nzbWpqSspMtLNpF+KcY3l5eavtLxz5+fn06tWLcePGtdTPA1qC/HXXXQfA9u3bWbp0KZWVlZq5p1QCxcri65AAJSKFwELggDHm8rb8Hw1Q8eO86YcXmQW7X1VcXBx1T6Wje0uFF2Jta0AoKSmhsLDwjDOnnJwcJkyYwMSJE9t8Ls7PQIu9KpU4rqWZi8iFwFzgUKJfS0XXWpHZmpoaFi9eHPHGe7bB4lyE7x+1NaEjVuPAiy66iJMnT1JfX98y/gULFrRr/FrsVSn3dMQe1HPAduAgcFsHvJ6KIdp+FMCSJUs4ePBgSPApLS1l06ZN1NXVAR3TYr61rsG33357xGzOGeeePXvIzMwMKeLq8/mYP38+Ho9HZz9KpaiEBigRuRGYDPQHtISBy5yMv7KyspBlvlOnTrUEHycQzJ07tyU4ORLdW2rgwIHk5uaGvK7H4+Gjjz5i8ODBVFVVtczmoiU2eDyekL21O++8s2UGpJRKPQkLUCKSBbwMzDLGVIpIol5KtZGT8Xfvvffy+uuvh9xXW1vLtm3beOGFF2Je0BqPDLZY+1qBQICGhoaIzDm/309xcXHIbTU1Nbz33nsYY1qqiwcCgbPaY1JKJa9EzqCmAtnAs239DyLyj8A/AlxxxRUJGtb5zePxcM8997B8+fKI1PN169axefPmqNcMtdZbqi3JFE7V8EceeYTq6uqQfaFVq1YxZswY3nvvPRoaGsjMzKRLly4cP348Ys/MEd6TCWy1jD59+uiMSal0YYw544HdOzJtONY3P74XcBIYHfQcC4D9bXk9YwyDBw82KjH8fr8ZMWKE8fl8BjAej8dkZGTE/L1mZGSYO+64w/j9/lafS0SMz+czI0aMCHms85icnJyI587JyTG33HKL8Xq9Ibd7vV4jIm35m2s5fD6fWblyZUf+KJVScQC8b6LEgbZWktgIXN2G44fNj38RWAeUi8iFzZl8XkCav89t4+uqBAjuJzV58mQyMzNpamqK+lifz8esWbNYsmRJ1CWz4Mw7E6O1R2lpKeXl5VFnZqdOnWLDhg0hFcXBFm3Nyspq8zlpXyal0k+blviMMXXAx+143n7A14FjUe47Bvw78HA7nk/FWXDqeXhwcDhlk37605+yZs0aKioq6N+/PwA7duygf//+LF68OGK/KjyZoqKiIiLh4kyci2mdxIi8vDx69erFNddcw9KlSyMqtU+dOpVp06bpvpNSaSRRe1D3ADlhtz0GDAbuBvYn6HVVO0VLPQ9ONnAqgTv7Q8FlgJysuXC5ublcf/31LXtTH374YUT7j9Y4gXHVqlWsWbMmJE0c4PDhwxHXZ2lwUir9dFipIxFZANxmtJJEUjnTBbltrdLgyMrKol+/fowdO5bly5fz6aefUldXh4iQkZHRkm0XrcJ4W7PwtLqDUulFGxaqqM5UbDZWlYZYunTpQlVVFUVFRSG3G2PIysqisLAwZGYWHhjbUulBqzsodX7osABljPmHjnot1T6tveHHqj4RTU5ODsePH4+5lBeeBt5aYFRKKZ1BqVY51SfCq6E7e1BwujJ6165d+eyzz2I+V/iFvjoTUkq1RgOUalX4EqDTimLnzp0hXztJEZMnT46YbTl9lzQNXCnVHtoPSsVNeMKFkxoe3HdJl/CUUuE0SUIl3JkSLpRSqj10BqWUUspVsWZQbS11pJRSSnUoDVBKKaWSkgYopZRSSUkDlFJKqaSkAUoppVRS0gCllFIqKSVtmrmIHAU+P8enuRj4axyGk4z03FKTnltq0nNLrK8bYy4JvzFpA1Q8iMj70XLr04GeW2rSc0tNem7u0CU+pZRSSUkDlFJKqaSU7gHqZbcHkEB6bqlJzy016bm5IK33oJRSSqWudJ9BKaWUSlEaoJRSSiWltAtQIvI1EVkiIidE5G8islRErnB7XPEgIpeLyDwR2SQidSJiRORKt8d1rkRkgoi8KSKfi8hJEdkjIs+KSCe3x3auRGSUiKwTkUMiUi8i+0Xkv0Wkn9tjSwQR+X/Nf5e/cHss50JEvtV8HuHHcbfHFi8iMkZE3hWRmub3yvdFZLjb4wqWVg0LRSQPWAfUA/cCBvgF8I6I9DfG1Lo5vjjoBXwf2Aq8B4x0dzhx83Pgz8ATwH5gIDAduFVEvmmMaXJxbOfqK9jf16+Ao8AVwGNAuYhcZ4w514vRk4aIFAID3B5HnD0E/Cnoe79bA4knEfkn4JfNx9PYycr1QJ6b44pgjEmbA/hnIAD0CrrtG9g/qkfcHl8czi8j6Ov7sQH4SrfHFYfzuiTKbT9sPr/hbo8vAefbp/ncHnV7LHE8pwuBQ0Bh87n9wu0xneP5fKv5PG5zeywJOLcrgZPAw26P5UxHui3xfRcoN8ZUOjcYYz4DyoCxro0qTkxqzyRiMsYcjXKz86m1e0eOpYN80fxvo6ujiK/ngF3GmGK3B6LO6D6gCfgvtwdyJukWoK4BPoxy+y4gLdf809gtzf/udnUUcSIiHhHxikhv4CXsbGORy8OKCxEZhp3xPuj2WBLgdREJiMgXIrIwTfazhwEfA/eISJWI+EWkUkR+4vbAwqXVHhR2vf9YlNu/BC7q4LGosyQi3YEi4PfGmPfdHk+cbAYGN39diV26POLieOJCRLKwAXe2MWaP2+OJoxPA88AG4G/YfdEngE0iMjDFf3dfbT5mYc+pCrgb+KWIZBpj/t3NwQVLtwAFdt04nHT4KNRZEREfsBy7b/gjl4cTT/8LuADogU0KWSsiw4wx+1wd1bmbCuQCM90eSDwZYyqAiqCbNojIu8AWbOLEU64MLD4ygE7APxhjljbftq45I/hxEXnRNG9WuS3dlviOYWdR4S4i+sxKJRERyQFWYN/ERxlj9rs8pLgxxuw2xmxu3qMZAfiw2Xwpq3m560ng/wDZInKhiFzYfLfzvce9EcaXMWYb8Alwg9tjOUfOHujasNvXAN2Ayzp2OLGlW4Dahd2HCtcP+KiDx6LaoXmp6E2gABhjjNnp8pASxhhzHLvM18vtsZyjHkAO8Br2A6BzgJ0lHgOuc2doCSNEX6VJJbti3O6sNCVNMla6BagVwFAR6eHc0DxtvbH5PpWERCQDeB07sxhrjCl3eUgJJSLdgL7Ytf9U9gFwa5QDbNC6FRuI04KI/A/gKux+Yip7q/nfUWG3jwL2G2MOdfB4Ykq3PahfAz8FlovIU9hPOk8Df8Fu5KY8EZnQ/KWz4X57c/fho8aYDS4N61z9B3aTdiZQKyJDg+7bn8pLfSLyFrAN2IHdbL8K+N/YPbbnXRzaOWueCa4Pv11EAD43xkTclypE5HXgM+zv7jg2SeJx4AAwz8WhxcMq4B3gJRG5GNgLTMBe+J9U+75pV828eV18LvBt7JT1D9gL0va5Oa54EZFYv7ANxphvdeRY4kVE9gFfj3H3DGPM9I4bTXyJyFRs9Y+egBf7YWk98Gy6/E2Ga/4bnWmMSdlEAhF5HHvR8dex1RUOAaXANGPMQTfHFg8icgHwLDYwXYRNO/9XY8xCVwcWJu0ClFJKqfSQbntQSiml0oQGKKWUUklJA5RSSqmkpAFKKaVUUtIApZRSKilpgFJKKZWUNEAppZRKShqglFJKJaX/D8F4lIDhC4z8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_prediction(model, 74, data_val_u, data_val_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
